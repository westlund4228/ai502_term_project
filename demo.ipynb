{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Repo & Install Libraries"
      ],
      "metadata": {
        "id": "r4Fchov7ULP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxxCkKiBTY5i",
        "outputId": "89939764-0dce-4fd1-fe01-168ef1418949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'amc3'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 168 (delta 95), reused 122 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (168/168), 62.09 KiB | 512.00 KiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "/content/amc3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GITHUB_PAT = userdata.get('github_pat')\n",
        "\n",
        "github_username = 'westlund4228'\n",
        "github_repo_name = 'ai502_term_project'\n",
        "\n",
        "!git clone https://github.com/{github_username}/{github_repo_name}.git\n",
        "%cd ai502_term_project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX torch-pruning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELoyNmbvTdDP",
        "outputId": "649a6424-fb54-427e-b448-cf5a28e792c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch-pruning\n",
            "  Downloading torch_pruning-1.5.2-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-pruning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-pruning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-pruning) (3.0.2)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pruning-1.5.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-pruning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorboardX-2.6.2.2 torch-pruning-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "def zip_folder(folder_path, zip_path, excluded=None):\n",
        "    if not os.path.isdir(folder_path):\n",
        "        print(f\"Error: Folder not found - {folder_path}\")\n",
        "        return\n",
        "\n",
        "    # Check folder size\n",
        "    total_size = sum(\n",
        "        os.path.getsize(os.path.join(root, file))\n",
        "        for root, _, files in os.walk(folder_path)\n",
        "        for file in files\n",
        "        if os.path.isfile(os.path.join(root, file))\n",
        "    )\n",
        "    if total_size <= 1024:\n",
        "        print(f\"Warning: Small folder size detected - {folder_path} (≤1KB)\")\n",
        "\n",
        "    if os.path.exists(zip_path):\n",
        "        raise FileExistsError(f\"Zip file already exists - {zip_path}\")\n",
        "\n",
        "    excluded = excluded or []\n",
        "    excluded = set(os.path.normpath(e) for e in excluded)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            # Filter out excluded items\n",
        "            dirs[:] = [d for d in dirs\n",
        "                      if os.path.normpath(os.path.join(root, d)) not in excluded]\n",
        "\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                rel_path = os.path.relpath(full_path, folder_path)\n",
        "\n",
        "                if os.path.normpath(rel_path) not in excluded:\n",
        "                    zipf.write(full_path, arcname=rel_path)\n",
        "\n",
        "    print(f\"Success: Compressed {folder_path} to {zip_path}\")\n",
        "\n",
        "\n",
        "def get_sizes(folder_path):\n",
        "    total_size = 0\n",
        "    file_sizes = {}\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"File sizes in '{folder_path}':\")\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                size_bytes = os.path.getsize(file_path)\n",
        "                total_size += size_bytes\n",
        "                file_sizes[file_path] = size_bytes\n",
        "                print(f\"  {file_path}: {format_bytes(size_bytes)}\")\n",
        "            except OSError as e:\n",
        "                print(f\"  Error accessing file '{file_path}': {e}\")\n",
        "\n",
        "    print(\"\\n---\")\n",
        "    print(f\"Total size of '{folder_path}': {format_bytes(total_size)}\")\n",
        "\n",
        "def format_bytes(bytes_size):\n",
        "    if bytes_size < 1024:\n",
        "        return f\"{bytes_size} Bytes\"\n",
        "    elif bytes_size < 1024**2:\n",
        "        return f\"{bytes_size / 1024:.2f} KB\"\n",
        "    elif bytes_size < 1024**3:\n",
        "        return f\"{bytes_size / (1024**2):.2f} MB\"\n",
        "    else:\n",
        "        return f\"{bytes_size / (1024**3):.2f} GB\"\n"
      ],
      "metadata": {
        "id": "WC603w9DaV4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetV1"
      ],
      "metadata": {
        "id": "lUtNHdXt_1HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Weights"
      ],
      "metadata": {
        "id": "MyiXfyF0Qhh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/download_mobilenet_weights.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DQCFuyZMyRQ",
        "outputId": "899497a8-6a59-4b9f-f981-5c8389c4e5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/state_dict/mobilenetv1_cifar.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMC Baseline"
      ],
      "metadata": {
        "id": "9bQrbX32QjkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=train \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=200 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdbMjPjW_wcg",
        "outputId": "77950ce6-a1e1-4fe0-939a-b483789be0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "100% 170M/170M [00:13<00:00, 12.6MB/s]\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "=> Saving logs to ./logs/mobilenet_cifar_amc_r0.5_ep200_search-run1\n",
            "=> Output path: ./logs/mobilenet_cifar_amc_r0.5_ep200_search-run1...\n",
            "** Actual replay buffer size: 900\n",
            "\u001b[92m New best reward: -7.9181, acc: 50.8200, compress: 0.6476\u001b[00m\n",
            "\u001b[92m New best policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 319, 511, 204, 237, 127, 54, 63, 28]\u001b[00m\n",
            "#0: episode_reward:-7.9181 acc: 50.8200, ratio: 0.6476\n",
            "New best clamped policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-13.8020 acc: 10.5000, ratio: 0.3284\n",
            "#2: episode_reward:-12.7168 acc: 17.8800, ratio: 0.3502\n",
            "#3: episode_reward:-13.1164 acc: 15.8800, ratio: 0.3898\n",
            "#4: episode_reward:-13.1286 acc: 14.2200, ratio: 0.2924\n",
            "#5: episode_reward:-10.2052 acc: 34.3400, ratio: 0.3707\n",
            "#6: episode_reward:-13.7160 acc: 13.1800, ratio: 0.4788\n",
            "#7: episode_reward:-10.6651 acc: 31.2600, ratio: 0.3607\n",
            "#8: episode_reward:-13.4443 acc: 10.3000, ratio: 0.2130\n",
            "#9: episode_reward:-13.4070 acc: 14.9400, ratio: 0.4616\n",
            "#10: episode_reward:-13.1665 acc: 16.8400, ratio: 0.4956\n",
            "#11: episode_reward:-13.9860 acc: 10.9400, ratio: 0.4357\n",
            "#12: episode_reward:-12.7516 acc: 18.0600, ratio: 0.3781\n",
            "#13: episode_reward:-13.6965 acc: 12.7600, ratio: 0.4339\n",
            "#14: episode_reward:-13.1667 acc: 16.8800, ratio: 0.4995\n",
            "#15: episode_reward:-13.7082 acc: 10.5800, ratio: 0.2998\n",
            "#16: episode_reward:-13.6744 acc: 10.6200, ratio: 0.2907\n",
            "#17: episode_reward:-13.3036 acc: 11.0200, ratio: 0.2052\n",
            "#18: episode_reward:-13.0596 acc: 14.3600, ratio: 0.2766\n",
            "#19: episode_reward:-13.6580 acc: 11.6200, ratio: 0.3393\n",
            "#20: episode_reward:-12.8479 acc: 17.2000, ratio: 0.3613\n",
            "#21: episode_reward:-13.4988 acc: 12.2600, ratio: 0.3167\n",
            "#22: episode_reward:-13.0510 acc: 13.9600, ratio: 0.2551\n",
            "#23: episode_reward:-12.9773 acc: 15.0600, ratio: 0.2846\n",
            "#24: episode_reward:-13.2305 acc: 14.8000, ratio: 0.3657\n",
            "#25: episode_reward:-13.0820 acc: 15.4400, ratio: 0.3450\n",
            "#26: episode_reward:-13.5738 acc: 12.2200, ratio: 0.3426\n",
            "#27: episode_reward:-13.1598 acc: 13.5800, ratio: 0.2706\n",
            "#28: episode_reward:-11.8780 acc: 22.7000, ratio: 0.3108\n",
            "#29: episode_reward:-13.9864 acc: 11.1000, ratio: 0.4484\n",
            "#30: episode_reward:-13.4135 acc: 13.0600, ratio: 0.3308\n",
            "#31: episode_reward:-13.8070 acc: 10.6200, ratio: 0.3372\n",
            "#32: episode_reward:-13.5333 acc: 10.6200, ratio: 0.2482\n",
            "#33: episode_reward:-14.0490 acc: 10.6200, ratio: 0.4420\n",
            "#34: episode_reward:-13.5805 acc: 14.5200, ratio: 0.5234\n",
            "#35: episode_reward:-13.9280 acc: 10.3000, ratio: 0.3651\n",
            "#36: episode_reward:-13.3811 acc: 10.6200, ratio: 0.2093\n",
            "#37: episode_reward:-13.6701 acc: 11.6800, ratio: 0.3476\n",
            "#38: episode_reward:-13.8728 acc: 10.5000, ratio: 0.3554\n",
            "#39: episode_reward:-12.7495 acc: 17.3600, ratio: 0.3306\n",
            "#40: episode_reward:-12.9862 acc: 16.6600, ratio: 0.3858\n",
            "#41: episode_reward:-13.3510 acc: 13.5600, ratio: 0.3364\n",
            "#42: episode_reward:-13.3035 acc: 12.8400, ratio: 0.2804\n",
            "#43: episode_reward:-13.4558 acc: 9.9800, ratio: 0.2045\n",
            "#44: episode_reward:-12.5737 acc: 16.3600, ratio: 0.2228\n",
            "#45: episode_reward:-12.9555 acc: 17.0000, ratio: 0.3963\n",
            "#46: episode_reward:-11.2128 acc: 27.2400, ratio: 0.3249\n",
            "#47: episode_reward:-12.4439 acc: 18.7200, ratio: 0.2938\n",
            "#48: episode_reward:-12.6986 acc: 17.2400, ratio: 0.3040\n",
            "#49: episode_reward:-12.7883 acc: 19.2400, ratio: 0.4967\n",
            "#50: episode_reward:-13.4653 acc: 10.7400, ratio: 0.2347\n",
            "#51: episode_reward:-12.4543 acc: 19.4800, ratio: 0.3439\n",
            "#52: episode_reward:-13.7774 acc: 10.9200, ratio: 0.3436\n",
            "#53: episode_reward:-13.7343 acc: 10.6800, ratio: 0.3141\n",
            "#54: episode_reward:-12.4027 acc: 19.6400, ratio: 0.3326\n",
            "#55: episode_reward:-13.3783 acc: 12.2600, ratio: 0.2761\n",
            "#56: episode_reward:-14.1266 acc: 10.5000, ratio: 0.4720\n",
            "#57: episode_reward:-13.8585 acc: 10.4800, ratio: 0.3486\n",
            "#58: episode_reward:-13.7428 acc: 10.4800, ratio: 0.3063\n",
            "#59: episode_reward:-13.4935 acc: 12.0000, ratio: 0.3008\n",
            "#60: episode_reward:-12.0295 acc: 22.0400, ratio: 0.3314\n",
            "#61: episode_reward:-12.9630 acc: 15.4800, ratio: 0.3019\n",
            "#62: episode_reward:-13.9136 acc: 10.6000, ratio: 0.3785\n",
            "#63: episode_reward:-10.6760 acc: 31.4600, ratio: 0.3835\n",
            "#64: episode_reward:-12.4581 acc: 19.7200, ratio: 0.3619\n",
            "#65: episode_reward:-13.6763 acc: 10.5400, ratio: 0.2873\n",
            "#66: episode_reward:-13.6985 acc: 10.6000, ratio: 0.2976\n",
            "#67: episode_reward:-13.4582 acc: 14.5400, ratio: 0.4553\n",
            "#68: episode_reward:-13.6117 acc: 11.6800, ratio: 0.3253\n",
            "#69: episode_reward:-12.5224 acc: 18.9600, ratio: 0.3387\n",
            "#70: episode_reward:-14.1234 acc: 10.6800, ratio: 0.4855\n",
            "#71: episode_reward:-12.5467 acc: 19.3600, ratio: 0.3769\n",
            "#72: episode_reward:-13.4098 acc: 13.8200, ratio: 0.3774\n",
            "#73: episode_reward:-12.8736 acc: 15.8000, ratio: 0.2878\n",
            "#74: episode_reward:-12.9658 acc: 16.1600, ratio: 0.3431\n",
            "#75: episode_reward:-13.8507 acc: 12.3600, ratio: 0.4816\n",
            "#76: episode_reward:-12.8779 acc: 17.5200, ratio: 0.3980\n",
            "#77: episode_reward:-13.1684 acc: 14.2800, ratio: 0.3096\n",
            "#78: episode_reward:-10.9215 acc: 29.2400, ratio: 0.3328\n",
            "#79: episode_reward:-13.6005 acc: 12.4800, ratio: 0.3698\n",
            "#80: episode_reward:-13.5269 acc: 14.0200, ratio: 0.4484\n",
            "#81: episode_reward:-12.9785 acc: 14.5200, ratio: 0.2588\n",
            "#82: episode_reward:-11.9270 acc: 22.1400, ratio: 0.2964\n",
            "#83: episode_reward:-13.4771 acc: 12.4400, ratio: 0.3189\n",
            "#84: episode_reward:-13.5965 acc: 11.8800, ratio: 0.3312\n",
            "#85: episode_reward:-11.8071 acc: 23.5200, ratio: 0.3340\n",
            "#86: episode_reward:-13.7334 acc: 12.8800, ratio: 0.4626\n",
            "#87: episode_reward:-14.4419 acc: 10.8800, ratio: 0.7191\n",
            "#88: episode_reward:-13.6749 acc: 10.5800, ratio: 0.2889\n",
            "#89: episode_reward:-13.9799 acc: 11.7000, ratio: 0.4954\n",
            "#90: episode_reward:-13.7381 acc: 11.6200, ratio: 0.3714\n",
            "#91: episode_reward:-12.7958 acc: 18.0600, ratio: 0.3991\n",
            "#92: episode_reward:-14.0577 acc: 10.6200, ratio: 0.4463\n",
            "#93: episode_reward:-13.3992 acc: 10.4800, ratio: 0.2087\n",
            "#94: episode_reward:-13.1189 acc: 13.2000, ratio: 0.2415\n",
            "#95: episode_reward:-11.1121 acc: 27.6000, ratio: 0.3053\n",
            "#96: episode_reward:-12.7094 acc: 17.6000, ratio: 0.3293\n",
            "#97: episode_reward:-13.5930 acc: 12.4800, ratio: 0.3666\n",
            "#98: episode_reward:-13.7653 acc: 10.7400, ratio: 0.3285\n",
            "#99: episode_reward:-12.6162 acc: 17.0600, ratio: 0.2662\n",
            "#100: episode_reward:-13.1341 acc: 15.0400, ratio: 0.3411\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-11.2092 acc: 28.5000, ratio: 0.4242\n",
            "#102: episode_reward:-13.4401 acc: 14.9600, ratio: 0.4818\n",
            "#103: episode_reward:-13.8225 acc: 10.0800, ratio: 0.3126\n",
            "#104: episode_reward:-12.7368 acc: 18.0400, ratio: 0.3699\n",
            "#105: episode_reward:-11.9642 acc: 22.8600, ratio: 0.3588\n",
            "#106: episode_reward:-10.9927 acc: 31.4000, ratio: 0.6003\n",
            "#107: episode_reward:-13.6522 acc: 14.4600, ratio: 0.5629\n",
            "#108: episode_reward:-8.6690 acc: 45.7000, ratio: 0.5657\n",
            "#109: episode_reward:-10.1195 acc: 35.7600, ratio: 0.4575\n",
            "#110: episode_reward:-12.3619 acc: 20.4000, ratio: 0.3661\n",
            "#111: episode_reward:-8.6818 acc: 45.9200, ratio: 0.6181\n",
            "#112: episode_reward:-9.1400 acc: 42.9600, ratio: 0.6000\n",
            "#113: episode_reward:-10.3328 acc: 36.0800, ratio: 0.6910\n",
            "#114: episode_reward:-8.5272 acc: 47.0400, ratio: 0.6482\n",
            "\u001b[92m New best reward: -6.1421, acc: 61.8000, compress: 0.6339\u001b[00m\n",
            "\u001b[92m New best policy: [0.9917359054455178, 0.6421948132774807, 0.7012496852104925, 0.9296126508747656, 0.8081873894456064, 0.8464047995680072, 0.9777233003866976, 0.8351867326059819, 0.8149404200261525]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [508, 329, 360, 238, 207, 109, 126, 54, 27]\u001b[00m\n",
            "#115: episode_reward:-6.1421 acc: 61.8000, ratio: 0.6339\n",
            "New best clamped policy: [0.9917359054455178, 0.6421948132774807, 0.7012496852104925, 0.9296126508747656, 0.8081873894456064, 0.8464047995680072, 0.9777233003866976, 0.8351867326059819, 0.8149404200261525]\n",
            "#116: episode_reward:-9.0606 acc: 44.2000, ratio: 0.7430\n",
            "\u001b[92m New best reward: -5.0371, acc: 68.5200, compress: 0.5865\u001b[00m\n",
            "\u001b[92m New best policy: [0.7183824288159938, 0.6356161052185202, 0.7215535807208032, 0.8263074413984476, 0.8807138312046651, 0.9134867396623279, 0.9090101246585895, 0.8878492970136, 0.9189871709086957]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [368, 326, 370, 212, 226, 117, 117, 57, 30]\u001b[00m\n",
            "#117: episode_reward:-5.0371 acc: 68.5200, ratio: 0.5865\n",
            "New best clamped policy: [0.7183824288159938, 0.6356161052185202, 0.7215535807208032, 0.8263074413984476, 0.8807138312046651, 0.9134867396623279, 0.9090101246585895, 0.8878492970136, 0.9189871709086957]\n",
            "#118: episode_reward:-5.3973 acc: 66.8600, ratio: 0.7801\n",
            "#119: episode_reward:-6.4380 acc: 60.6400, ratio: 0.8370\n",
            "\u001b[92m New best reward: -4.5287, acc: 72.1400, compress: 0.7561\u001b[00m\n",
            "\u001b[92m New best policy: [0.7799560729876194, 0.8253459468977582, 0.966962603458319, 0.8069278224564073, 0.8703111507769467, 0.9647398493144639, 0.9636941926617929, 0.7326350441873845, 0.8460992487202633]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [400, 423, 496, 207, 223, 124, 124, 47, 28]\u001b[00m\n",
            "#120: episode_reward:-4.5287 acc: 72.1400, ratio: 0.7561\n",
            "New best clamped policy: [0.7799560729876194, 0.8253459468977582, 0.966962603458319, 0.8069278224564073, 0.8703111507769467, 0.9647398493144639, 0.9636941926617929, 0.7326350441873845, 0.8460992487202633]\n",
            "#121: episode_reward:-5.5749 acc: 65.3800, ratio: 0.6494\n",
            "#122: episode_reward:-6.9182 acc: 57.1800, ratio: 0.6850\n",
            "#123: episode_reward:-5.9196 acc: 63.7000, ratio: 0.7968\n",
            "\u001b[92m New best reward: -3.5903, acc: 78.0800, compress: 0.8559\u001b[00m\n",
            "\u001b[92m New best policy: [0.9579979353493951, 0.9131420093156024, 0.9901389224960496, 0.7834180838432864, 0.9479065010141938, 0.9285093485968786, 0.9598554707020347, 0.7449283318185521, 0.998227588993929]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [491, 468, 507, 201, 243, 119, 123, 48, 31]\u001b[00m\n",
            "#124: episode_reward:-3.5903 acc: 78.0800, ratio: 0.8559\n",
            "New best clamped policy: [0.9579979353493951, 0.9131420093156024, 0.9901389224960496, 0.7834180838432864, 0.9479065010141938, 0.9285093485968786, 0.9598554707020347, 0.7449283318185521, 0.998227588993929]\n",
            "\u001b[92m New best reward: -3.0027, acc: 81.7000, compress: 0.8811\u001b[00m\n",
            "\u001b[92m New best policy: [0.8619174035550148, 0.9773330376780732, 0.9924505153587361, 0.863593915347571, 0.8934727431247595, 0.8596612897560709, 0.9125637505426442, 0.9225525162394235, 0.9850069721111298]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [442, 501, 509, 222, 229, 111, 117, 60, 31]\u001b[00m\n",
            "#125: episode_reward:-3.0027 acc: 81.7000, ratio: 0.8811\n",
            "New best clamped policy: [0.8619174035550148, 0.9773330376780732, 0.9924505153587361, 0.863593915347571, 0.8934727431247595, 0.8596612897560709, 0.9125637505426442, 0.9225525162394235, 0.9850069721111298]\n",
            "#126: episode_reward:-3.1636 acc: 80.7000, ratio: 0.8667\n",
            "#127: episode_reward:-6.0809 acc: 62.4000, ratio: 0.6961\n",
            "#128: episode_reward:-3.8760 acc: 76.3200, ratio: 0.8467\n",
            "#129: episode_reward:-4.5008 acc: 72.5200, ratio: 0.8552\n",
            "#130: episode_reward:-4.1982 acc: 74.3200, ratio: 0.8297\n",
            "#131: episode_reward:-3.6221 acc: 77.7600, ratio: 0.7802\n",
            "\u001b[92m New best reward: -2.7142, acc: 83.4800, compress: 0.9004\u001b[00m\n",
            "\u001b[92m New best policy: [0.9962590899259551, 0.9944052332236325, 0.8454727881459556, 0.9808259239863834, 0.984636545674067, 0.9739140140042365, 0.8389437581010756, 0.9266896913462491, 0.9348828620947544]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 510, 433, 252, 253, 125, 108, 60, 30]\u001b[00m\n",
            "#132: episode_reward:-2.7142 acc: 83.4800, ratio: 0.9004\n",
            "New best clamped policy: [0.9962590899259551, 0.9944052332236325, 0.8454727881459556, 0.9808259239863834, 0.984636545674067, 0.9739140140042365, 0.8389437581010756, 0.9266896913462491, 0.9348828620947544]\n",
            "#133: episode_reward:-3.2318 acc: 80.1800, ratio: 0.7955\n",
            "#134: episode_reward:-3.3937 acc: 79.2400, ratio: 0.8293\n",
            "\u001b[92m New best reward: -2.5708, acc: 84.3600, compress: 0.9071\u001b[00m\n",
            "\u001b[92m New best policy: [0.9790154245166517, 0.966216258175842, 0.8989464423955915, 0.9504066916793629, 0.9420100587175035, 0.9283065860634784, 0.9743059410588883, 0.9767410406911226, 0.9440979882531378]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [502, 495, 461, 244, 242, 119, 125, 63, 31]\u001b[00m\n",
            "#135: episode_reward:-2.5708 acc: 84.3600, ratio: 0.9071\n",
            "New best clamped policy: [0.9790154245166517, 0.966216258175842, 0.8989464423955915, 0.9504066916793629, 0.9420100587175035, 0.9283065860634784, 0.9743059410588883, 0.9767410406911226, 0.9440979882531378]\n",
            "#136: episode_reward:-3.3857 acc: 79.3400, ratio: 0.8635\n",
            "#137: episode_reward:-2.7067 acc: 83.5200, ratio: 0.8953\n",
            "#138: episode_reward:-2.6339 acc: 83.9600, ratio: 0.8926\n",
            "#139: episode_reward:-2.8353 acc: 82.6600, ratio: 0.8322\n",
            "\u001b[92m New best reward: -2.4599, acc: 85.0600, compress: 0.9327\u001b[00m\n",
            "\u001b[92m New best policy: [0.9636407531372865, 0.93413258695247, 0.9995013002759068, 0.9657861384935755, 0.9989132403983779, 0.9375395372939588, 0.9587661977805269, 0.9586445218567761, 0.9515433707365251]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [494, 479, 511, 248, 255, 121, 123, 62, 31]\u001b[00m\n",
            "#140: episode_reward:-2.4599 acc: 85.0600, ratio: 0.9327\n",
            "New best clamped policy: [0.9636407531372865, 0.93413258695247, 0.9995013002759068, 0.9657861384935755, 0.9989132403983779, 0.9375395372939588, 0.9587661977805269, 0.9586445218567761, 0.9515433707365251]\n",
            "#141: episode_reward:-2.4723 acc: 84.9800, ratio: 0.9282\n",
            "#142: episode_reward:-2.7091 acc: 83.5400, ratio: 0.9270\n",
            "\u001b[92m New best reward: -2.4318, acc: 85.2400, compress: 0.9428\u001b[00m\n",
            "\u001b[92m New best policy: [0.9990166597653938, 0.9703005991478866, 0.9323162615722131, 0.9893854487397972, 0.9912219538821543, 0.9568606858651967, 0.9943469151488941, 0.9509702777094777, 0.9898954988159733]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 497, 478, 254, 254, 123, 127, 61, 31]\u001b[00m\n",
            "#143: episode_reward:-2.4318 acc: 85.2400, ratio: 0.9428\n",
            "New best clamped policy: [0.9990166597653938, 0.9703005991478866, 0.9323162615722131, 0.9893854487397972, 0.9912219538821543, 0.9568606858651967, 0.9943469151488941, 0.9509702777094777, 0.9898954988159733]\n",
            "#144: episode_reward:-2.6696 acc: 83.7600, ratio: 0.9081\n",
            "#145: episode_reward:-2.5954 acc: 84.1800, ratio: 0.8791\n",
            "#146: episode_reward:-2.4752 acc: 84.9800, ratio: 0.9463\n",
            "#147: episode_reward:-2.6156 acc: 84.1200, ratio: 0.9384\n",
            "#148: episode_reward:-2.8651 acc: 82.6000, ratio: 0.9339\n",
            "#149: episode_reward:-2.5352 acc: 84.6200, ratio: 0.9501\n",
            "\u001b[92m New best reward: -2.3995, acc: 85.4600, compress: 0.9687\u001b[00m\n",
            "\u001b[92m New best policy: [0.9772097265554139, 0.9835449533359908, 0.9846495485615474, 0.9927179043890516, 0.9489802287826589, 0.9961172250188287, 0.995514201741362, 0.9894345665577751, 0.9506288772240713]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 504, 505, 255, 243, 127, 127, 63, 31]\u001b[00m\n",
            "#150: episode_reward:-2.3995 acc: 85.4600, ratio: 0.9687\n",
            "New best clamped policy: [0.9772097265554139, 0.9835449533359908, 0.9846495485615474, 0.9927179043890516, 0.9489802287826589, 0.9961172250188287, 0.995514201741362, 0.9894345665577751, 0.9506288772240713]\n",
            "#151: episode_reward:-2.4087 acc: 85.4000, ratio: 0.9641\n",
            "\u001b[92m New best reward: -2.3884, acc: 85.5000, compress: 0.9388\u001b[00m\n",
            "\u001b[92m New best policy: [0.9586701184965094, 0.9723778934881622, 0.9478617378224645, 0.9818540541921748, 0.9916959880740503, 0.9566592955566435, 0.9757221793943389, 0.9831276019145924, 0.9573916238487262]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [491, 498, 486, 252, 254, 123, 125, 63, 31]\u001b[00m\n",
            "#152: episode_reward:-2.3884 acc: 85.5000, ratio: 0.9388\n",
            "New best clamped policy: [0.9586701184965094, 0.9723778934881622, 0.9478617378224645, 0.9818540541921748, 0.9916959880740503, 0.9566592955566435, 0.9757221793943389, 0.9831276019145924, 0.9573916238487262]\n",
            "#153: episode_reward:-2.4465 acc: 85.1600, ratio: 0.9525\n",
            "#154: episode_reward:-2.5234 acc: 84.7000, ratio: 0.9591\n",
            "#155: episode_reward:-2.5065 acc: 84.8000, ratio: 0.9565\n",
            "\u001b[92m New best reward: -2.3789, acc: 85.5800, compress: 0.9633\u001b[00m\n",
            "\u001b[92m New best policy: [0.992361796941764, 0.9827295221721555, 0.9547643747879843, 0.9976790783539013, 0.9790394815041139, 0.9967013661712579, 0.991849761786991, 0.9999561571725373, 0.9902829158123267]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [509, 504, 489, 255, 251, 127, 127, 63, 31]\u001b[00m\n",
            "#156: episode_reward:-2.3789 acc: 85.5800, ratio: 0.9633\n",
            "New best clamped policy: [0.992361796941764, 0.9827295221721555, 0.9547643747879843, 0.9976790783539013, 0.9790394815041139, 0.9967013661712579, 0.991849761786991, 0.9999561571725373, 0.9902829158123267]\n",
            "#157: episode_reward:-2.5747 acc: 84.3600, ratio: 0.9299\n",
            "\u001b[92m New best reward: -2.3671, acc: 85.6400, compress: 0.9504\u001b[00m\n",
            "\u001b[92m New best policy: [0.9497849402995532, 0.9519057485055181, 0.9940721514004858, 0.9895246387944098, 0.9840592708114032, 0.9890501184372209, 0.9942255380772371, 0.969864545101939, 0.9442519515910397]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 488, 509, 254, 252, 127, 127, 63, 31]\u001b[00m\n",
            "#158: episode_reward:-2.3671 acc: 85.6400, ratio: 0.9504\n",
            "New best clamped policy: [0.9497849402995532, 0.9519057485055181, 0.9940721514004858, 0.9895246387944098, 0.9840592708114032, 0.9890501184372209, 0.9942255380772371, 0.969864545101939, 0.9442519515910397]\n",
            "#159: episode_reward:-2.4523 acc: 85.1400, ratio: 0.9684\n",
            "#160: episode_reward:-2.4103 acc: 85.3800, ratio: 0.9529\n",
            "#161: episode_reward:-2.4774 acc: 84.9800, ratio: 0.9600\n",
            "#162: episode_reward:-2.3935 acc: 85.4800, ratio: 0.9505\n",
            "\u001b[92m New best reward: -2.3393, acc: 85.8400, compress: 0.9859\u001b[00m\n",
            "\u001b[92m New best policy: [0.9975920796192225, 0.9969779888278875, 0.9899989290999324, 0.9810467999520064, 0.994394182781121, 0.9851994218491926, 0.9846237436164832, 0.9777832825661464, 0.9718890172906239]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 511, 507, 252, 255, 127, 127, 63, 31]\u001b[00m\n",
            "#163: episode_reward:-2.3393 acc: 85.8400, ratio: 0.9859\n",
            "New best clamped policy: [0.9975920796192225, 0.9969779888278875, 0.9899989290999324, 0.9810467999520064, 0.994394182781121, 0.9851994218491926, 0.9846237436164832, 0.9777832825661464, 0.9718890172906239]\n",
            "#164: episode_reward:-2.5165 acc: 84.7600, ratio: 0.9781\n",
            "#165: episode_reward:-2.5935 acc: 84.2800, ratio: 0.9640\n",
            "#166: episode_reward:-3.0407 acc: 81.5400, ratio: 0.9392\n",
            "#167: episode_reward:-2.4869 acc: 84.9200, ratio: 0.9574\n",
            "#168: episode_reward:-2.4209 acc: 85.3200, ratio: 0.9575\n",
            "#169: episode_reward:-2.5518 acc: 84.5400, ratio: 0.9715\n",
            "#170: episode_reward:-2.5517 acc: 84.5400, ratio: 0.9706\n",
            "#171: episode_reward:-2.9049 acc: 82.3800, ratio: 0.9530\n",
            "#172: episode_reward:-2.6468 acc: 83.9600, ratio: 0.9672\n",
            "#173: episode_reward:-2.5713 acc: 84.4200, ratio: 0.9693\n",
            "#174: episode_reward:-2.4709 acc: 85.0200, ratio: 0.9607\n",
            "#175: episode_reward:-2.4590 acc: 85.1000, ratio: 0.9691\n",
            "#176: episode_reward:-2.7220 acc: 83.5000, ratio: 0.9629\n",
            "#177: episode_reward:-2.7431 acc: 83.3600, ratio: 0.9517\n",
            "#178: episode_reward:-2.7796 acc: 83.1600, ratio: 0.9716\n",
            "#179: episode_reward:-2.4697 acc: 85.0400, ratio: 0.9743\n",
            "#180: episode_reward:-2.7059 acc: 83.6000, ratio: 0.9651\n",
            "#181: episode_reward:-2.6703 acc: 83.8200, ratio: 0.9692\n",
            "#182: episode_reward:-2.4766 acc: 85.0000, ratio: 0.9763\n",
            "#183: episode_reward:-2.5844 acc: 84.3400, ratio: 0.9689\n",
            "#184: episode_reward:-2.8378 acc: 82.8000, ratio: 0.9650\n",
            "#185: episode_reward:-2.4241 acc: 85.3200, ratio: 0.9784\n",
            "#186: episode_reward:-2.5514 acc: 84.5400, ratio: 0.9690\n",
            "#187: episode_reward:-2.5445 acc: 84.5800, ratio: 0.9672\n",
            "#188: episode_reward:-2.7327 acc: 83.4400, ratio: 0.9674\n",
            "#189: episode_reward:-2.6678 acc: 83.8400, ratio: 0.9744\n",
            "#190: episode_reward:-2.5059 acc: 84.8200, ratio: 0.9734\n",
            "#191: episode_reward:-2.6480 acc: 83.9600, ratio: 0.9741\n",
            "#192: episode_reward:-2.4375 acc: 85.2400, ratio: 0.9795\n",
            "#193: episode_reward:-2.5224 acc: 84.7200, ratio: 0.9732\n",
            "#194: episode_reward:-2.7331 acc: 83.4400, ratio: 0.9700\n",
            "#195: episode_reward:-2.7006 acc: 83.6400, ratio: 0.9729\n",
            "#196: episode_reward:-2.5130 acc: 84.7800, ratio: 0.9768\n",
            "#197: episode_reward:-2.6545 acc: 83.9200, ratio: 0.9739\n",
            "#198: episode_reward:-2.5095 acc: 84.8000, ratio: 0.9754\n",
            "#199: episode_reward:-2.4249 acc: 85.3200, ratio: 0.9839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/mobilenet_amc_r0.5_ep200_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/mobilenet_amc_r0.5_ep200_search/mobilenet_amc_r0.5_ep200_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1500a2-54af-4713-ceae-86232b56b8f8",
        "id": "YhKIbHDKdHRg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Identified sensitive layers: ['features.0.0', 'features.1.0', 'features.2.0', 'features.3.0', 'features.4.0', 'features.5.0', 'features.6.0', 'features.7.0']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "=> Original model channels: [512, 512, 512, 256, 256, 128, 128, 64, 32]\n",
            "=> Pruning with ratios: [0.9975920796192225, 0.9969779888278875, 0.9899989290999324, 0.9810467999520064, 0.994394182781121, 0.9851994218491926, 0.9846237436164832, 0.9777832825661464, 0.9718890172906239]\n",
            "=> Channels after pruning: [511, 510, 507, 251, 255, 126, 126, 63, 31]\n",
            "\u001b[92m New best reward: -2.3393, acc: 85.8400, compress: 0.9859\u001b[00m\n",
            "\u001b[92m New best policy: [0.9975920796192225, 0.9969779888278875, 0.9899989290999324, 0.9810467999520064, 0.994394182781121, 0.9851994218491926, 0.9846237436164832, 0.9777832825661464, 0.9718890172906239]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 511, 507, 252, 255, 127, 127, 63, 31]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_amc_r0.5_ep200_search/mobilenet_amc_r0.5_ep200_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0efc4fa-ae2c-4e45-e911-adc172ee4a40",
        "id": "pIE-6TcKdHRh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_amc_r0.5_ep200_search/mobilenet_amc_r0.5_ep200_search.pt...\n",
            "=> Model Parameter: 0.802 M, FLOPs: 14.716M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_amc_r0.5_ep200_search/mobilenet_amc_r0.5_ep200_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training mobilenet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/mobilenet_cifar_finetune-run10\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 149ms | Tot: 23s162ms | Loss: 0.487 | Acc1: 82.876% | Acc5: 99.304% 352/352 \n",
            " [=======================================>]  Step: 53ms | Tot: 623ms | Loss: 0.412 | Acc1: 85.880% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 65ms | Tot: 23s134ms | Loss: 0.480 | Acc1: 83.122% | Acc5: 99.309% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 575ms | Loss: 0.412 | Acc1: 85.820% | Acc5: 99.380% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 8ms | Tot: 23s300ms | Loss: 0.477 | Acc1: 83.158% | Acc5: 99.296% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 608ms | Loss: 0.410 | Acc1: 85.340% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 65ms | Tot: 23s77ms | Loss: 0.476 | Acc1: 83.320% | Acc5: 99.400% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 591ms | Loss: 0.414 | Acc1: 85.440% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 65ms | Tot: 23s103ms | Loss: 0.472 | Acc1: 83.444% | Acc5: 99.402% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 561ms | Loss: 0.410 | Acc1: 85.800% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 8ms | Tot: 23s136ms | Loss: 0.468 | Acc1: 83.507% | Acc5: 99.369% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 607ms | Loss: 0.411 | Acc1: 85.700% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 8ms | Tot: 23s490ms | Loss: 0.466 | Acc1: 83.602% | Acc5: 99.382% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 707ms | Loss: 0.406 | Acc1: 85.620% | Acc5: 99.520% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 42ms | Tot: 23s469ms | Loss: 0.470 | Acc1: 83.524% | Acc5: 99.378% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 556ms | Loss: 0.410 | Acc1: 85.600% | Acc5: 99.480% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 65ms | Tot: 23s171ms | Loss: 0.459 | Acc1: 83.973% | Acc5: 99.371% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 558ms | Loss: 0.407 | Acc1: 85.800% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 66ms | Tot: 23s408ms | Loss: 0.464 | Acc1: 83.667% | Acc5: 99.424% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 578ms | Loss: 0.410 | Acc1: 85.860% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 10ms | Tot: 23s253ms | Loss: 0.457 | Acc1: 84.140% | Acc5: 99.456% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 642ms | Loss: 0.405 | Acc1: 85.740% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 65ms | Tot: 23s482ms | Loss: 0.459 | Acc1: 83.771% | Acc5: 99.400% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 560ms | Loss: 0.407 | Acc1: 85.640% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 66ms | Tot: 23s651ms | Loss: 0.455 | Acc1: 83.993% | Acc5: 99.367% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 562ms | Loss: 0.409 | Acc1: 85.460% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 9ms | Tot: 23s514ms | Loss: 0.459 | Acc1: 83.780% | Acc5: 99.413% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 583ms | Loss: 0.407 | Acc1: 85.640% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 8ms | Tot: 23s277ms | Loss: 0.451 | Acc1: 84.122% | Acc5: 99.413% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 568ms | Loss: 0.407 | Acc1: 85.580% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 8ms | Tot: 23s179ms | Loss: 0.447 | Acc1: 84.171% | Acc5: 99.449% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 562ms | Loss: 0.405 | Acc1: 85.680% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 8ms | Tot: 23s261ms | Loss: 0.454 | Acc1: 84.071% | Acc5: 99.373% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 560ms | Loss: 0.406 | Acc1: 85.860% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 8ms | Tot: 23s245ms | Loss: 0.450 | Acc1: 84.302% | Acc5: 99.476% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 575ms | Loss: 0.405 | Acc1: 85.740% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 8ms | Tot: 23s56ms | Loss: 0.448 | Acc1: 84.104% | Acc5: 99.482% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 574ms | Loss: 0.406 | Acc1: 85.740% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 73ms | Tot: 23s298ms | Loss: 0.454 | Acc1: 84.058% | Acc5: 99.380% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 563ms | Loss: 0.404 | Acc1: 85.760% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.88\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run10/ckpt.pth.tar\n",
            "=> Model Parameter: 0.802 M, FLOPs: 14.716M, best top-1 acc: 85.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_finetune-run10', 'mobilenet_amc_r0.5_ep200_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx97VDZkdHRh",
        "outputId": "cdbb3774-0b09-4721-98e6-467cbf1ce63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/mobilenet_cifar_finetune-run10 to mobilenet_amc_r0.5_ep200_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMC, rbound=0.8"
      ],
      "metadata": {
        "id": "rO7SNN3h0T1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=train \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --rbound=0.8 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=300 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --init_delta=1.0 \\\n",
        "    --delta_decay=0.99 \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --seed=10000 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3OKlX_q0VSI",
        "outputId": "b19458e5-c236-4217-a1e4-0baada4bb7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "=> Saving logs to ./logs/mobilenet_cifar_amc_r0.5_ep300_search-run9\n",
            "=> Output path: ./logs/mobilenet_cifar_amc_r0.5_ep300_search-run9...\n",
            "** Actual replay buffer size: 900\n",
            "\u001b[92m New best reward: -10.2873, acc: 35.3600, compress: 0.5380\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.6212741278231493, 0.8, 0.7946774141029013, 0.8, 0.8, 0.41936359483482594, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 319, 410, 204, 205, 103, 54, 52, 26]\u001b[00m\n",
            "#0: episode_reward:-10.2873 acc: 35.3600, ratio: 0.5380\n",
            "New best clamped policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-13.5252 acc: 11.5800, ratio: 0.2899\n",
            "#2: episode_reward:-13.3817 acc: 12.3400, ratio: 0.2811\n",
            "#3: episode_reward:-13.2397 acc: 14.8800, ratio: 0.3751\n",
            "#4: episode_reward:-13.3938 acc: 11.7600, ratio: 0.2577\n",
            "#5: episode_reward:-11.7417 acc: 23.3800, ratio: 0.2982\n",
            "#6: episode_reward:-13.3599 acc: 15.3000, ratio: 0.4669\n",
            "#7: episode_reward:-11.6375 acc: 23.9000, ratio: 0.2887\n",
            "#8: episode_reward:-13.3800 acc: 10.6400, ratio: 0.2098\n",
            "#9: episode_reward:-13.1443 acc: 15.8600, ratio: 0.4014\n",
            "#10: episode_reward:-13.1143 acc: 16.2000, ratio: 0.4126\n",
            "#11: episode_reward:-13.5504 acc: 12.8600, ratio: 0.3736\n",
            "#12: episode_reward:-13.1156 acc: 14.0400, ratio: 0.2789\n",
            "#13: episode_reward:-12.6530 acc: 19.0400, ratio: 0.4041\n",
            "#14: episode_reward:-13.0113 acc: 17.3200, ratio: 0.4503\n",
            "#15: episode_reward:-13.7082 acc: 10.5800, ratio: 0.2998\n",
            "#16: episode_reward:-12.7763 acc: 15.9800, ratio: 0.2649\n",
            "#17: episode_reward:-13.2412 acc: 11.1800, ratio: 0.1966\n",
            "#18: episode_reward:-13.2448 acc: 13.0400, ratio: 0.2715\n",
            "#19: episode_reward:-13.6649 acc: 11.5600, ratio: 0.3384\n",
            "#20: episode_reward:-12.9681 acc: 15.1600, ratio: 0.2867\n",
            "#21: episode_reward:-13.5995 acc: 11.3600, ratio: 0.3035\n",
            "#22: episode_reward:-13.0222 acc: 13.6400, ratio: 0.2332\n",
            "#23: episode_reward:-13.2739 acc: 12.3000, ratio: 0.2468\n",
            "#24: episode_reward:-13.5733 acc: 11.6600, ratio: 0.3104\n",
            "#25: episode_reward:-13.3355 acc: 12.7800, ratio: 0.2879\n",
            "#26: episode_reward:-13.4707 acc: 11.9600, ratio: 0.2911\n",
            "#27: episode_reward:-13.4187 acc: 10.9000, ratio: 0.2289\n",
            "#28: episode_reward:-12.1042 acc: 20.3200, ratio: 0.2609\n",
            "#29: episode_reward:-14.0215 acc: 10.7000, ratio: 0.4347\n",
            "#30: episode_reward:-13.6934 acc: 10.5800, ratio: 0.2949\n",
            "#31: episode_reward:-13.7986 acc: 10.6000, ratio: 0.3328\n",
            "#32: episode_reward:-13.5185 acc: 10.6000, ratio: 0.2433\n",
            "#33: episode_reward:-13.9724 acc: 10.9000, ratio: 0.4261\n",
            "#34: episode_reward:-13.8809 acc: 12.1800, ratio: 0.4826\n",
            "#35: episode_reward:-13.9177 acc: 10.3000, ratio: 0.3610\n",
            "#36: episode_reward:-13.3425 acc: 10.5000, ratio: 0.1965\n",
            "#37: episode_reward:-13.3579 acc: 13.1200, ratio: 0.3136\n",
            "#38: episode_reward:-13.7766 acc: 10.4600, ratio: 0.3170\n",
            "#39: episode_reward:-12.1488 acc: 20.6000, ratio: 0.2911\n",
            "#40: episode_reward:-13.3510 acc: 12.6200, ratio: 0.2849\n",
            "#41: episode_reward:-13.6250 acc: 11.7000, ratio: 0.3314\n",
            "#42: episode_reward:-13.3433 acc: 12.0800, ratio: 0.2571\n",
            "#43: episode_reward:-12.7781 acc: 13.7400, ratio: 0.1788\n",
            "#44: episode_reward:-12.6712 acc: 15.3600, ratio: 0.2093\n",
            "#45: episode_reward:-12.7239 acc: 18.3800, ratio: 0.3885\n",
            "#46: episode_reward:-12.5014 acc: 17.5600, ratio: 0.2540\n",
            "#47: episode_reward:-13.2058 acc: 13.0800, ratio: 0.2614\n",
            "#48: episode_reward:-12.8522 acc: 15.9000, ratio: 0.2857\n",
            "#49: episode_reward:-12.7305 acc: 18.8800, ratio: 0.4312\n",
            "#50: episode_reward:-13.4371 acc: 10.6000, ratio: 0.2221\n",
            "#51: episode_reward:-13.0776 acc: 13.9600, ratio: 0.2631\n",
            "#52: episode_reward:-13.8890 acc: 9.3600, ratio: 0.2978\n",
            "#53: episode_reward:-13.7416 acc: 9.4800, ratio: 0.2582\n",
            "#54: episode_reward:-12.2282 acc: 19.8600, ratio: 0.2791\n",
            "#55: episode_reward:-13.7014 acc: 9.3000, ratio: 0.2397\n",
            "#56: episode_reward:-13.9401 acc: 10.9400, ratio: 0.4139\n",
            "#57: episode_reward:-13.7604 acc: 10.4800, ratio: 0.3124\n",
            "#58: episode_reward:-13.7253 acc: 10.4800, ratio: 0.3004\n",
            "#59: episode_reward:-13.2321 acc: 13.2400, ratio: 0.2771\n",
            "#60: episode_reward:-12.5161 acc: 18.0000, ratio: 0.2805\n",
            "#61: episode_reward:-12.9414 acc: 15.6000, ratio: 0.3008\n",
            "#62: episode_reward:-13.9088 acc: 10.6000, ratio: 0.3765\n",
            "#63: episode_reward:-11.9724 acc: 22.6000, ratio: 0.3442\n",
            "#64: episode_reward:-12.2660 acc: 20.9400, ratio: 0.3606\n",
            "#65: episode_reward:-13.6052 acc: 10.5200, ratio: 0.2645\n",
            "#66: episode_reward:-13.6605 acc: 10.6000, ratio: 0.2852\n",
            "#67: episode_reward:-12.9041 acc: 17.4800, ratio: 0.4077\n",
            "#68: episode_reward:-13.7823 acc: 10.4200, ratio: 0.3169\n",
            "#69: episode_reward:-12.5805 acc: 17.6400, ratio: 0.2837\n",
            "#70: episode_reward:-14.0810 acc: 10.6600, ratio: 0.4614\n",
            "#71: episode_reward:-13.0970 acc: 14.6600, ratio: 0.3049\n",
            "#72: episode_reward:-13.6194 acc: 11.7800, ratio: 0.3339\n",
            "#73: episode_reward:-12.8457 acc: 15.8800, ratio: 0.2825\n",
            "#74: episode_reward:-12.8148 acc: 16.5600, ratio: 0.3083\n",
            "#75: episode_reward:-13.0543 acc: 16.8200, ratio: 0.4314\n",
            "#76: episode_reward:-13.3216 acc: 13.0200, ratio: 0.2955\n",
            "#77: episode_reward:-13.6539 acc: 10.1000, ratio: 0.2600\n",
            "#78: episode_reward:-11.9665 acc: 21.4800, ratio: 0.2740\n",
            "#79: episode_reward:-13.7531 acc: 10.6800, ratio: 0.3207\n",
            "#80: episode_reward:-13.5249 acc: 13.8200, ratio: 0.4313\n",
            "#81: episode_reward:-13.1209 acc: 13.3200, ratio: 0.2472\n",
            "#82: episode_reward:-12.2486 acc: 18.9200, ratio: 0.2398\n",
            "#83: episode_reward:-13.2046 acc: 12.8800, ratio: 0.2521\n",
            "#84: episode_reward:-13.6272 acc: 10.6200, ratio: 0.2757\n",
            "#85: episode_reward:-12.4748 acc: 18.2200, ratio: 0.2778\n",
            "#86: episode_reward:-13.8432 acc: 11.8400, ratio: 0.4350\n",
            "#87: episode_reward:-13.8434 acc: 13.2000, ratio: 0.5565\n",
            "#88: episode_reward:-13.1281 acc: 13.4600, ratio: 0.2554\n",
            "#89: episode_reward:-13.9738 acc: 11.6400, ratio: 0.4867\n",
            "#90: episode_reward:-13.8702 acc: 10.7400, ratio: 0.3695\n",
            "#91: episode_reward:-13.0437 acc: 15.2400, ratio: 0.3180\n",
            "#92: episode_reward:-14.0058 acc: 10.7200, ratio: 0.4286\n",
            "#93: episode_reward:-13.3368 acc: 10.4800, ratio: 0.1946\n",
            "#94: episode_reward:-13.1861 acc: 12.4200, ratio: 0.2279\n",
            "#95: episode_reward:-11.9153 acc: 21.2800, ratio: 0.2470\n",
            "#96: episode_reward:-13.1199 acc: 13.7400, ratio: 0.2658\n",
            "#97: episode_reward:-13.6916 acc: 10.9000, ratio: 0.3109\n",
            "#98: episode_reward:-13.6867 acc: 10.8400, ratio: 0.3060\n",
            "#99: episode_reward:-12.3718 acc: 18.2000, ratio: 0.2441\n",
            "#100: episode_reward:-13.1124 acc: 13.9600, ratio: 0.2739\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-12.4510 acc: 20.2400, ratio: 0.3969\n",
            "#102: episode_reward:-13.8384 acc: 10.9000, ratio: 0.3666\n",
            "#103: episode_reward:-13.5043 acc: 11.0600, ratio: 0.2589\n",
            "#104: episode_reward:-13.3931 acc: 12.4600, ratio: 0.2907\n",
            "#105: episode_reward:-12.9324 acc: 15.3200, ratio: 0.2829\n",
            "#106: episode_reward:-13.6360 acc: 12.9600, ratio: 0.4197\n",
            "#107: episode_reward:-14.0069 acc: 10.3200, ratio: 0.4001\n",
            "#108: episode_reward:-11.5346 acc: 25.4600, ratio: 0.3463\n",
            "#109: episode_reward:-12.8263 acc: 15.0000, ratio: 0.2357\n",
            "#110: episode_reward:-13.6273 acc: 10.8600, ratio: 0.2873\n",
            "#111: episode_reward:-13.7414 acc: 10.8600, ratio: 0.3266\n",
            "#112: episode_reward:-13.3297 acc: 12.5000, ratio: 0.2723\n",
            "#113: episode_reward:-13.8470 acc: 10.7400, ratio: 0.3600\n",
            "#114: episode_reward:-13.4651 acc: 11.5800, ratio: 0.2708\n",
            "#115: episode_reward:-12.8050 acc: 14.9800, ratio: 0.2291\n",
            "#116: episode_reward:-13.7244 acc: 12.2800, ratio: 0.4111\n",
            "#117: episode_reward:-13.0325 acc: 14.2200, ratio: 0.2614\n",
            "#118: episode_reward:-14.1249 acc: 9.1800, ratio: 0.3745\n",
            "#119: episode_reward:-14.1236 acc: 10.0200, ratio: 0.4324\n",
            "#120: episode_reward:-13.7797 acc: 10.2400, ratio: 0.3064\n",
            "#121: episode_reward:-13.4076 acc: 10.9800, ratio: 0.2292\n",
            "#122: episode_reward:-13.3802 acc: 11.2200, ratio: 0.2314\n",
            "#123: episode_reward:-13.8357 acc: 10.3000, ratio: 0.3294\n",
            "#124: episode_reward:-13.6726 acc: 13.0000, ratio: 0.4408\n",
            "#125: episode_reward:-12.3553 acc: 21.5000, ratio: 0.4514\n",
            "#126: episode_reward:-13.2806 acc: 15.7600, ratio: 0.4632\n",
            "#127: episode_reward:-13.2506 acc: 13.4000, ratio: 0.2912\n",
            "#128: episode_reward:-14.1150 acc: 9.2600, ratio: 0.3756\n",
            "#129: episode_reward:-13.5670 acc: 12.2000, ratio: 0.3387\n",
            "#130: episode_reward:-13.6775 acc: 10.5200, ratio: 0.2867\n",
            "#131: episode_reward:-13.1705 acc: 14.0800, ratio: 0.2994\n",
            "#132: episode_reward:-13.6733 acc: 12.1200, ratio: 0.3769\n",
            "#133: episode_reward:-11.6638 acc: 23.5000, ratio: 0.2758\n",
            "#134: episode_reward:-13.2871 acc: 11.0800, ratio: 0.2035\n",
            "#135: episode_reward:-12.4524 acc: 20.5600, ratio: 0.4234\n",
            "#136: episode_reward:-13.4431 acc: 10.4800, ratio: 0.2192\n",
            "#137: episode_reward:-12.5214 acc: 18.9000, ratio: 0.3344\n",
            "#138: episode_reward:-12.6856 acc: 16.5200, ratio: 0.2622\n",
            "#139: episode_reward:-13.4069 acc: 11.6000, ratio: 0.2545\n",
            "#140: episode_reward:-13.0332 acc: 16.6000, ratio: 0.4036\n",
            "#141: episode_reward:-13.2408 acc: 14.4800, ratio: 0.3492\n",
            "#142: episode_reward:-12.1713 acc: 21.8000, ratio: 0.3789\n",
            "#143: episode_reward:-11.1040 acc: 29.2400, ratio: 0.4307\n",
            "#144: episode_reward:-13.4846 acc: 11.0000, ratio: 0.2507\n",
            "#145: episode_reward:-13.3612 acc: 12.1800, ratio: 0.2670\n",
            "#146: episode_reward:-13.8401 acc: 11.9000, ratio: 0.4381\n",
            "#147: episode_reward:-13.7366 acc: 10.9000, ratio: 0.3270\n",
            "#148: episode_reward:-13.8144 acc: 10.6000, ratio: 0.3388\n",
            "#149: episode_reward:-13.5190 acc: 12.5400, ratio: 0.3405\n",
            "#150: episode_reward:-13.3571 acc: 16.1600, ratio: 0.5471\n",
            "#151: episode_reward:-13.5157 acc: 14.7600, ratio: 0.5073\n",
            "#152: episode_reward:-13.0131 acc: 14.4200, ratio: 0.2648\n",
            "#153: episode_reward:-13.6799 acc: 11.4600, ratio: 0.3382\n",
            "#154: episode_reward:-13.4880 acc: 13.7800, ratio: 0.4102\n",
            "#155: episode_reward:-13.6756 acc: 11.5000, ratio: 0.3389\n",
            "#156: episode_reward:-11.0892 acc: 29.1600, ratio: 0.4144\n",
            "#157: episode_reward:-13.5654 acc: 11.1800, ratio: 0.2831\n",
            "#158: episode_reward:-13.9284 acc: 9.0600, ratio: 0.2956\n",
            "#159: episode_reward:-12.6853 acc: 18.6400, ratio: 0.3894\n",
            "#160: episode_reward:-13.5592 acc: 10.2200, ratio: 0.2388\n",
            "#161: episode_reward:-12.9706 acc: 16.0000, ratio: 0.3350\n",
            "#162: episode_reward:-12.8459 acc: 15.5000, ratio: 0.2638\n",
            "\u001b[92m New best reward: -9.1255, acc: 42.9800, compress: 0.5882\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.7562306869781501, 0.6083210550349538, 0.8, 0.8, 0.7606766869204105, 0.7186741434193439, 0.5796041953125141]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 410, 388, 156, 205, 103, 98, 46, 19]\u001b[00m\n",
            "#163: episode_reward:-9.1255 acc: 42.9800, ratio: 0.5882\n",
            "New best clamped policy: [0.9430119173348027, 0.9264931488313041, 0.7562306869781501, 0.6083210550349538, 0.8906797562215073, 0.8304701806871335, 0.7606766869204105, 0.7186741434193439, 0.5796041953125141]\n",
            "#164: episode_reward:-13.4836 acc: 15.2000, ratio: 0.5304\n",
            "#165: episode_reward:-13.4471 acc: 15.2200, ratio: 0.5099\n",
            "#166: episode_reward:-13.4814 acc: 11.7000, ratio: 0.2817\n",
            "#167: episode_reward:-13.5566 acc: 11.0400, ratio: 0.2737\n",
            "#168: episode_reward:-12.1891 acc: 21.5800, ratio: 0.3711\n",
            "#169: episode_reward:-13.8001 acc: 13.2200, ratio: 0.5313\n",
            "#170: episode_reward:-13.2912 acc: 15.9400, ratio: 0.4852\n",
            "#171: episode_reward:-13.7112 acc: 12.3000, ratio: 0.4064\n",
            "\u001b[92m New best reward: -7.7110, acc: 51.7800, compress: 0.5807\u001b[00m\n",
            "\u001b[92m New best policy: [0.7146885173974674, 0.8, 0.8, 0.6110588817114271, 0.6377235347188343, 0.8, 0.7085908773992106, 0.8, 0.7802590598542494]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [366, 410, 410, 157, 164, 103, 91, 52, 25]\u001b[00m\n",
            "#172: episode_reward:-7.7110 acc: 51.7800, ratio: 0.5807\n",
            "New best clamped policy: [0.7146885173974674, 0.8694720723948591, 0.9347539433148125, 0.6110588817114271, 0.6377235347188343, 0.8604471979183276, 0.7085908773992106, 0.9381906477965113, 0.7802590598542494]\n",
            "#173: episode_reward:-12.9123 acc: 18.5000, ratio: 0.5009\n",
            "#174: episode_reward:-13.3513 acc: 12.4000, ratio: 0.2743\n",
            "#175: episode_reward:-10.3838 acc: 33.5200, ratio: 0.4004\n",
            "#176: episode_reward:-14.0494 acc: 10.7200, ratio: 0.4500\n",
            "#177: episode_reward:-13.7039 acc: 10.0000, ratio: 0.2703\n",
            "#178: episode_reward:-13.6387 acc: 14.7400, ratio: 0.5839\n",
            "#179: episode_reward:-13.9222 acc: 11.0800, ratio: 0.4157\n",
            "#180: episode_reward:-12.2868 acc: 20.6000, ratio: 0.3464\n",
            "#181: episode_reward:-9.2461 acc: 41.4800, ratio: 0.4796\n",
            "#182: episode_reward:-10.1924 acc: 36.0400, ratio: 0.5492\n",
            "#183: episode_reward:-12.7984 acc: 16.8400, ratio: 0.3183\n",
            "#184: episode_reward:-13.6534 acc: 13.8000, ratio: 0.4988\n",
            "#185: episode_reward:-11.0788 acc: 30.7600, ratio: 0.5862\n",
            "#186: episode_reward:-12.7520 acc: 16.0000, ratio: 0.2583\n",
            "#187: episode_reward:-13.2167 acc: 13.8200, ratio: 0.3016\n",
            "#188: episode_reward:-12.9965 acc: 17.2400, ratio: 0.4357\n",
            "#189: episode_reward:-7.9269 acc: 50.2600, ratio: 0.5499\n",
            "#190: episode_reward:-9.0870 acc: 41.7200, ratio: 0.3895\n",
            "#191: episode_reward:-11.2531 acc: 29.7200, ratio: 0.5928\n",
            "#192: episode_reward:-12.8572 acc: 18.2000, ratio: 0.4418\n",
            "#193: episode_reward:-12.8179 acc: 16.4800, ratio: 0.3050\n",
            "#194: episode_reward:-11.6772 acc: 26.7200, ratio: 0.5490\n",
            "#195: episode_reward:-8.8581 acc: 44.2800, ratio: 0.5288\n",
            "#196: episode_reward:-12.8993 acc: 17.9200, ratio: 0.4408\n",
            "#197: episode_reward:-11.0304 acc: 28.7200, ratio: 0.3465\n",
            "#198: episode_reward:-10.2573 acc: 34.8000, ratio: 0.4481\n",
            "#199: episode_reward:-8.6680 acc: 45.2400, ratio: 0.4938\n",
            "#200: episode_reward:-14.2791 acc: 10.4400, ratio: 0.5537\n",
            "#201: episode_reward:-10.2714 acc: 35.3600, ratio: 0.5249\n",
            "#202: episode_reward:-11.8993 acc: 23.1000, ratio: 0.3461\n",
            "#203: episode_reward:-12.2199 acc: 22.0000, ratio: 0.4197\n",
            "#204: episode_reward:-12.9033 acc: 19.3400, ratio: 0.5841\n",
            "#205: episode_reward:-12.1807 acc: 23.3200, ratio: 0.5222\n",
            "#206: episode_reward:-9.9018 acc: 37.4200, ratio: 0.4906\n",
            "#207: episode_reward:-13.6665 acc: 13.2200, ratio: 0.4556\n",
            "#208: episode_reward:-11.2042 acc: 28.8800, ratio: 0.4581\n",
            "#209: episode_reward:-13.4686 acc: 11.4800, ratio: 0.2673\n",
            "#210: episode_reward:-13.2772 acc: 15.6800, ratio: 0.4545\n",
            "#211: episode_reward:-13.7366 acc: 9.5200, ratio: 0.2585\n",
            "#212: episode_reward:-13.1812 acc: 17.5000, ratio: 0.5727\n",
            "#213: episode_reward:-11.5000 acc: 25.2400, ratio: 0.3160\n",
            "#214: episode_reward:-12.7534 acc: 16.2800, ratio: 0.2722\n",
            "#215: episode_reward:-13.3737 acc: 13.4000, ratio: 0.3357\n",
            "#216: episode_reward:-13.7957 acc: 9.2600, ratio: 0.2642\n",
            "#217: episode_reward:-12.9356 acc: 16.7400, ratio: 0.3685\n",
            "#218: episode_reward:-12.2948 acc: 20.2400, ratio: 0.3263\n",
            "#219: episode_reward:-12.5827 acc: 19.2200, ratio: 0.3836\n",
            "#220: episode_reward:-13.5062 acc: 14.7600, ratio: 0.5017\n",
            "#221: episode_reward:-13.2204 acc: 15.0200, ratio: 0.3762\n",
            "#222: episode_reward:-12.3341 acc: 19.9200, ratio: 0.3222\n",
            "#223: episode_reward:-13.2253 acc: 15.1000, ratio: 0.3840\n",
            "#224: episode_reward:-12.3549 acc: 21.4400, ratio: 0.4457\n",
            "#225: episode_reward:-12.5308 acc: 18.9000, ratio: 0.3383\n",
            "#226: episode_reward:-11.9153 acc: 23.5800, ratio: 0.3895\n",
            "#227: episode_reward:-13.9024 acc: 10.4800, ratio: 0.3661\n",
            "#228: episode_reward:-12.1656 acc: 22.4000, ratio: 0.4243\n",
            "#229: episode_reward:-10.1195 acc: 36.4400, ratio: 0.5414\n",
            "#230: episode_reward:-11.5790 acc: 27.2000, ratio: 0.5328\n",
            "#231: episode_reward:-13.8041 acc: 11.0400, ratio: 0.3615\n",
            "#232: episode_reward:-12.4768 acc: 20.2000, ratio: 0.4067\n",
            "#233: episode_reward:-9.5399 acc: 39.5600, ratio: 0.4720\n",
            "#234: episode_reward:-12.9715 acc: 16.7200, ratio: 0.3833\n",
            "#235: episode_reward:-12.4582 acc: 18.7600, ratio: 0.3013\n",
            "#236: episode_reward:-13.4044 acc: 14.7600, ratio: 0.4452\n",
            "#237: episode_reward:-10.8731 acc: 31.4000, ratio: 0.5042\n",
            "#238: episode_reward:-12.4693 acc: 19.2200, ratio: 0.3333\n",
            "#239: episode_reward:-11.8319 acc: 24.4000, ratio: 0.4131\n",
            "#240: episode_reward:-12.3291 acc: 21.1000, ratio: 0.4032\n",
            "#241: episode_reward:-10.6669 acc: 31.4400, ratio: 0.3767\n",
            "#242: episode_reward:-10.6754 acc: 31.8800, ratio: 0.4218\n",
            "#243: episode_reward:-11.5670 acc: 26.4800, ratio: 0.4486\n",
            "#244: episode_reward:-11.9257 acc: 22.2200, ratio: 0.3006\n",
            "#245: episode_reward:-13.6025 acc: 11.3600, ratio: 0.3045\n",
            "#246: episode_reward:-12.7258 acc: 17.3600, ratio: 0.3212\n",
            "#247: episode_reward:-12.4061 acc: 20.6000, ratio: 0.4025\n",
            "#248: episode_reward:-9.5411 acc: 40.0400, ratio: 0.5367\n",
            "#249: episode_reward:-13.7506 acc: 12.7600, ratio: 0.4617\n",
            "#250: episode_reward:-8.9111 acc: 44.0200, ratio: 0.5399\n",
            "#251: episode_reward:-13.1014 acc: 13.7200, ratio: 0.2593\n",
            "#252: episode_reward:-8.4265 acc: 46.4600, ratio: 0.4511\n",
            "#253: episode_reward:-9.1999 acc: 41.7000, ratio: 0.4703\n",
            "#254: episode_reward:-12.4761 acc: 20.6400, ratio: 0.4431\n",
            "#255: episode_reward:-12.1176 acc: 20.2200, ratio: 0.2603\n",
            "#256: episode_reward:-11.7814 acc: 25.2600, ratio: 0.4623\n",
            "#257: episode_reward:-12.4935 acc: 20.1200, ratio: 0.4088\n",
            "#258: episode_reward:-11.4065 acc: 26.2800, ratio: 0.3458\n",
            "#259: episode_reward:-9.0890 acc: 42.3400, ratio: 0.4623\n",
            "#260: episode_reward:-10.9434 acc: 31.5400, ratio: 0.5772\n",
            "#261: episode_reward:-11.3294 acc: 27.4600, ratio: 0.3999\n",
            "#262: episode_reward:-11.5701 acc: 26.8200, ratio: 0.4847\n",
            "#263: episode_reward:-12.8775 acc: 18.3200, ratio: 0.4635\n",
            "#264: episode_reward:-8.8727 acc: 44.0800, ratio: 0.5128\n",
            "#265: episode_reward:-12.3004 acc: 22.5000, ratio: 0.5152\n",
            "#266: episode_reward:-11.6149 acc: 25.7200, ratio: 0.4074\n",
            "#267: episode_reward:-9.1855 acc: 42.3800, ratio: 0.5525\n",
            "#268: episode_reward:-12.1054 acc: 22.3200, ratio: 0.3863\n",
            "#269: episode_reward:-11.7660 acc: 24.7000, ratio: 0.4028\n",
            "#270: episode_reward:-10.7677 acc: 30.9800, ratio: 0.3930\n",
            "#271: episode_reward:-9.5567 acc: 39.4200, ratio: 0.4680\n",
            "#272: episode_reward:-11.3386 acc: 27.9800, ratio: 0.4533\n",
            "#273: episode_reward:-8.8554 acc: 43.9000, ratio: 0.4725\n",
            "#274: episode_reward:-8.1303 acc: 48.9000, ratio: 0.5357\n",
            "#275: episode_reward:-7.8155 acc: 50.9800, ratio: 0.5536\n",
            "#276: episode_reward:-9.0641 acc: 42.9000, ratio: 0.5165\n",
            "#277: episode_reward:-11.4336 acc: 26.3200, ratio: 0.3618\n",
            "#278: episode_reward:-7.7240 acc: 51.0400, ratio: 0.4683\n",
            "#279: episode_reward:-10.2084 acc: 35.1600, ratio: 0.4535\n",
            "\u001b[92m New best reward: -7.6948, acc: 51.6000, compress: 0.5292\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.6203110371004293, 0.6485829471498799, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 318, 333, 205, 205, 103, 103, 52, 26]\u001b[00m\n",
            "#280: episode_reward:-7.6948 acc: 51.6000, ratio: 0.5292\n",
            "#281: episode_reward:-10.6889 acc: 32.3400, ratio: 0.4787\n",
            "#282: episode_reward:-9.7050 acc: 38.2200, ratio: 0.4379\n",
            "#283: episode_reward:-8.0801 acc: 48.8200, ratio: 0.4737\n",
            "\u001b[92m New best reward: -5.7805, acc: 63.9200, compress: 0.5985\u001b[00m\n",
            "\u001b[92m New best policy: [0.5522167986133778, 0.8, 0.8, 0.7970966566712706, 0.8, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [283, 410, 410, 205, 205, 103, 103, 52, 26]\u001b[00m\n",
            "#284: episode_reward:-5.7805 acc: 63.9200, ratio: 0.5985\n",
            "New best clamped policy: [0.5522167986133778, 0.8337655666786092, 0.8903277044676648, 0.7970966566712706, 0.8657015782667492, 0.9480487289146672, 0.849503226836157, 0.8921825300566504, 0.838624944128433]\n",
            "#285: episode_reward:-7.0803 acc: 55.6200, ratio: 0.5594\n",
            "#286: episode_reward:-8.7969 acc: 44.6600, ratio: 0.5280\n",
            "#287: episode_reward:-9.0058 acc: 43.1000, ratio: 0.4930\n",
            "#288: episode_reward:-10.0412 acc: 37.2200, ratio: 0.5825\n",
            "#289: episode_reward:-9.4601 acc: 40.5400, ratio: 0.5354\n",
            "#290: episode_reward:-10.4341 acc: 34.4200, ratio: 0.5357\n",
            "#291: episode_reward:-6.0015 acc: 62.4000, ratio: 0.5636\n",
            "#292: episode_reward:-9.6977 acc: 38.5400, ratio: 0.4696\n",
            "#293: episode_reward:-8.9528 acc: 43.8600, ratio: 0.5558\n",
            "#294: episode_reward:-8.8077 acc: 44.4400, ratio: 0.5055\n",
            "#295: episode_reward:-7.8431 acc: 50.5200, ratio: 0.5048\n",
            "#296: episode_reward:-8.0900 acc: 49.5000, ratio: 0.5976\n",
            "#297: episode_reward:-9.9334 acc: 37.1400, ratio: 0.4808\n",
            "#298: episode_reward:-7.4666 acc: 53.1800, ratio: 0.5559\n",
            "#299: episode_reward:-8.9142 acc: 44.3000, ratio: 0.5881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_amc_r0.5_ep300_search-run9', 'mobilenet_amc_r0.5_rbound0.8_ep300_search.zip')"
      ],
      "metadata": {
        "id": "MPHzRPWL0ZOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/mobilenet_amc_r0.5_rbound0.8_ep300_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/mobilenet_amc_r0.5_rbound0.8_ep300_search/mobilenet_amc_r0.5_rbound0.8_ep300_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUa63ug3dohb",
        "outputId": "0fe2da9a-ddb3-4708-e902-b6e3bb0b1974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Identified sensitive layers: ['features.0.0', 'features.1.0', 'features.2.0', 'features.3.0', 'features.4.0', 'features.5.0', 'features.6.0', 'features.7.0']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "=> Original model channels: [512, 512, 512, 256, 256, 128, 128, 64, 32]\n",
            "=> Pruning with ratios: [0.5522167986133778, 0.8337655666786092, 0.8903277044676648, 0.7970966566712706, 0.8657015782667492, 0.9480487289146672, 0.849503226836157, 0.8921825300566504, 0.838624944128433]\n",
            "=> Channels after pruning: [283, 427, 456, 204, 222, 121, 109, 57, 27]\n",
            "\u001b[92m New best reward: -3.5864, acc: 77.7800, compress: 0.6740\u001b[00m\n",
            "\u001b[92m New best policy: [0.5522167986133778, 0.8337655666786092, 0.8903277044676648, 0.7970966566712706, 0.8657015782667492, 0.9480487289146672, 0.849503226836157, 0.8921825300566504, 0.838624944128433]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [283, 427, 456, 205, 222, 122, 109, 58, 27]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_amc_r0.5_rbound0.8_ep300_search/mobilenet_amc_r0.5_rbound0.8_ep300_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkW9bdIBdohb",
        "outputId": "60cbf6b7-354f-4371-df4d-40a12bbc5b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_amc_r0.5_rbound0.8_ep300_search/mobilenet_amc_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Model Parameter: 0.528 M, FLOPs: 10.019M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_amc_r0.5_rbound0.8_ep300_search/mobilenet_amc_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training mobilenet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/mobilenet_cifar_finetune-run11\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 193ms | Tot: 23s200ms | Loss: 0.557 | Acc1: 80.640% | Acc5: 99.004% 352/352 \n",
            " [=======================================>]  Step: 55ms | Tot: 651ms | Loss: 0.451 | Acc1: 84.500% | Acc5: 99.360% 40/40 \n",
            "Current best acc: 84.5\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 9ms | Tot: 23s126ms | Loss: 0.530 | Acc1: 81.580% | Acc5: 99.116% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 604ms | Loss: 0.439 | Acc1: 85.160% | Acc5: 99.360% 40/40 \n",
            "Current best acc: 85.16\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 9ms | Tot: 23s82ms | Loss: 0.520 | Acc1: 81.884% | Acc5: 99.207% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 608ms | Loss: 0.435 | Acc1: 85.000% | Acc5: 99.340% 40/40 \n",
            "Current best acc: 85.16\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 8ms | Tot: 23s15ms | Loss: 0.515 | Acc1: 81.969% | Acc5: 99.180% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 622ms | Loss: 0.432 | Acc1: 85.200% | Acc5: 99.340% 40/40 \n",
            "Current best acc: 85.2\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 63ms | Tot: 23s398ms | Loss: 0.509 | Acc1: 82.244% | Acc5: 99.233% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 619ms | Loss: 0.433 | Acc1: 85.120% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.2\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 9ms | Tot: 23s338ms | Loss: 0.510 | Acc1: 81.904% | Acc5: 99.207% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 590ms | Loss: 0.431 | Acc1: 85.180% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.2\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 9ms | Tot: 23s246ms | Loss: 0.506 | Acc1: 82.307% | Acc5: 99.178% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 662ms | Loss: 0.429 | Acc1: 85.320% | Acc5: 99.380% 40/40 \n",
            "Current best acc: 85.32\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 8ms | Tot: 23s188ms | Loss: 0.504 | Acc1: 82.402% | Acc5: 99.242% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 631ms | Loss: 0.423 | Acc1: 85.480% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.48\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 63ms | Tot: 23s500ms | Loss: 0.504 | Acc1: 82.291% | Acc5: 99.220% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 653ms | Loss: 0.426 | Acc1: 85.380% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.48\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 66ms | Tot: 23s420ms | Loss: 0.498 | Acc1: 82.616% | Acc5: 99.271% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 625ms | Loss: 0.424 | Acc1: 85.240% | Acc5: 99.380% 40/40 \n",
            "Current best acc: 85.48\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 9ms | Tot: 22s881ms | Loss: 0.493 | Acc1: 82.807% | Acc5: 99.347% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 575ms | Loss: 0.423 | Acc1: 85.300% | Acc5: 99.400% 40/40 \n",
            "Current best acc: 85.48\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 9ms | Tot: 23s784ms | Loss: 0.491 | Acc1: 82.696% | Acc5: 99.284% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 618ms | Loss: 0.423 | Acc1: 85.520% | Acc5: 99.400% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 10ms | Tot: 23s130ms | Loss: 0.491 | Acc1: 82.747% | Acc5: 99.289% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 606ms | Loss: 0.421 | Acc1: 85.500% | Acc5: 99.380% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 64ms | Tot: 23s381ms | Loss: 0.492 | Acc1: 82.656% | Acc5: 99.244% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 597ms | Loss: 0.420 | Acc1: 85.460% | Acc5: 99.340% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 9ms | Tot: 23s70ms | Loss: 0.490 | Acc1: 82.802% | Acc5: 99.287% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 565ms | Loss: 0.422 | Acc1: 85.480% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 9ms | Tot: 23s260ms | Loss: 0.491 | Acc1: 82.547% | Acc5: 99.349% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 616ms | Loss: 0.422 | Acc1: 85.440% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 64ms | Tot: 23s127ms | Loss: 0.482 | Acc1: 83.160% | Acc5: 99.342% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 602ms | Loss: 0.420 | Acc1: 85.500% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.52\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 9ms | Tot: 23s50ms | Loss: 0.483 | Acc1: 83.060% | Acc5: 99.304% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 625ms | Loss: 0.419 | Acc1: 85.560% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.56\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 63ms | Tot: 23s148ms | Loss: 0.489 | Acc1: 82.911% | Acc5: 99.256% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 658ms | Loss: 0.419 | Acc1: 85.520% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.56\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 32ms | Tot: 23s37ms | Loss: 0.487 | Acc1: 82.933% | Acc5: 99.307% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 611ms | Loss: 0.418 | Acc1: 85.760% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.76\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run11/ckpt.pth.tar\n",
            "=> Model Parameter: 0.528 M, FLOPs: 10.019M, best top-1 acc: 85.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_finetune-run11', 'mobilenet_amc_r0.5_rbound0.8_ep300_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3yO9S0Adohb",
        "outputId": "fb6802e8-3efc-4f6f-87c5-38abef004389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/mobilenet_cifar_finetune-run11 to mobilenet_amc_r0.5_rbound0.8_ep300_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity"
      ],
      "metadata": {
        "id": "ZZRwUpVvhl4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=200 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "id": "eLqED6sKW8aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cdcfb9-1c7b-4455-c567-d5c2e94b5f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "Identified sensitive layers: ['features.0.0', 'features.1.0', 'features.2.0', 'features.3.0', 'features.4.0', 'features.5.0', 'features.6.0', 'features.7.0']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "=> Saving logs to ./logs/mobilenet_cifar_sensitivity_r0.5_ep200_search-run2\n",
            "=> Output path: ./logs/mobilenet_cifar_sensitivity_r0.5_ep200_search-run2...\n",
            "** Actual replay buffer size: 900\n",
            "\u001b[92m New best reward: -6.0333, acc: 63.0600, compress: 0.8171\u001b[00m\n",
            "\u001b[92m New best policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 461, 511, 231, 237, 127, 54, 63, 28]\u001b[00m\n",
            "#0: episode_reward:-6.0333 acc: 63.0600, ratio: 0.8171\n",
            "New best clamped policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-13.8528 acc: 12.0800, ratio: 0.4591\n",
            "#2: episode_reward:-11.1351 acc: 30.5600, ratio: 0.6071\n",
            "#3: episode_reward:-9.7947 acc: 39.1400, ratio: 0.6435\n",
            "#4: episode_reward:-10.7117 acc: 32.5000, ratio: 0.5140\n",
            "#5: episode_reward:-13.6238 acc: 12.6000, ratio: 0.3880\n",
            "#6: episode_reward:-11.8030 acc: 27.2200, ratio: 0.7281\n",
            "#7: episode_reward:-14.0604 acc: 10.5200, ratio: 0.4399\n",
            "#8: episode_reward:-13.7049 acc: 14.2600, ratio: 0.5767\n",
            "#9: episode_reward:-13.5794 acc: 15.9800, ratio: 0.6889\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#10: episode_reward:-10.1425 acc: 37.4200, ratio: 0.7207\n",
            "#11: episode_reward:-13.3129 acc: 16.3000, ratio: 0.5330\n",
            "#12: episode_reward:-13.1461 acc: 17.6400, ratio: 0.5638\n",
            "#13: episode_reward:-10.8500 acc: 32.0000, ratio: 0.5605\n",
            "#14: episode_reward:-10.9880 acc: 31.2600, ratio: 0.5770\n",
            "#15: episode_reward:-13.7747 acc: 12.9800, ratio: 0.4939\n",
            "#16: episode_reward:-7.8554 acc: 51.8000, ratio: 0.7887\n",
            "#17: episode_reward:-13.5736 acc: 15.1400, ratio: 0.5831\n",
            "#18: episode_reward:-10.7120 acc: 33.4000, ratio: 0.6372\n",
            "#19: episode_reward:-14.0143 acc: 10.6000, ratio: 0.4237\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#20: episode_reward:-7.9417 acc: 50.4600, ratio: 0.6043\n",
            "#21: episode_reward:-14.0243 acc: 11.6400, ratio: 0.5153\n",
            "#22: episode_reward:-12.7454 acc: 20.5200, ratio: 0.6073\n",
            "#23: episode_reward:-10.2017 acc: 36.6200, ratio: 0.6449\n",
            "#24: episode_reward:-13.2738 acc: 15.3800, ratio: 0.4281\n",
            "#25: episode_reward:-13.1239 acc: 16.8800, ratio: 0.4744\n",
            "#26: episode_reward:-13.8779 acc: 12.3400, ratio: 0.4950\n",
            "#27: episode_reward:-12.2084 acc: 23.8800, ratio: 0.6087\n",
            "#28: episode_reward:-10.0843 acc: 36.5800, ratio: 0.5305\n",
            "#29: episode_reward:-8.2612 acc: 49.1200, ratio: 0.7423\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#30: episode_reward:-13.6770 acc: 13.9200, ratio: 0.5242\n",
            "#31: episode_reward:-13.9814 acc: 12.7600, ratio: 0.6015\n",
            "#32: episode_reward:-14.1516 acc: 10.7000, ratio: 0.5028\n",
            "#33: episode_reward:-13.2482 acc: 17.7800, ratio: 0.6560\n",
            "#34: episode_reward:-12.2326 acc: 24.5200, ratio: 0.7201\n",
            "#35: episode_reward:-14.1619 acc: 12.2600, ratio: 0.6744\n",
            "#36: episode_reward:-13.2388 acc: 15.6400, ratio: 0.4310\n",
            "#37: episode_reward:-14.0191 acc: 12.3000, ratio: 0.5773\n",
            "#38: episode_reward:-13.0078 acc: 16.9200, ratio: 0.4157\n",
            "#39: episode_reward:-11.6033 acc: 27.1200, ratio: 0.5414\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#40: episode_reward:-13.4752 acc: 14.1800, ratio: 0.4347\n",
            "#41: episode_reward:-13.4752 acc: 16.1000, ratio: 0.6227\n",
            "#42: episode_reward:-13.9124 acc: 12.8000, ratio: 0.5598\n",
            "#43: episode_reward:-11.8747 acc: 26.8800, ratio: 0.7448\n",
            "#44: episode_reward:-13.9468 acc: 12.1400, ratio: 0.5164\n",
            "#45: episode_reward:-13.8221 acc: 13.5200, ratio: 0.5759\n",
            "#46: episode_reward:-14.0887 acc: 11.1400, ratio: 0.5067\n",
            "#47: episode_reward:-13.0992 acc: 18.4400, ratio: 0.6226\n",
            "#48: episode_reward:-13.6748 acc: 12.0800, ratio: 0.3749\n",
            "#49: episode_reward:-8.1817 acc: 49.2800, ratio: 0.6679\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#50: episode_reward:-13.9643 acc: 12.3200, ratio: 0.5443\n",
            "#51: episode_reward:-10.8235 acc: 30.6400, ratio: 0.3946\n",
            "#52: episode_reward:-11.2507 acc: 28.8000, ratio: 0.4804\n",
            "#53: episode_reward:-11.2645 acc: 28.0000, ratio: 0.4108\n",
            "#54: episode_reward:-13.7774 acc: 9.8600, ratio: 0.2864\n",
            "#55: episode_reward:-13.0796 acc: 17.9200, ratio: 0.5491\n",
            "#56: episode_reward:-13.9506 acc: 12.3400, ratio: 0.5378\n",
            "#57: episode_reward:-13.4665 acc: 15.1800, ratio: 0.5178\n",
            "#58: episode_reward:-13.4991 acc: 12.9000, ratio: 0.3547\n",
            "#59: episode_reward:-8.8041 acc: 44.2600, ratio: 0.4772\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#60: episode_reward:-11.8447 acc: 22.7600, ratio: 0.3013\n",
            "#61: episode_reward:-12.1712 acc: 24.3800, ratio: 0.6443\n",
            "#62: episode_reward:-14.0004 acc: 12.5800, ratio: 0.5947\n",
            "\u001b[92m New best reward: -3.2958, acc: 79.7400, compress: 0.7656\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.7346086336580893, 0.9, 0.9196580853505114, 0.9, 0.9706298824559081, 0.9, 0.8853384964917524]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 461, 377, 231, 236, 116, 125, 58, 29]\u001b[00m\n",
            "#63: episode_reward:-3.2958 acc: 79.7400, ratio: 0.7656\n",
            "New best clamped policy: [0.9, 0.9, 0.7346086336580893, 0.9, 0.9196580853505114, 0.9, 0.9706298824559081, 0.9, 0.8853384964917524]\n",
            "#64: episode_reward:-10.6073 acc: 33.3800, ratio: 0.5419\n",
            "#65: episode_reward:-13.8344 acc: 11.2200, ratio: 0.3860\n",
            "#66: episode_reward:-13.2568 acc: 15.6800, ratio: 0.4437\n",
            "#67: episode_reward:-8.8488 acc: 45.0200, ratio: 0.6439\n",
            "#68: episode_reward:-12.4887 acc: 20.8200, ratio: 0.4667\n",
            "#69: episode_reward:-11.3800 acc: 29.3600, ratio: 0.6538\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#70: episode_reward:-13.1219 acc: 18.5400, ratio: 0.6529\n",
            "#71: episode_reward:-13.1252 acc: 18.5400, ratio: 0.6556\n",
            "#72: episode_reward:-12.7801 acc: 19.1600, ratio: 0.4840\n",
            "#73: episode_reward:-6.1354 acc: 61.9200, ratio: 0.6552\n",
            "#74: episode_reward:-6.9774 acc: 57.1000, ratio: 0.7630\n",
            "#75: episode_reward:-7.3059 acc: 54.9600, ratio: 0.7306\n",
            "#76: episode_reward:-10.2993 acc: 35.2000, ratio: 0.5269\n",
            "#77: episode_reward:-5.0781 acc: 68.8200, ratio: 0.7802\n",
            "#78: episode_reward:-13.6196 acc: 13.2600, ratio: 0.4347\n",
            "#79: episode_reward:-12.4175 acc: 21.6000, ratio: 0.4986\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#80: episode_reward:-13.2959 acc: 16.4400, ratio: 0.5364\n",
            "#81: episode_reward:-13.5300 acc: 14.5200, ratio: 0.4934\n",
            "#82: episode_reward:-12.2776 acc: 21.6800, ratio: 0.4238\n",
            "#83: episode_reward:-13.1351 acc: 13.6400, ratio: 0.2658\n",
            "#84: episode_reward:-13.8834 acc: 10.8800, ratio: 0.3843\n",
            "#85: episode_reward:-12.0745 acc: 22.6400, ratio: 0.3959\n",
            "#86: episode_reward:-13.8856 acc: 12.7800, ratio: 0.5409\n",
            "#87: episode_reward:-13.5393 acc: 16.6000, ratio: 0.7404\n",
            "#88: episode_reward:-13.6531 acc: 12.9200, ratio: 0.4249\n",
            "#89: episode_reward:-13.5761 acc: 15.0200, ratio: 0.5717\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#90: episode_reward:-11.5736 acc: 26.5400, ratio: 0.4585\n",
            "#91: episode_reward:-13.8680 acc: 13.5200, ratio: 0.6073\n",
            "#92: episode_reward:-10.9755 acc: 31.6400, ratio: 0.6192\n",
            "#93: episode_reward:-10.9559 acc: 31.5800, ratio: 0.5933\n",
            "#94: episode_reward:-6.6856 acc: 58.6600, ratio: 0.6959\n",
            "#95: episode_reward:-11.8381 acc: 25.2400, ratio: 0.4966\n",
            "#96: episode_reward:-13.8699 acc: 11.8800, ratio: 0.4516\n",
            "#97: episode_reward:-14.2445 acc: 10.6200, ratio: 0.5501\n",
            "#98: episode_reward:-13.5059 acc: 15.4800, ratio: 0.5739\n",
            "#99: episode_reward:-14.2038 acc: 10.6600, ratio: 0.5294\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#100: episode_reward:-13.5365 acc: 13.1800, ratio: 0.3894\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-10.2844 acc: 34.6200, ratio: 0.4473\n",
            "#102: episode_reward:-13.4694 acc: 15.1000, ratio: 0.5118\n",
            "#103: episode_reward:-12.7435 acc: 17.6200, ratio: 0.3445\n",
            "#104: episode_reward:-11.6836 acc: 24.5400, ratio: 0.3494\n",
            "#105: episode_reward:-13.9482 acc: 9.2400, ratio: 0.3114\n",
            "#106: episode_reward:-11.9732 acc: 25.3200, ratio: 0.6053\n",
            "#107: episode_reward:-13.5178 acc: 16.1000, ratio: 0.6552\n",
            "#108: episode_reward:-7.1457 acc: 55.8400, ratio: 0.7024\n",
            "#109: episode_reward:-4.2536 acc: 73.7200, ratio: 0.7053\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#110: episode_reward:-7.5982 acc: 52.8400, ratio: 0.6550\n",
            "#111: episode_reward:-7.2104 acc: 55.7000, ratio: 0.7723\n",
            "#112: episode_reward:-5.9848 acc: 63.2000, ratio: 0.7620\n",
            "#113: episode_reward:-6.0485 acc: 62.8400, ratio: 0.7727\n",
            "#114: episode_reward:-6.3853 acc: 60.7800, ratio: 0.7756\n",
            "#115: episode_reward:-4.0915 acc: 74.8200, ratio: 0.7516\n",
            "#116: episode_reward:-9.0551 acc: 44.1600, ratio: 0.7272\n",
            "#117: episode_reward:-3.5728 acc: 78.0000, ratio: 0.7446\n",
            "\u001b[92m New best reward: -2.7788, acc: 83.0600, compress: 0.8770\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9863251344276591, 0.9279258138465772, 0.9, 0.8554025143885766, 0.9, 0.9895842382229902, 0.9, 0.8670275767162671]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 505, 476, 231, 219, 116, 127, 58, 28]\u001b[00m\n",
            "#118: episode_reward:-2.7788 acc: 83.0600, ratio: 0.8770\n",
            "New best clamped policy: [0.9, 0.9863251344276591, 0.9279258138465772, 0.9, 0.8554025143885766, 0.9, 0.9895842382229902, 0.9, 0.8670275767162671]\n",
            "#119: episode_reward:-8.0581 acc: 50.7800, ratio: 0.8495\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#120: episode_reward:-3.0189 acc: 81.5600, ratio: 0.8495\n",
            "#121: episode_reward:-3.5320 acc: 78.3000, ratio: 0.7725\n",
            "#122: episode_reward:-4.0585 acc: 75.0400, ratio: 0.7597\n",
            "#123: episode_reward:-5.3589 acc: 67.2000, ratio: 0.8215\n",
            "\u001b[92m New best reward: -2.6896, acc: 83.6200, compress: 0.8916\u001b[00m\n",
            "\u001b[92m New best policy: [0.9576072642614847, 0.9124204736462346, 0.9900406739796472, 0.9, 0.946894966457873, 0.9277614882124762, 0.9587722595875511, 0.9, 0.9981667688822655]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [491, 468, 507, 231, 243, 119, 123, 58, 31]\u001b[00m\n",
            "#124: episode_reward:-2.6896 acc: 83.6200, ratio: 0.8916\n",
            "New best clamped policy: [0.9576072642614847, 0.9124204736462346, 0.9900406739796472, 0.9, 0.946894966457873, 0.9277614882124762, 0.9587722595875511, 0.9, 0.9981667688822655]\n",
            "#125: episode_reward:-2.7835 acc: 83.0600, ratio: 0.9021\n",
            "#126: episode_reward:-2.9837 acc: 81.8000, ratio: 0.8689\n",
            "#127: episode_reward:-3.8480 acc: 76.4600, ratio: 0.8284\n",
            "#128: episode_reward:-2.7286 acc: 83.3800, ratio: 0.8893\n",
            "#129: episode_reward:-3.6079 acc: 78.0000, ratio: 0.8737\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#130: episode_reward:-3.8103 acc: 76.7200, ratio: 0.8460\n",
            "#131: episode_reward:-3.5083 acc: 78.5600, ratio: 0.8427\n",
            "#132: episode_reward:-2.7078 acc: 83.5200, ratio: 0.9012\n",
            "#133: episode_reward:-3.0659 acc: 81.2200, ratio: 0.8110\n",
            "#134: episode_reward:-2.7420 acc: 83.2800, ratio: 0.8737\n",
            "\u001b[92m New best reward: -2.5708, acc: 84.3600, compress: 0.9071\u001b[00m\n",
            "\u001b[92m New best policy: [0.9793652232634701, 0.9664260958711575, 0.8993721465432974, 0.9510151174008118, 0.9426666965615995, 0.9291055726393136, 0.9746820856470574, 0.9770314806763526, 0.9446673109009108]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [502, 495, 461, 244, 242, 119, 125, 63, 31]\u001b[00m\n",
            "#135: episode_reward:-2.5708 acc: 84.3600, ratio: 0.9071\n",
            "New best clamped policy: [0.9793652232634701, 0.9664260958711575, 0.8993721465432974, 0.9510151174008118, 0.9426666965615995, 0.9291055726393136, 0.9746820856470574, 0.9770314806763526, 0.9446673109009108]\n",
            "#136: episode_reward:-3.2918 acc: 79.9200, ratio: 0.8684\n",
            "#137: episode_reward:-2.6215 acc: 84.0400, ratio: 0.8964\n",
            "#138: episode_reward:-2.5765 acc: 84.3200, ratio: 0.9023\n",
            "#139: episode_reward:-2.8358 acc: 82.6600, ratio: 0.8347\n",
            "\u001b[92m New best reward: -2.4599, acc: 85.0600, compress: 0.9327\u001b[00m\n",
            "\u001b[92m New best policy: [0.9641062585613123, 0.9344154926855754, 0.9995048153395923, 0.9663473174313192, 0.9989358931519507, 0.9384363127120379, 0.9595296332867301, 0.9592487941629949, 0.9523455505367092]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [494, 479, 511, 248, 255, 121, 123, 62, 31]\u001b[00m\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#140: episode_reward:-2.4599 acc: 85.0600, ratio: 0.9327\n",
            "New best clamped policy: [0.9641062585613123, 0.9344154926855754, 0.9995048153395923, 0.9663473174313192, 0.9989358931519507, 0.9384363127120379, 0.9595296332867301, 0.9592487941629949, 0.9523455505367092]\n",
            "#141: episode_reward:-2.4757 acc: 84.9600, ratio: 0.9287\n",
            "#142: episode_reward:-2.7091 acc: 83.5400, ratio: 0.9270\n",
            "\u001b[92m New best reward: -2.4318, acc: 85.2400, compress: 0.9428\u001b[00m\n",
            "\u001b[92m New best policy: [0.9990302909668315, 0.9704310514233332, 0.9325315522737828, 0.9895967600226032, 0.9913912954234553, 0.9576256021312731, 0.9945037373226955, 0.9517156480720829, 0.9901622714838921]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 497, 478, 254, 254, 123, 127, 61, 31]\u001b[00m\n",
            "#143: episode_reward:-2.4318 acc: 85.2400, ratio: 0.9428\n",
            "New best clamped policy: [0.9990302909668315, 0.9704310514233332, 0.9325315522737828, 0.9895967600226032, 0.9913912954234553, 0.9576256021312731, 0.9945037373226955, 0.9517156480720829, 0.9901622714838921]\n",
            "#144: episode_reward:-2.6696 acc: 83.7600, ratio: 0.9081\n",
            "#145: episode_reward:-2.6189 acc: 84.0400, ratio: 0.8820\n",
            "#146: episode_reward:-2.4752 acc: 84.9800, ratio: 0.9463\n",
            "#147: episode_reward:-2.6156 acc: 84.1200, ratio: 0.9384\n",
            "#148: episode_reward:-2.8291 acc: 82.8200, ratio: 0.9347\n",
            "#149: episode_reward:-2.5352 acc: 84.6200, ratio: 0.9501\n",
            "\u001b[92m New best reward: -2.4260, acc: 85.3000, compress: 0.9691\u001b[00m\n",
            "\u001b[92m New best policy: [0.9774448535462874, 0.9836284809272103, 0.9847271299155392, 0.9929283053669361, 0.9498003635785626, 0.9962957260804967, 0.9957230578127533, 0.9898499869830344, 0.9520813892626726]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 504, 505, 255, 244, 127, 127, 63, 31]\u001b[00m\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#150: episode_reward:-2.4260 acc: 85.3000, ratio: 0.9691\n",
            "New best clamped policy: [0.9774448535462874, 0.9836284809272103, 0.9847271299155392, 0.9929283053669361, 0.9498003635785626, 0.9962957260804967, 0.9957230578127533, 0.9898499869830344, 0.9520813892626726]\n",
            "\u001b[92m New best reward: -2.4087, acc: 85.4000, compress: 0.9641\u001b[00m\n",
            "\u001b[92m New best policy: [0.9780598400151969, 0.9893730866067286, 0.9763108041808034, 0.9757470468943258, 0.9912851305401691, 0.9949203381476207, 0.9512220484232016, 0.9969187243004628, 0.9815255079040633]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 507, 500, 250, 254, 127, 122, 63, 31]\u001b[00m\n",
            "#151: episode_reward:-2.4087 acc: 85.4000, ratio: 0.9641\n",
            "New best clamped policy: [0.9780598400151969, 0.9893730866067286, 0.9763108041808034, 0.9757470468943258, 0.9912851305401691, 0.9949203381476207, 0.9512220484232016, 0.9969187243004628, 0.9815255079040633]\n",
            "\u001b[92m New best reward: -2.4018, acc: 85.4200, compress: 0.9401\u001b[00m\n",
            "\u001b[92m New best policy: [0.9590106843966936, 0.9725014126465172, 0.9480334834767548, 0.9823505080631448, 0.9919447115195862, 0.9580871994245076, 0.9767114293692747, 0.9838715249761705, 0.958956044142602]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [492, 498, 486, 252, 254, 123, 126, 63, 31]\u001b[00m\n",
            "#152: episode_reward:-2.4018 acc: 85.4200, ratio: 0.9401\n",
            "New best clamped policy: [0.9590106843966936, 0.9725014126465172, 0.9480334834767548, 0.9823505080631448, 0.9919447115195862, 0.9580871994245076, 0.9767114293692747, 0.9838715249761705, 0.958956044142602]\n",
            "#153: episode_reward:-2.4465 acc: 85.1600, ratio: 0.9525\n",
            "#154: episode_reward:-2.4840 acc: 84.9400, ratio: 0.9602\n",
            "#155: episode_reward:-2.5065 acc: 84.8000, ratio: 0.9565\n",
            "\u001b[92m New best reward: -2.3789, acc: 85.5800, compress: 0.9633\u001b[00m\n",
            "\u001b[92m New best policy: [0.9924953511490893, 0.9828514244694553, 0.9549723397738326, 0.9978058889962781, 0.9798116921611673, 0.9970534643592386, 0.9925420330815616, 0.9999610480711613, 0.9912369315925819]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [509, 504, 489, 255, 251, 127, 127, 63, 31]\u001b[00m\n",
            "#156: episode_reward:-2.3789 acc: 85.5800, ratio: 0.9633\n",
            "New best clamped policy: [0.9924953511490893, 0.9828514244694553, 0.9549723397738326, 0.9978058889962781, 0.9798116921611673, 0.9970534643592386, 0.9925420330815616, 0.9999610480711613, 0.9912369315925819]\n",
            "#157: episode_reward:-2.5487 acc: 84.5200, ratio: 0.9323\n",
            "\u001b[92m New best reward: -2.3309, acc: 85.8600, compress: 0.9508\u001b[00m\n",
            "\u001b[92m New best policy: [0.9502945514651315, 0.9521567636921895, 0.9941333908682038, 0.9901463013923798, 0.9848727322883212, 0.9905132866823267, 0.9949183021943829, 0.9727589906652577, 0.9480780248295588]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 488, 509, 254, 253, 127, 127, 63, 31]\u001b[00m\n",
            "#158: episode_reward:-2.3309 acc: 85.8600, ratio: 0.9508\n",
            "New best clamped policy: [0.9502945514651315, 0.9521567636921895, 0.9941333908682038, 0.9901463013923798, 0.9848727322883212, 0.9905132866823267, 0.9949183021943829, 0.9727589906652577, 0.9480780248295588]\n",
            "#159: episode_reward:-2.4523 acc: 85.1400, ratio: 0.9684\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#160: episode_reward:-2.3645 acc: 85.6600, ratio: 0.9554\n",
            "#161: episode_reward:-2.4612 acc: 85.0800, ratio: 0.9621\n",
            "#162: episode_reward:-2.4072 acc: 85.4000, ratio: 0.9539\n",
            "#163: episode_reward:-2.3592 acc: 85.7200, ratio: 0.9867\n",
            "#164: episode_reward:-2.3953 acc: 85.5000, ratio: 0.9846\n",
            "#165: episode_reward:-2.3878 acc: 85.5400, ratio: 0.9789\n",
            "#166: episode_reward:-2.3928 acc: 85.5000, ratio: 0.9679\n",
            "#167: episode_reward:-2.3667 acc: 85.6600, ratio: 0.9702\n",
            "\u001b[92m New best reward: -2.3032, acc: 86.0400, compress: 0.9648\u001b[00m\n",
            "\u001b[92m New best policy: [0.9906233717369908, 0.953602809460789, 0.9959995808799639, 0.9992080947482034, 0.9909331715860172, 0.994755145681448, 0.9953378771359748, 0.9964389715331048, 0.9995704233334626]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [508, 489, 510, 255, 254, 127, 127, 63, 31]\u001b[00m\n",
            "#168: episode_reward:-2.3032 acc: 86.0400, ratio: 0.9648\n",
            "New best clamped policy: [0.9906233717369908, 0.953602809460789, 0.9959995808799639, 0.9992080947482034, 0.9909331715860172, 0.994755145681448, 0.9953378771359748, 0.9964389715331048, 0.9995704233334626]\n",
            "#169: episode_reward:-2.3758 acc: 85.6200, ratio: 0.9869\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#170: episode_reward:-2.3193 acc: 85.9600, ratio: 0.9844\n",
            "#171: episode_reward:-2.3449 acc: 85.8000, ratio: 0.9788\n",
            "#172: episode_reward:-2.3233 acc: 85.9400, ratio: 0.9893\n",
            "#173: episode_reward:-2.3624 acc: 85.7000, ratio: 0.9855\n",
            "#174: episode_reward:-2.3640 acc: 85.6800, ratio: 0.9742\n",
            "#175: episode_reward:-2.3256 acc: 85.9200, ratio: 0.9824\n",
            "#176: episode_reward:-2.3526 acc: 85.7600, ratio: 0.9864\n",
            "#177: episode_reward:-2.4170 acc: 85.3600, ratio: 0.9753\n",
            "#178: episode_reward:-2.3203 acc: 85.9600, ratio: 0.9916\n",
            "#179: episode_reward:-2.3460 acc: 85.8000, ratio: 0.9863\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#180: episode_reward:-2.3591 acc: 85.7200, ratio: 0.9858\n",
            "#181: episode_reward:-2.3263 acc: 85.9200, ratio: 0.9875\n",
            "#182: episode_reward:-2.3200 acc: 85.9600, ratio: 0.9895\n",
            "#183: episode_reward:-2.3259 acc: 85.9200, ratio: 0.9848\n",
            "#184: episode_reward:-2.3332 acc: 85.8800, ratio: 0.9897\n",
            "#185: episode_reward:-2.3203 acc: 85.9600, ratio: 0.9916\n",
            "#186: episode_reward:-2.3225 acc: 85.9400, ratio: 0.9837\n",
            "#187: episode_reward:-2.3423 acc: 85.8200, ratio: 0.9837\n",
            "#188: episode_reward:-2.3167 acc: 85.9800, ratio: 0.9894\n",
            "#189: episode_reward:-2.3169 acc: 85.9800, ratio: 0.9911\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#190: episode_reward:-2.3298 acc: 85.9000, ratio: 0.9886\n",
            "#191: episode_reward:-2.3203 acc: 85.9600, ratio: 0.9916\n",
            "#192: episode_reward:-2.3300 acc: 85.9000, ratio: 0.9901\n",
            "#193: episode_reward:-2.3132 acc: 86.0000, ratio: 0.9884\n",
            "#194: episode_reward:-2.3203 acc: 85.9600, ratio: 0.9916\n",
            "#195: episode_reward:-2.3235 acc: 85.9400, ratio: 0.9908\n",
            "#196: episode_reward:-2.3169 acc: 85.9800, ratio: 0.9911\n",
            "#197: episode_reward:-2.3399 acc: 85.8400, ratio: 0.9897\n",
            "#198: episode_reward:-2.3201 acc: 85.9600, ratio: 0.9906\n",
            "#199: episode_reward:-2.3203 acc: 85.9600, ratio: 0.9916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_sensitivity_r0.5_ep200_search-run2', 'mobilenet_cifar_sensitivity_r0.5_ep200.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWmHgUNA4SMi",
        "outputId": "83b220c8-e1be-469a-8889-7cf594cc1786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/amc3/logs/mobilenet_cifar_sensitivity_r0.5_ep200_search-run2' successfully zipped to 'mobilenet_cifar_sensitivity_r0.5_ep200.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/mobilenet_cifar_sensitivity_r0.5_ep200_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/mobilenet_cifar_sensitivity_r0.5_ep200_search/mobilenet_cifar_sensitivity_r0.5_ep200_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8Gvc29heE6c",
        "outputId": "4324c6ec-f799-4834-9737-20984d152273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Identified sensitive layers: ['features.0.0', 'features.1.0', 'features.2.0', 'features.3.0', 'features.4.0', 'features.5.0', 'features.6.0', 'features.7.0']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "=> Original model channels: [512, 512, 512, 256, 256, 128, 128, 64, 32]\n",
            "=> Pruning with ratios: [0.9906233717369908, 0.953602809460789, 0.9959995808799639, 0.9992080947482034, 0.9909331715860172, 0.994755145681448, 0.9953378771359748, 0.9964389715331048, 0.9995704233334626]\n",
            "=> Channels after pruning: [507, 488, 510, 256, 254, 127, 127, 64, 32]\n",
            "\u001b[92m New best reward: -2.3032, acc: 86.0400, compress: 0.9648\u001b[00m\n",
            "\u001b[92m New best policy: [0.9906233717369908, 0.953602809460789, 0.9959995808799639, 0.9992080947482034, 0.9909331715860172, 0.994755145681448, 0.9953378771359748, 0.9964389715331048, 0.9995704233334626]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [508, 489, 510, 255, 254, 127, 127, 63, 31]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_cifar_sensitivity_r0.5_ep200_search/mobilenet_cifar_sensitivity_r0.5_ep200_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pry0iqKyeE6c",
        "outputId": "1c4779b3-7263-4155-82bf-4cd28862bf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_cifar_sensitivity_r0.5_ep200_search/mobilenet_cifar_sensitivity_r0.5_ep200_search.pt...\n",
            "=> Model Parameter: 0.782 M, FLOPs: 14.397M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_cifar_sensitivity_r0.5_ep200_search/mobilenet_cifar_sensitivity_r0.5_ep200_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training mobilenet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/mobilenet_cifar_finetune-run12\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 148ms | Tot: 23s442ms | Loss: 0.493 | Acc1: 82.820% | Acc5: 99.249% 352/352 \n",
            " [=======================================>]  Step: 54ms | Tot: 623ms | Loss: 0.417 | Acc1: 85.280% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.28\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 8ms | Tot: 23s685ms | Loss: 0.480 | Acc1: 83.178% | Acc5: 99.322% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 601ms | Loss: 0.417 | Acc1: 85.600% | Acc5: 99.360% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 66ms | Tot: 23s574ms | Loss: 0.476 | Acc1: 83.111% | Acc5: 99.296% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 612ms | Loss: 0.412 | Acc1: 85.500% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 39ms | Tot: 23s523ms | Loss: 0.477 | Acc1: 83.229% | Acc5: 99.324% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 621ms | Loss: 0.413 | Acc1: 85.420% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 8ms | Tot: 23s434ms | Loss: 0.473 | Acc1: 83.396% | Acc5: 99.304% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 602ms | Loss: 0.410 | Acc1: 85.380% | Acc5: 99.440% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 9ms | Tot: 23s587ms | Loss: 0.471 | Acc1: 83.449% | Acc5: 99.322% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 569ms | Loss: 0.410 | Acc1: 85.520% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 8ms | Tot: 23s495ms | Loss: 0.472 | Acc1: 83.480% | Acc5: 99.347% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 702ms | Loss: 0.412 | Acc1: 85.300% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 65ms | Tot: 23s454ms | Loss: 0.463 | Acc1: 83.560% | Acc5: 99.376% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 570ms | Loss: 0.411 | Acc1: 85.480% | Acc5: 99.420% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 8ms | Tot: 23s326ms | Loss: 0.462 | Acc1: 83.709% | Acc5: 99.362% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 593ms | Loss: 0.409 | Acc1: 85.440% | Acc5: 99.480% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 9ms | Tot: 23s472ms | Loss: 0.468 | Acc1: 83.764% | Acc5: 99.353% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 568ms | Loss: 0.406 | Acc1: 85.600% | Acc5: 99.460% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 8ms | Tot: 23s612ms | Loss: 0.462 | Acc1: 83.718% | Acc5: 99.380% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 585ms | Loss: 0.407 | Acc1: 85.540% | Acc5: 99.520% 40/40 \n",
            "Current best acc: 85.6\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 66ms | Tot: 23s628ms | Loss: 0.458 | Acc1: 84.131% | Acc5: 99.411% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 639ms | Loss: 0.407 | Acc1: 85.860% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 9ms | Tot: 23s611ms | Loss: 0.458 | Acc1: 84.051% | Acc5: 99.384% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 565ms | Loss: 0.406 | Acc1: 85.520% | Acc5: 99.520% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 8ms | Tot: 23s290ms | Loss: 0.456 | Acc1: 83.967% | Acc5: 99.362% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 573ms | Loss: 0.407 | Acc1: 85.520% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 9ms | Tot: 23s481ms | Loss: 0.452 | Acc1: 84.051% | Acc5: 99.389% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 577ms | Loss: 0.405 | Acc1: 85.660% | Acc5: 99.540% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 8ms | Tot: 23s368ms | Loss: 0.456 | Acc1: 84.133% | Acc5: 99.442% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 578ms | Loss: 0.406 | Acc1: 85.560% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 66ms | Tot: 23s848ms | Loss: 0.452 | Acc1: 84.089% | Acc5: 99.404% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 581ms | Loss: 0.406 | Acc1: 85.460% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 9ms | Tot: 23s372ms | Loss: 0.450 | Acc1: 84.164% | Acc5: 99.420% 352/352 \n",
            " [=======================================>]  Step: 2ms | Tot: 590ms | Loss: 0.408 | Acc1: 85.540% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 8ms | Tot: 23s495ms | Loss: 0.451 | Acc1: 84.327% | Acc5: 99.389% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 582ms | Loss: 0.406 | Acc1: 85.560% | Acc5: 99.500% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 12ms | Tot: 23s55ms | Loss: 0.449 | Acc1: 84.351% | Acc5: 99.453% 352/352 \n",
            " [=======================================>]  Step: 3ms | Tot: 643ms | Loss: 0.406 | Acc1: 85.740% | Acc5: 99.560% 40/40 \n",
            "Current best acc: 85.86\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_finetune-run12/ckpt.pth.tar\n",
            "=> Model Parameter: 0.782 M, FLOPs: 14.397M, best top-1 acc: 85.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_finetune-run12', 'mobilenet_sensitivty_r0.5_ep200_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBGRr6Z1eE6c",
        "outputId": "425f8b19-17a4-49c7-da88-c8834e4ef78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/mobilenet_cifar_finetune-run12 to mobilenet_sensitivty_r0.5_ep200_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity, rbound=0.8"
      ],
      "metadata": {
        "id": "8bYcV3ynho_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --rbound=0.8 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=300 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --init_delta=1.0 \\\n",
        "    --delta_decay=0.99 \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --seed=10000 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_R_unEhslK",
        "outputId": "b278a59b-5bd4-47a3-d809-7de8af91cc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "Identified sensitive layers: ['conv1.0', 'features.0.0', 'features.1.0', 'features.2.0', 'features.3.0', 'features.4.0', 'features.5.0', 'features.6.0', 'features.7.0']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 86.040%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "=> Saving logs to ./logs/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run3\n",
            "=> Output path: ./logs/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run3...\n",
            "** Actual replay buffer size: 900\n",
            "\u001b[92m New best reward: -8.8686, acc: 44.7600, compress: 0.6188\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.41936359483482594, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 410, 410, 205, 205, 103, 54, 52, 26]\u001b[00m\n",
            "#0: episode_reward:-8.8686 acc: 44.7600, ratio: 0.6188\n",
            "New best clamped policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631]\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-12.7311 acc: 17.9200, ratio: 0.3591\n",
            "#2: episode_reward:-12.1668 acc: 21.8600, ratio: 0.3813\n",
            "#3: episode_reward:-12.1887 acc: 22.4200, ratio: 0.4388\n",
            "#4: episode_reward:-12.0180 acc: 22.1200, ratio: 0.3318\n",
            "#5: episode_reward:-12.2207 acc: 20.0800, ratio: 0.2884\n",
            "#6: episode_reward:-12.8041 acc: 19.5400, ratio: 0.5373\n",
            "#7: episode_reward:-12.8876 acc: 15.1600, ratio: 0.2607\n",
            "#8: episode_reward:-13.6332 acc: 13.8600, ratio: 0.4927\n",
            "#9: episode_reward:-13.0274 acc: 16.8000, ratio: 0.4161\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#10: episode_reward:-11.5956 acc: 26.4800, ratio: 0.4664\n",
            "#11: episode_reward:-13.7969 acc: 12.0200, ratio: 0.4262\n",
            "#12: episode_reward:-13.3530 acc: 15.1800, ratio: 0.4529\n",
            "#13: episode_reward:-11.7493 acc: 25.5600, ratio: 0.4719\n",
            "#14: episode_reward:-12.4304 acc: 21.3400, ratio: 0.4810\n",
            "#15: episode_reward:-12.8988 acc: 17.6600, ratio: 0.4192\n",
            "#16: episode_reward:-9.5327 acc: 40.6800, ratio: 0.6283\n",
            "#17: episode_reward:-13.0358 acc: 17.6600, ratio: 0.4951\n",
            "#18: episode_reward:-12.2614 acc: 23.0200, ratio: 0.5451\n",
            "#19: episode_reward:-14.1793 acc: 8.5400, ratio: 0.3565\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#20: episode_reward:-9.2714 acc: 41.5600, ratio: 0.5117\n",
            "#21: episode_reward:-13.7582 acc: 11.7800, ratio: 0.3909\n",
            "#22: episode_reward:-13.7758 acc: 12.8400, ratio: 0.4821\n",
            "#23: episode_reward:-11.8342 acc: 25.3800, ratio: 0.5089\n",
            "#24: episode_reward:-13.6287 acc: 10.6000, ratio: 0.2752\n",
            "#25: episode_reward:-12.0694 acc: 22.5600, ratio: 0.3870\n",
            "#26: episode_reward:-13.5468 acc: 11.4200, ratio: 0.2890\n",
            "#27: episode_reward:-13.2417 acc: 16.6000, ratio: 0.5182\n",
            "#28: episode_reward:-10.9150 acc: 30.0400, ratio: 0.3934\n",
            "#29: episode_reward:-9.6510 acc: 39.9400, ratio: 0.6276\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#30: episode_reward:-13.5930 acc: 13.3000, ratio: 0.4246\n",
            "#31: episode_reward:-13.5515 acc: 14.5800, ratio: 0.5116\n",
            "#32: episode_reward:-13.0096 acc: 16.9600, ratio: 0.4198\n",
            "#33: episode_reward:-14.1852 acc: 11.1000, ratio: 0.5608\n",
            "#34: episode_reward:-13.5530 acc: 15.3200, ratio: 0.5887\n",
            "#35: episode_reward:-13.2334 acc: 17.1800, ratio: 0.5734\n",
            "#36: episode_reward:-13.9209 acc: 10.2800, ratio: 0.3610\n",
            "#37: episode_reward:-14.0448 acc: 11.1600, ratio: 0.4840\n",
            "#38: episode_reward:-13.1841 acc: 14.7400, ratio: 0.3425\n",
            "#39: episode_reward:-12.0237 acc: 23.7200, ratio: 0.4620\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#40: episode_reward:-13.7694 acc: 11.2600, ratio: 0.3613\n",
            "#41: episode_reward:-13.7792 acc: 13.3600, ratio: 0.5322\n",
            "#42: episode_reward:-13.6061 acc: 13.6600, ratio: 0.4602\n",
            "#43: episode_reward:-12.5038 acc: 21.7800, ratio: 0.5774\n",
            "#44: episode_reward:-13.4341 acc: 14.4600, ratio: 0.4362\n",
            "#45: episode_reward:-12.6188 acc: 20.2400, ratio: 0.4898\n",
            "#46: episode_reward:-13.0096 acc: 16.9600, ratio: 0.4198\n",
            "#47: episode_reward:-13.3993 acc: 15.7400, ratio: 0.5313\n",
            "#48: episode_reward:-13.8464 acc: 9.9200, ratio: 0.3124\n",
            "#49: episode_reward:-10.1865 acc: 36.0800, ratio: 0.5497\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#50: episode_reward:-13.7456 acc: 12.8000, ratio: 0.4624\n",
            "#51: episode_reward:-11.5177 acc: 26.4800, ratio: 0.4195\n",
            "#52: episode_reward:-11.2411 acc: 29.3800, ratio: 0.5395\n",
            "#53: episode_reward:-11.9193 acc: 24.1000, ratio: 0.4357\n",
            "#54: episode_reward:-13.8793 acc: 10.2600, ratio: 0.3435\n",
            "#55: episode_reward:-12.1494 acc: 23.8800, ratio: 0.5634\n",
            "#56: episode_reward:-11.1072 acc: 30.6800, ratio: 0.5995\n",
            "#57: episode_reward:-13.4288 acc: 14.2800, ratio: 0.4194\n",
            "#58: episode_reward:-13.8990 acc: 9.7200, ratio: 0.3200\n",
            "\u001b[92m New best reward: -7.3733, acc: 53.7600, compress: 0.5549\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.5095048579020626, 0.8, 0.7974626680180504, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 410, 261, 205, 205, 103, 103, 52, 26]\u001b[00m\n",
            "#59: episode_reward:-7.3733 acc: 53.7600, ratio: 0.5549\n",
            "New best clamped policy: [0.9, 0.9035947355086894, 0.5095048579020626, 0.9, 0.7974626680180504, 0.9, 0.8570348745235581, 0.9, 0.8238256244014492]\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#60: episode_reward:-13.6916 acc: 11.7400, ratio: 0.3599\n",
            "#61: episode_reward:-12.7101 acc: 19.8400, ratio: 0.5072\n",
            "#62: episode_reward:-13.6658 acc: 13.4200, ratio: 0.4720\n",
            "\u001b[92m New best reward: -5.9606, acc: 62.7200, compress: 0.5792\u001b[00m\n",
            "\u001b[92m New best policy: [0.5627478881669523, 0.8, 0.7346086336580893, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [289, 410, 377, 205, 205, 103, 103, 52, 26]\u001b[00m\n",
            "#63: episode_reward:-5.9606 acc: 62.7200, ratio: 0.5792\n",
            "New best clamped policy: [0.5627478881669523, 0.9, 0.7346086336580893, 0.9, 0.9196580853505114, 0.9, 0.9706298824559081, 0.9, 0.8853384964917524]\n",
            "#64: episode_reward:-12.1403 acc: 22.3600, ratio: 0.4074\n",
            "#65: episode_reward:-13.7882 acc: 10.4800, ratio: 0.3223\n",
            "#66: episode_reward:-13.2326 acc: 14.4600, ratio: 0.3446\n",
            "#67: episode_reward:-10.7323 acc: 32.4000, ratio: 0.5176\n",
            "#68: episode_reward:-13.2595 acc: 14.8000, ratio: 0.3784\n",
            "#69: episode_reward:-12.8104 acc: 18.3200, ratio: 0.4270\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#70: episode_reward:-12.3773 acc: 21.9000, ratio: 0.5032\n",
            "#71: episode_reward:-13.2736 acc: 15.3200, ratio: 0.4233\n",
            "#72: episode_reward:-13.7579 acc: 11.5200, ratio: 0.3732\n",
            "#73: episode_reward:-7.4032 acc: 53.5600, ratio: 0.5525\n",
            "#74: episode_reward:-8.9255 acc: 44.0600, ratio: 0.5603\n",
            "#75: episode_reward:-12.0490 acc: 24.7200, ratio: 0.5891\n",
            "#76: episode_reward:-12.0536 acc: 21.5000, ratio: 0.3073\n",
            "#77: episode_reward:-9.4927 acc: 40.0600, ratio: 0.4977\n",
            "#78: episode_reward:-13.7276 acc: 10.2200, ratio: 0.2881\n",
            "#79: episode_reward:-13.0059 acc: 16.7400, ratio: 0.4010\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#80: episode_reward:-13.4341 acc: 14.7000, ratio: 0.4559\n",
            "#81: episode_reward:-12.7217 acc: 18.7600, ratio: 0.4167\n",
            "#82: episode_reward:-13.8623 acc: 10.9400, ratio: 0.3792\n",
            "#83: episode_reward:-12.7388 acc: 15.6400, ratio: 0.2383\n",
            "#84: episode_reward:-13.1980 acc: 14.6600, ratio: 0.3432\n",
            "#85: episode_reward:-11.6185 acc: 25.0000, ratio: 0.3522\n",
            "#86: episode_reward:-14.1373 acc: 10.5600, ratio: 0.4827\n",
            "#87: episode_reward:-13.6685 acc: 14.3200, ratio: 0.5589\n",
            "#88: episode_reward:-13.4039 acc: 13.2400, ratio: 0.3378\n",
            "#89: episode_reward:-12.8806 acc: 18.7800, ratio: 0.5087\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#90: episode_reward:-13.0001 acc: 16.9000, ratio: 0.4103\n",
            "#91: episode_reward:-13.3263 acc: 16.0600, ratio: 0.5175\n",
            "#92: episode_reward:-11.7927 acc: 25.7800, ratio: 0.5242\n",
            "#93: episode_reward:-11.2661 acc: 28.8400, ratio: 0.4953\n",
            "#94: episode_reward:-8.1156 acc: 49.2400, ratio: 0.5789\n",
            "#95: episode_reward:-12.2596 acc: 21.7600, ratio: 0.4209\n",
            "#96: episode_reward:-13.8390 acc: 11.1200, ratio: 0.3812\n",
            "#97: episode_reward:-13.8866 acc: 11.9600, ratio: 0.4669\n",
            "#98: episode_reward:-13.8204 acc: 12.4400, ratio: 0.4720\n",
            "#99: episode_reward:-13.5621 acc: 13.7600, ratio: 0.4454\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#100: episode_reward:-13.9542 acc: 9.4600, ratio: 0.3255\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-9.3482 acc: 41.2600, ratio: 0.5379\n",
            "#102: episode_reward:-12.7798 acc: 18.1400, ratio: 0.3973\n",
            "#103: episode_reward:-12.4460 acc: 20.2800, ratio: 0.3975\n",
            "#104: episode_reward:-12.3564 acc: 20.9400, ratio: 0.4043\n",
            "#105: episode_reward:-13.8875 acc: 10.6600, ratio: 0.3715\n",
            "#106: episode_reward:-13.7374 acc: 12.5800, ratio: 0.4402\n",
            "#107: episode_reward:-14.2801 acc: 10.4000, ratio: 0.5504\n",
            "#108: episode_reward:-12.0888 acc: 24.0200, ratio: 0.5357\n",
            "#109: episode_reward:-7.6009 acc: 52.4800, ratio: 0.5830\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#110: episode_reward:-13.6946 acc: 13.9000, ratio: 0.5330\n",
            "#111: episode_reward:-13.4010 acc: 16.0600, ratio: 0.5656\n",
            "#112: episode_reward:-11.6852 acc: 26.6200, ratio: 0.5431\n",
            "#113: episode_reward:-12.0542 acc: 24.2800, ratio: 0.5405\n",
            "#114: episode_reward:-12.9941 acc: 18.5400, ratio: 0.5581\n",
            "#115: episode_reward:-12.6201 acc: 19.6800, ratio: 0.4393\n",
            "#116: episode_reward:-13.6604 acc: 13.0200, ratio: 0.4362\n",
            "#117: episode_reward:-10.7406 acc: 31.7800, ratio: 0.4536\n",
            "#118: episode_reward:-8.5017 acc: 47.0800, ratio: 0.6253\n",
            "#119: episode_reward:-13.4644 acc: 14.8000, ratio: 0.4812\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#120: episode_reward:-11.3855 acc: 29.0800, ratio: 0.6183\n",
            "#121: episode_reward:-11.3816 acc: 27.4600, ratio: 0.4297\n",
            "#122: episode_reward:-13.1597 acc: 15.7400, ratio: 0.3998\n",
            "#123: episode_reward:-13.7145 acc: 13.0000, ratio: 0.4626\n",
            "#124: episode_reward:-6.6592 acc: 58.6600, ratio: 0.6529\n",
            "#125: episode_reward:-10.1862 acc: 36.5400, ratio: 0.6167\n",
            "#126: episode_reward:-11.7826 acc: 25.9400, ratio: 0.5352\n",
            "#127: episode_reward:-14.2918 acc: 10.4400, ratio: 0.5616\n",
            "#128: episode_reward:-12.4452 acc: 22.3400, ratio: 0.6008\n",
            "#129: episode_reward:-13.0780 acc: 16.5400, ratio: 0.4211\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#130: episode_reward:-13.4996 acc: 15.2800, ratio: 0.5486\n",
            "#131: episode_reward:-13.4916 acc: 13.4600, ratio: 0.3888\n",
            "#132: episode_reward:-13.6985 acc: 12.0800, ratio: 0.3852\n",
            "#133: episode_reward:-13.5000 acc: 11.1000, ratio: 0.2595\n",
            "#134: episode_reward:-9.8355 acc: 38.3200, ratio: 0.5550\n",
            "#135: episode_reward:-10.2733 acc: 34.9000, ratio: 0.4705\n",
            "#136: episode_reward:-14.0244 acc: 10.3600, ratio: 0.4109\n",
            "#137: episode_reward:-10.8906 acc: 31.0800, ratio: 0.4805\n",
            "#138: episode_reward:-11.5304 acc: 25.1400, ratio: 0.3223\n",
            "#139: episode_reward:-13.6889 acc: 10.4800, ratio: 0.2884\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#140: episode_reward:-8.4883 acc: 47.0400, ratio: 0.6023\n",
            "#141: episode_reward:-13.4521 acc: 14.2000, ratio: 0.4247\n",
            "#142: episode_reward:-10.9320 acc: 31.7400, ratio: 0.5948\n",
            "#143: episode_reward:-7.9599 acc: 49.7600, ratio: 0.5011\n",
            "#144: episode_reward:-10.9564 acc: 30.8600, ratio: 0.5026\n",
            "#145: episode_reward:-13.5465 acc: 12.9200, ratio: 0.3759\n",
            "#146: episode_reward:-11.1462 acc: 30.2000, ratio: 0.5678\n",
            "#147: episode_reward:-13.6768 acc: 13.2400, ratio: 0.4627\n",
            "#148: episode_reward:-13.8204 acc: 11.4600, ratio: 0.3963\n",
            "#149: episode_reward:-10.2447 acc: 35.1800, ratio: 0.4820\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#150: episode_reward:-13.2640 acc: 17.1000, ratio: 0.5858\n",
            "#151: episode_reward:-12.0077 acc: 24.4800, ratio: 0.5301\n",
            "#152: episode_reward:-12.6786 acc: 18.0600, ratio: 0.3459\n",
            "#153: episode_reward:-13.3442 acc: 14.1800, ratio: 0.3732\n",
            "#154: episode_reward:-11.1425 acc: 29.2400, ratio: 0.4548\n",
            "#155: episode_reward:-10.9397 acc: 29.7000, ratio: 0.3779\n",
            "#156: episode_reward:-10.7456 acc: 31.7000, ratio: 0.4485\n",
            "#157: episode_reward:-13.7588 acc: 11.8800, ratio: 0.3981\n",
            "#158: episode_reward:-14.1871 acc: 10.2200, ratio: 0.4806\n",
            "#159: episode_reward:-12.9309 acc: 18.4600, ratio: 0.5085\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#160: episode_reward:-13.7557 acc: 12.8000, ratio: 0.4677\n",
            "#161: episode_reward:-12.1045 acc: 24.4000, ratio: 0.5925\n",
            "#162: episode_reward:-11.3331 acc: 27.8000, ratio: 0.4326\n",
            "#163: episode_reward:-8.9343 acc: 44.3800, ratio: 0.6239\n",
            "#164: episode_reward:-12.0680 acc: 24.6200, ratio: 0.5914\n",
            "#165: episode_reward:-13.5296 acc: 15.1600, ratio: 0.5557\n",
            "#166: episode_reward:-8.4998 acc: 46.3200, ratio: 0.4963\n",
            "#167: episode_reward:-11.8626 acc: 25.2600, ratio: 0.5153\n",
            "#168: episode_reward:-6.5587 acc: 59.2600, ratio: 0.6468\n",
            "#169: episode_reward:-14.2608 acc: 10.6200, ratio: 0.5602\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#170: episode_reward:-11.7777 acc: 26.6600, ratio: 0.6215\n",
            "#171: episode_reward:-13.2032 acc: 17.1000, ratio: 0.5444\n",
            "#172: episode_reward:-8.0230 acc: 50.0800, ratio: 0.6294\n",
            "#173: episode_reward:-7.7309 acc: 51.8400, ratio: 0.6175\n",
            "#174: episode_reward:-13.7586 acc: 13.8600, ratio: 0.5699\n",
            "#175: episode_reward:-8.5415 acc: 46.8800, ratio: 0.6344\n",
            "#176: episode_reward:-10.4447 acc: 34.3000, ratio: 0.5288\n",
            "#177: episode_reward:-12.1198 acc: 23.6000, ratio: 0.5111\n",
            "#178: episode_reward:-12.7809 acc: 20.2400, ratio: 0.6001\n",
            "#179: episode_reward:-14.3210 acc: 10.3800, ratio: 0.5740\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#180: episode_reward:-12.4513 acc: 21.3600, ratio: 0.4959\n",
            "#181: episode_reward:-8.4834 acc: 47.0400, ratio: 0.5968\n",
            "#182: episode_reward:-9.7759 acc: 39.2000, ratio: 0.6338\n",
            "#183: episode_reward:-11.0960 acc: 29.8800, ratio: 0.4914\n",
            "#184: episode_reward:-14.2980 acc: 10.7400, ratio: 0.5967\n",
            "#185: episode_reward:-8.5569 acc: 46.7400, ratio: 0.6259\n",
            "#186: episode_reward:-7.9600 acc: 49.9600, ratio: 0.5340\n",
            "#187: episode_reward:-13.5988 acc: 14.5000, ratio: 0.5327\n",
            "#188: episode_reward:-12.8753 acc: 18.1600, ratio: 0.4482\n",
            "#189: episode_reward:-7.8771 acc: 50.5600, ratio: 0.5476\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#190: episode_reward:-9.8721 acc: 37.5800, ratio: 0.4872\n",
            "#191: episode_reward:-7.0281 acc: 56.3400, ratio: 0.6458\n",
            "#192: episode_reward:-12.0235 acc: 24.8400, ratio: 0.5842\n",
            "#193: episode_reward:-9.9118 acc: 38.1800, ratio: 0.6056\n",
            "#194: episode_reward:-12.5264 acc: 21.6400, ratio: 0.5775\n",
            "#195: episode_reward:-8.8049 acc: 44.5600, ratio: 0.5206\n",
            "#196: episode_reward:-13.2733 acc: 17.2400, ratio: 0.6087\n",
            "#197: episode_reward:-7.7143 acc: 51.4200, ratio: 0.5193\n",
            "#198: episode_reward:-7.8677 acc: 51.0400, ratio: 0.6280\n",
            "#199: episode_reward:-8.2844 acc: 48.3600, ratio: 0.6113\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#200: episode_reward:-14.2458 acc: 10.6200, ratio: 0.5508\n",
            "#201: episode_reward:-8.1500 acc: 48.9800, ratio: 0.5709\n",
            "#202: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#203: episode_reward:-10.4889 acc: 34.3400, ratio: 0.5711\n",
            "#204: episode_reward:-12.8747 acc: 19.2800, ratio: 0.5572\n",
            "#205: episode_reward:-8.3699 acc: 47.2200, ratio: 0.5083\n",
            "#206: episode_reward:-8.2628 acc: 47.9000, ratio: 0.5091\n",
            "#207: episode_reward:-13.0355 acc: 18.5600, ratio: 0.5895\n",
            "#208: episode_reward:-7.3719 acc: 54.1000, ratio: 0.6225\n",
            "#209: episode_reward:-12.7885 acc: 16.6000, ratio: 0.3009\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#210: episode_reward:-13.7480 acc: 13.1400, ratio: 0.4931\n",
            "#211: episode_reward:-9.3223 acc: 41.7800, ratio: 0.5930\n",
            "#212: episode_reward:-10.3713 acc: 35.4800, ratio: 0.6311\n",
            "#213: episode_reward:-9.1780 acc: 41.9800, ratio: 0.4887\n",
            "#214: episode_reward:-8.9674 acc: 43.9800, ratio: 0.5902\n",
            "#215: episode_reward:-10.7904 acc: 32.7000, ratio: 0.6057\n",
            "#216: episode_reward:-13.2803 acc: 16.4400, ratio: 0.5265\n",
            "#217: episode_reward:-9.7094 acc: 39.5200, ratio: 0.6183\n",
            "#218: episode_reward:-6.9764 acc: 56.5200, ratio: 0.6129\n",
            "#219: episode_reward:-10.7681 acc: 32.2600, ratio: 0.5281\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#220: episode_reward:-10.0138 acc: 37.7800, ratio: 0.6437\n",
            "#221: episode_reward:-13.4762 acc: 14.4800, ratio: 0.4599\n",
            "#222: episode_reward:-6.6196 acc: 58.8600, ratio: 0.6413\n",
            "#223: episode_reward:-8.2602 acc: 48.5400, ratio: 0.6169\n",
            "#224: episode_reward:-6.9320 acc: 56.8800, ratio: 0.6321\n",
            "#225: episode_reward:-8.8010 acc: 45.2200, ratio: 0.6258\n",
            "#226: episode_reward:-8.5381 acc: 46.5000, ratio: 0.5624\n",
            "#227: episode_reward:-11.8857 acc: 25.4400, ratio: 0.5523\n",
            "#228: episode_reward:-9.8975 acc: 38.3800, ratio: 0.6234\n",
            "#229: episode_reward:-6.5646 acc: 59.2200, ratio: 0.6459\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#230: episode_reward:-8.8280 acc: 45.1600, ratio: 0.6460\n",
            "#231: episode_reward:-9.8406 acc: 38.6200, ratio: 0.6051\n",
            "#232: episode_reward:-6.5580 acc: 59.1600, ratio: 0.6207\n",
            "#233: episode_reward:-6.5229 acc: 59.4800, ratio: 0.6461\n",
            "#234: episode_reward:-8.0102 acc: 49.6600, ratio: 0.5366\n",
            "#235: episode_reward:-7.8484 acc: 50.8600, ratio: 0.5694\n",
            "#236: episode_reward:-11.3653 acc: 29.3000, ratio: 0.6317\n",
            "#237: episode_reward:-6.6546 acc: 58.6400, ratio: 0.6406\n",
            "#238: episode_reward:-6.5587 acc: 59.2600, ratio: 0.6468\n",
            "#239: episode_reward:-7.6975 acc: 51.8400, ratio: 0.5761\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#240: episode_reward:-6.7999 acc: 57.7400, ratio: 0.6414\n",
            "#241: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#242: episode_reward:-6.7510 acc: 58.0800, ratio: 0.6503\n",
            "#243: episode_reward:-7.4195 acc: 53.7400, ratio: 0.6090\n",
            "#244: episode_reward:-8.2960 acc: 47.9200, ratio: 0.5459\n",
            "#245: episode_reward:-7.1229 acc: 55.4800, ratio: 0.5855\n",
            "#246: episode_reward:-6.5502 acc: 59.3000, ratio: 0.6435\n",
            "#247: episode_reward:-7.6100 acc: 52.6600, ratio: 0.6316\n",
            "#248: episode_reward:-6.7295 acc: 58.2200, ratio: 0.6520\n",
            "#249: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#250: episode_reward:-6.7510 acc: 58.0800, ratio: 0.6503\n",
            "#251: episode_reward:-8.0976 acc: 49.0000, ratio: 0.5184\n",
            "#252: episode_reward:-6.7510 acc: 58.0800, ratio: 0.6503\n",
            "#253: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#254: episode_reward:-6.5989 acc: 58.9400, ratio: 0.6292\n",
            "#255: episode_reward:-8.6614 acc: 45.3600, ratio: 0.5051\n",
            "#256: episode_reward:-6.4632 acc: 59.8200, ratio: 0.6382\n",
            "#257: episode_reward:-8.4834 acc: 47.2400, ratio: 0.6341\n",
            "#258: episode_reward:-7.6959 acc: 51.9200, ratio: 0.5896\n",
            "#259: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#260: episode_reward:-7.6283 acc: 52.6200, ratio: 0.6476\n",
            "#261: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#262: episode_reward:-7.1341 acc: 55.6800, ratio: 0.6453\n",
            "#263: episode_reward:-6.4987 acc: 59.6400, ratio: 0.6487\n",
            "#264: episode_reward:-7.6283 acc: 52.6200, ratio: 0.6476\n",
            "#265: episode_reward:-7.1853 acc: 55.3200, ratio: 0.6357\n",
            "#266: episode_reward:-6.5602 acc: 59.2400, ratio: 0.6439\n",
            "#267: episode_reward:-6.9034 acc: 57.1000, ratio: 0.6421\n",
            "#268: episode_reward:-7.8357 acc: 50.9600, ratio: 0.5731\n",
            "#269: episode_reward:-7.5135 acc: 53.3000, ratio: 0.6403\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#270: episode_reward:-6.7794 acc: 57.9000, ratio: 0.6494\n",
            "#271: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#272: episode_reward:-8.8280 acc: 45.1600, ratio: 0.6460\n",
            "#273: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#274: episode_reward:-6.6530 acc: 58.7000, ratio: 0.6532\n",
            "#275: episode_reward:-6.4874 acc: 59.7200, ratio: 0.6512\n",
            "#276: episode_reward:-6.5364 acc: 59.4200, ratio: 0.6522\n",
            "#277: episode_reward:-8.3495 acc: 48.0600, ratio: 0.6317\n",
            "#278: episode_reward:-7.2660 acc: 54.6400, ratio: 0.5968\n",
            "#279: episode_reward:-6.6282 acc: 58.7800, ratio: 0.6346\n",
            "[Train] Sensitive layer indices: [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#280: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#281: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#282: episode_reward:-6.5135 acc: 59.5600, ratio: 0.6518\n",
            "#283: episode_reward:-6.6524 acc: 58.6800, ratio: 0.6473\n",
            "#284: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#285: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#286: episode_reward:-6.8225 acc: 57.6400, ratio: 0.6513\n",
            "#287: episode_reward:-6.9651 acc: 56.7200, ratio: 0.6430\n",
            "#288: episode_reward:-6.9338 acc: 56.9400, ratio: 0.6492\n",
            "#289: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "[Train] Sensitive layer indices: [1, 3, 5, 7, 9, 11, 13, 15]\n",
            "#290: episode_reward:-6.4032 acc: 60.2400, ratio: 0.6505\n",
            "#291: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#292: episode_reward:-7.6038 acc: 52.6600, ratio: 0.6233\n",
            "#293: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#294: episode_reward:-6.5826 acc: 59.1200, ratio: 0.6489\n",
            "#295: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#296: episode_reward:-6.9869 acc: 56.6000, ratio: 0.6467\n",
            "#297: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#298: episode_reward:-6.5374 acc: 59.4200, ratio: 0.6539\n",
            "#299: episode_reward:-6.7592 acc: 58.0200, ratio: 0.6481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run3', 'mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.zip')"
      ],
      "metadata": {
        "id": "bqSCpQimfwMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff5e690-4a70-40fd-a4ae-ccac6bdcd63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The zip file 'mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.zip' already exists. Please choose a different name or delete the existing file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --policy_path=./checkpoints/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "id": "VDwWPv-Cd0x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/mobilenet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt"
      ],
      "metadata": {
        "id": "iLPM5P3yd0x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/mobilenet_cifar_finetune-run', 'mobilenet_sensitivity_r0.5_rbound0.8_ep300_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "id": "GOzUTJoId0x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "JpNRWg58XGBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Weights"
      ],
      "metadata": {
        "id": "o7OiUtYZpm4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/download_resnet_weights.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7ea0bf-43bf-4c5d-d134-bdf660dadd09",
        "id": "3znIXUwWpm4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/state_dict/resnet_cifar.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMC Baseline"
      ],
      "metadata": {
        "id": "paMa_PH6pm4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=train \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=200 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ac239b-4d90-4d4a-aa94-40c8d6130b18",
        "id": "ffss1ZTKpm4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Saving logs to ./logs/resnet_cifar_sensitivity_r0.5_ep200_search-run1\n",
            "=> Output path: ./logs/resnet_cifar_sensitivity_r0.5_ep200_search-run1...\n",
            "** Actual replay buffer size: 1100\n",
            "\u001b[92m New best reward: -4.4119, acc: 76.1000, compress: 0.7382\u001b[00m\n",
            "\u001b[92m New best policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.8962211148428955, 0.875450813354181]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 160, 127, 51, 60, 127, 54, 255, 220, 459, 449]\u001b[00m\n",
            "#0: episode_reward:-4.4119 acc: 76.1000, ratio: 0.7382\n",
            "New best clamped policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.8962211148428955, 0.875450813354181]\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-15.3568 acc: 11.7000, ratio: 0.2537\n",
            "#2: episode_reward:-14.5707 acc: 18.9400, ratio: 0.4548\n",
            "#3: episode_reward:-15.7891 acc: 10.5000, ratio: 0.3257\n",
            "#4: episode_reward:-15.3931 acc: 13.1600, ratio: 0.3544\n",
            "#5: episode_reward:-13.3427 acc: 25.4200, ratio: 0.4178\n",
            "#6: episode_reward:-13.3165 acc: 25.8000, ratio: 0.4420\n",
            "#7: episode_reward:-13.5801 acc: 23.4800, ratio: 0.3620\n",
            "#8: episode_reward:-15.3474 acc: 14.2200, ratio: 0.4183\n",
            "#9: episode_reward:-14.7940 acc: 17.4400, ratio: 0.4300\n",
            "#10: episode_reward:-15.5283 acc: 13.8800, ratio: 0.4808\n",
            "#11: episode_reward:-13.6013 acc: 24.2400, ratio: 0.4448\n",
            "#12: episode_reward:-13.1711 acc: 27.1200, ratio: 0.5011\n",
            "#13: episode_reward:-14.3255 acc: 19.6800, ratio: 0.3955\n",
            "#14: episode_reward:-15.1649 acc: 14.0600, ratio: 0.3272\n",
            "#15: episode_reward:-15.8657 acc: 10.7600, ratio: 0.3736\n",
            "#16: episode_reward:-15.6237 acc: 11.1400, ratio: 0.3070\n",
            "#17: episode_reward:-15.0235 acc: 15.0000, ratio: 0.3367\n",
            "#18: episode_reward:-15.8416 acc: 10.7600, ratio: 0.3637\n",
            "#19: episode_reward:-15.3121 acc: 14.1800, ratio: 0.3981\n",
            "#20: episode_reward:-14.8867 acc: 16.9200, ratio: 0.4297\n",
            "#21: episode_reward:-14.5889 acc: 18.2800, ratio: 0.4021\n",
            "#22: episode_reward:-15.5370 acc: 10.8600, ratio: 0.2636\n",
            "#23: episode_reward:-14.7642 acc: 17.2600, ratio: 0.3989\n",
            "#24: episode_reward:-14.1479 acc: 20.3200, ratio: 0.3652\n",
            "#25: episode_reward:-15.4529 acc: 10.9200, ratio: 0.2427\n",
            "#26: episode_reward:-13.0104 acc: 26.7600, ratio: 0.3682\n",
            "#27: episode_reward:-12.6966 acc: 29.3000, ratio: 0.4472\n",
            "#28: episode_reward:-15.0897 acc: 15.6200, ratio: 0.4147\n",
            "#29: episode_reward:-15.3432 acc: 12.6000, ratio: 0.2988\n",
            "#30: episode_reward:-15.0638 acc: 14.0000, ratio: 0.2873\n",
            "#31: episode_reward:-15.5211 acc: 12.4600, ratio: 0.3560\n",
            "#32: episode_reward:-15.4316 acc: 12.0200, ratio: 0.2943\n",
            "#33: episode_reward:-15.8308 acc: 10.9200, ratio: 0.3709\n",
            "#34: episode_reward:-14.2546 acc: 18.6200, ratio: 0.2873\n",
            "#35: episode_reward:-15.5680 acc: 12.7600, ratio: 0.3992\n",
            "#36: episode_reward:-15.9332 acc: 10.7400, ratio: 0.4014\n",
            "#37: episode_reward:-15.9133 acc: 10.9200, ratio: 0.4069\n",
            "#38: episode_reward:-14.4275 acc: 19.3000, ratio: 0.4126\n",
            "#39: episode_reward:-15.7565 acc: 10.4800, ratio: 0.3128\n",
            "#40: episode_reward:-12.4158 acc: 31.0000, ratio: 0.4633\n",
            "#41: episode_reward:-15.2192 acc: 14.0000, ratio: 0.3442\n",
            "#42: episode_reward:-14.7117 acc: 17.4400, ratio: 0.3891\n",
            "#43: episode_reward:-15.1915 acc: 14.4600, ratio: 0.3665\n",
            "#44: episode_reward:-15.4235 acc: 12.0400, ratio: 0.2927\n",
            "#45: episode_reward:-15.5252 acc: 12.5800, ratio: 0.3665\n",
            "#46: episode_reward:-12.4596 acc: 31.2400, ratio: 0.5258\n",
            "#47: episode_reward:-11.9637 acc: 33.0400, ratio: 0.4081\n",
            "#48: episode_reward:-15.1476 acc: 13.3600, ratio: 0.2781\n",
            "#49: episode_reward:-15.1335 acc: 15.0000, ratio: 0.3832\n",
            "#50: episode_reward:-14.9287 acc: 15.8800, ratio: 0.3619\n",
            "#51: episode_reward:-15.8850 acc: 10.5600, ratio: 0.3669\n",
            "#52: episode_reward:-7.9066 acc: 56.4000, ratio: 0.5333\n",
            "#53: episode_reward:-13.1627 acc: 25.7000, ratio: 0.3508\n",
            "#54: episode_reward:-15.7677 acc: 11.9200, ratio: 0.4225\n",
            "#55: episode_reward:-15.6205 acc: 12.2800, ratio: 0.3845\n",
            "#56: episode_reward:-15.3603 acc: 14.6200, ratio: 0.4618\n",
            "#57: episode_reward:-13.2023 acc: 26.7200, ratio: 0.4738\n",
            "#58: episode_reward:-15.1487 acc: 14.0000, ratio: 0.3171\n",
            "#59: episode_reward:-15.7007 acc: 10.9400, ratio: 0.3218\n",
            "#60: episode_reward:-14.2221 acc: 20.3600, ratio: 0.4045\n",
            "#61: episode_reward:-9.1296 acc: 49.8600, ratio: 0.5741\n",
            "#62: episode_reward:-15.6140 acc: 12.0400, ratio: 0.3635\n",
            "#63: episode_reward:-15.9209 acc: 10.3800, ratio: 0.3685\n",
            "#64: episode_reward:-15.4073 acc: 13.3400, ratio: 0.3738\n",
            "#65: episode_reward:-14.0847 acc: 21.0400, ratio: 0.3964\n",
            "#66: episode_reward:-15.7469 acc: 11.4200, ratio: 0.3730\n",
            "#67: episode_reward:-15.2233 acc: 12.4200, ratio: 0.2513\n",
            "#68: episode_reward:-15.5011 acc: 12.2600, ratio: 0.3342\n",
            "#69: episode_reward:-14.9253 acc: 13.0600, ratio: 0.2027\n",
            "#70: episode_reward:-11.4395 acc: 36.5600, ratio: 0.4814\n",
            "#71: episode_reward:-14.4515 acc: 20.2600, ratio: 0.5273\n",
            "#72: episode_reward:-14.7493 acc: 17.7200, ratio: 0.4328\n",
            "#73: episode_reward:-9.7287 acc: 46.1600, ratio: 0.4998\n",
            "#74: episode_reward:-14.3409 acc: 18.7200, ratio: 0.3265\n",
            "#75: episode_reward:-15.2335 acc: 14.7600, ratio: 0.4099\n",
            "#76: episode_reward:-15.3149 acc: 14.3000, ratio: 0.4095\n",
            "#77: episode_reward:-15.3103 acc: 13.8400, ratio: 0.3702\n",
            "#78: episode_reward:-12.1100 acc: 32.9000, ratio: 0.4890\n",
            "#79: episode_reward:-13.1796 acc: 25.2200, ratio: 0.3202\n",
            "#80: episode_reward:-14.9475 acc: 16.3800, ratio: 0.4116\n",
            "#81: episode_reward:-15.8282 acc: 10.9800, ratio: 0.3743\n",
            "#82: episode_reward:-15.3375 acc: 10.6200, ratio: 0.2012\n",
            "#83: episode_reward:-9.4446 acc: 48.2600, ratio: 0.6010\n",
            "#84: episode_reward:-15.3708 acc: 13.3200, ratio: 0.3569\n",
            "#85: episode_reward:-15.2428 acc: 11.6000, ratio: 0.2187\n",
            "#86: episode_reward:-15.6133 acc: 9.5200, ratio: 0.2215\n",
            "#87: episode_reward:-15.1993 acc: 13.6400, ratio: 0.3125\n",
            "#88: episode_reward:-13.0002 acc: 27.5000, ratio: 0.4352\n",
            "#89: episode_reward:-13.9566 acc: 22.1800, ratio: 0.4366\n",
            "#90: episode_reward:-15.5618 acc: 11.6800, ratio: 0.3187\n",
            "#91: episode_reward:-13.8205 acc: 22.7200, ratio: 0.4150\n",
            "#92: episode_reward:-12.5873 acc: 29.5400, ratio: 0.4071\n",
            "#93: episode_reward:-15.4700 acc: 11.9200, ratio: 0.3013\n",
            "#94: episode_reward:-14.5796 acc: 18.2000, ratio: 0.3908\n",
            "#95: episode_reward:-13.7674 acc: 22.6400, ratio: 0.3804\n",
            "#96: episode_reward:-12.9696 acc: 27.8200, ratio: 0.4517\n",
            "#97: episode_reward:-13.8686 acc: 22.5600, ratio: 0.4256\n",
            "#98: episode_reward:-15.6020 acc: 11.1800, ratio: 0.3020\n",
            "#99: episode_reward:-15.1461 acc: 14.7200, ratio: 0.3669\n",
            "#100: episode_reward:-11.6274 acc: 34.4600, ratio: 0.3598\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-14.9169 acc: 14.1600, ratio: 0.2502\n",
            "#102: episode_reward:-14.8399 acc: 17.5200, ratio: 0.4625\n",
            "#103: episode_reward:-11.0143 acc: 38.7800, ratio: 0.4621\n",
            "#104: episode_reward:-14.8346 acc: 15.4800, ratio: 0.2977\n",
            "#105: episode_reward:-13.1157 acc: 26.7800, ratio: 0.4272\n",
            "#106: episode_reward:-11.4069 acc: 36.3800, ratio: 0.4346\n",
            "#107: episode_reward:-15.3637 acc: 11.8800, ratio: 0.2649\n",
            "#108: episode_reward:-14.2206 acc: 22.1400, ratio: 0.6072\n",
            "#109: episode_reward:-15.4920 acc: 11.8800, ratio: 0.3065\n",
            "#110: episode_reward:-12.9205 acc: 29.0400, ratio: 0.5741\n",
            "#111: episode_reward:-6.4849 acc: 64.5800, ratio: 0.6347\n",
            "#112: episode_reward:-11.4271 acc: 36.8000, ratio: 0.5054\n",
            "#113: episode_reward:-8.0252 acc: 55.9400, ratio: 0.5776\n",
            "#114: episode_reward:-11.0156 acc: 39.6200, ratio: 0.5948\n",
            "#115: episode_reward:-6.2698 acc: 65.8800, ratio: 0.6787\n",
            "#116: episode_reward:-8.6321 acc: 53.0600, ratio: 0.6883\n",
            "#117: episode_reward:-6.0581 acc: 67.2400, ratio: 0.7627\n",
            "\u001b[92m New best reward: -3.7627, acc: 79.5400, compress: 0.6889\u001b[00m\n",
            "\u001b[92m New best policy: [0.7709614617499051, 0.7839841065603356, 0.9940920173633521, 0.9369461426508774, 0.7781427457252795, 0.6278668549822513, 0.8079530777966415, 0.8145764407189747, 0.4890996921018355, 0.7179805773584267, 0.8073947147729676]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [395, 201, 127, 60, 50, 81, 104, 209, 126, 368, 414]\u001b[00m\n",
            "#118: episode_reward:-3.7627 acc: 79.5400, ratio: 0.6889\n",
            "New best clamped policy: [0.7709614617499051, 0.7839841065603356, 0.9940920173633521, 0.9369461426508774, 0.7781427457252795, 0.6278668549822513, 0.8079530777966415, 0.8145764407189747, 0.4890996921018355, 0.7179805773584267, 0.8073947147729676]\n",
            "#119: episode_reward:-7.4263 acc: 59.4800, ratio: 0.6468\n",
            "\u001b[92m New best reward: -3.3290, acc: 82.0000, compress: 0.7643\u001b[00m\n",
            "\u001b[92m New best policy: [0.7609590521520663, 0.9248328089761633, 0.9183789668433898, 0.7176029121195584, 0.944361713855711, 0.8423699443124697, 0.846541012510317, 0.8233956346977082, 0.8194724328724543, 0.6748028728813932, 0.9264195609746225]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [390, 237, 118, 46, 61, 108, 109, 211, 210, 346, 475]\u001b[00m\n",
            "#120: episode_reward:-3.3290 acc: 82.0000, ratio: 0.7643\n",
            "New best clamped policy: [0.7609590521520663, 0.9248328089761633, 0.9183789668433898, 0.7176029121195584, 0.944361713855711, 0.8423699443124697, 0.846541012510317, 0.8233956346977082, 0.8194724328724543, 0.6748028728813932, 0.9264195609746225]\n",
            "#121: episode_reward:-3.5552 acc: 80.6400, ratio: 0.6705\n",
            "#122: episode_reward:-4.5525 acc: 75.3800, ratio: 0.7617\n",
            "\u001b[92m New best reward: -2.3718, acc: 87.2400, compress: 0.8388\u001b[00m\n",
            "\u001b[92m New best policy: [0.9684553612329947, 0.7898735871219567, 0.9840399901479693, 0.980768934624507, 0.9546921888899671, 0.8050412737314141, 0.8961691956181054, 0.9533423432580709, 0.8719078302690992, 0.8893530433781094, 0.7258931058783379]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [496, 203, 126, 63, 62, 104, 115, 245, 224, 456, 372]\u001b[00m\n",
            "#123: episode_reward:-2.3718 acc: 87.2400, ratio: 0.8388\n",
            "New best clamped policy: [0.9684553612329947, 0.7898735871219567, 0.9840399901479693, 0.980768934624507, 0.9546921888899671, 0.8050412737314141, 0.8961691956181054, 0.9533423432580709, 0.8719078302690992, 0.8893530433781094, 0.7258931058783379]\n",
            "\u001b[92m New best reward: -2.3599, acc: 87.2600, compress: 0.7866\u001b[00m\n",
            "\u001b[92m New best policy: [0.9777545085489153, 0.7984209692153268, 0.986970386534819, 0.9208705395644666, 0.8186534236985312, 0.882370643909624, 0.7672454947635536, 0.9240820067819419, 0.9557110284541915, 0.8145484498590698, 0.5780787835298091]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 205, 127, 59, 53, 113, 99, 237, 245, 418, 296]\u001b[00m\n",
            "#124: episode_reward:-2.3599 acc: 87.2600, ratio: 0.7866\n",
            "New best clamped policy: [0.9777545085489153, 0.7984209692153268, 0.986970386534819, 0.9208705395644666, 0.8186534236985312, 0.882370643909624, 0.7672454947635536, 0.9240820067819419, 0.9557110284541915, 0.8145484498590698, 0.5780787835298091]\n",
            "\u001b[92m New best reward: -2.0775, acc: 88.7600, compress: 0.7558\u001b[00m\n",
            "\u001b[92m New best policy: [0.9309061839799011, 0.8309602519436629, 0.9788118489707814, 0.9566912688130109, 0.7323866524425976, 0.9611053572422176, 0.8868014905906971, 0.8118518581690746, 0.7996072272238736, 0.8480469825076433, 0.3923327816957924]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [477, 213, 126, 62, 47, 124, 114, 208, 205, 435, 201]\u001b[00m\n",
            "#125: episode_reward:-2.0775 acc: 88.7600, ratio: 0.7558\n",
            "New best clamped policy: [0.9309061839799011, 0.8309602519436629, 0.9788118489707814, 0.9566912688130109, 0.7323866524425976, 0.9611053572422176, 0.8868014905906971, 0.8118518581690746, 0.7996072272238736, 0.8480469825076433, 0.3923327816957924]\n",
            "#126: episode_reward:-3.6068 acc: 80.5400, ratio: 0.7956\n",
            "#127: episode_reward:-3.2927 acc: 82.2600, ratio: 0.8169\n",
            "#128: episode_reward:-2.2406 acc: 87.9400, ratio: 0.8318\n",
            "#129: episode_reward:-4.2331 acc: 77.0400, ratio: 0.7217\n",
            "#130: episode_reward:-3.1756 acc: 82.8800, ratio: 0.8074\n",
            "#131: episode_reward:-2.1598 acc: 88.3600, ratio: 0.8119\n",
            "#132: episode_reward:-2.3870 acc: 87.1200, ratio: 0.7938\n",
            "\u001b[92m New best reward: -1.8676, acc: 89.9800, compress: 0.8828\u001b[00m\n",
            "\u001b[92m New best policy: [0.9457017640832851, 0.9508778446138201, 0.9590863764392131, 0.9608939488838832, 0.9893234002683589, 0.9864257124747207, 0.9538555841839221, 0.926724470918656, 0.9774900930007647, 0.9680888290539477, 0.5160620137455337]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [485, 244, 123, 62, 63, 127, 123, 238, 251, 496, 265]\u001b[00m\n",
            "#133: episode_reward:-1.8676 acc: 89.9800, ratio: 0.8828\n",
            "New best clamped policy: [0.9457017640832851, 0.9508778446138201, 0.9590863764392131, 0.9608939488838832, 0.9893234002683589, 0.9864257124747207, 0.9538555841839221, 0.926724470918656, 0.9774900930007647, 0.9680888290539477, 0.5160620137455337]\n",
            "#134: episode_reward:-1.9420 acc: 89.5600, ratio: 0.8505\n",
            "#135: episode_reward:-2.0689 acc: 88.8600, ratio: 0.8261\n",
            "#136: episode_reward:-2.3593 acc: 87.3000, ratio: 0.8301\n",
            "#137: episode_reward:-2.0587 acc: 88.9400, ratio: 0.8610\n",
            "\u001b[92m New best reward: -1.7394, acc: 90.6800, compress: 0.9050\u001b[00m\n",
            "\u001b[92m New best policy: [0.9781244156831315, 0.9833319672759498, 0.9979956185412754, 0.9752991474608297, 0.9909926809975617, 0.9941141603775517, 0.9418778959972298, 0.8485346675418909, 0.9579231492429878, 0.9516061672736188, 0.6324331216831157]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 252, 127, 63, 63, 127, 121, 218, 246, 488, 324]\u001b[00m\n",
            "#138: episode_reward:-1.7394 acc: 90.6800, ratio: 0.9050\n",
            "New best clamped policy: [0.9781244156831315, 0.9833319672759498, 0.9979956185412754, 0.9752991474608297, 0.9909926809975617, 0.9941141603775517, 0.9418778959972298, 0.8485346675418909, 0.9579231492429878, 0.9516061672736188, 0.6324331216831157]\n",
            "#139: episode_reward:-1.8139 acc: 90.2600, ratio: 0.8691\n",
            "#140: episode_reward:-2.1907 acc: 88.2400, ratio: 0.8740\n",
            "#141: episode_reward:-1.7966 acc: 90.3600, ratio: 0.8809\n",
            "#142: episode_reward:-2.0464 acc: 89.0200, ratio: 0.8823\n",
            "#143: episode_reward:-2.0052 acc: 89.2400, ratio: 0.8802\n",
            "#144: episode_reward:-1.8337 acc: 90.1600, ratio: 0.8798\n",
            "#145: episode_reward:-2.1362 acc: 88.5400, ratio: 0.8844\n",
            "#146: episode_reward:-2.0163 acc: 89.1800, ratio: 0.8793\n",
            "#147: episode_reward:-1.9660 acc: 89.4400, ratio: 0.8640\n",
            "#148: episode_reward:-1.8389 acc: 90.1600, ratio: 0.9278\n",
            "\u001b[92m New best reward: -1.7329, acc: 90.7200, compress: 0.9141\u001b[00m\n",
            "\u001b[92m New best policy: [0.9678422030675854, 0.9936456031367626, 0.9703066003787177, 0.9702569798715158, 0.9937654846869208, 0.9867122010677281, 0.9731447365002754, 0.9637572479391237, 0.9842365796921267, 0.9408569323569044, 0.5875023625550914]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [496, 255, 125, 63, 63, 127, 125, 247, 252, 482, 301]\u001b[00m\n",
            "#149: episode_reward:-1.7329 acc: 90.7200, ratio: 0.9141\n",
            "New best clamped policy: [0.9678422030675854, 0.9936456031367626, 0.9703066003787177, 0.9702569798715158, 0.9937654846869208, 0.9867122010677281, 0.9731447365002754, 0.9637572479391237, 0.9842365796921267, 0.9408569323569044, 0.5875023625550914]\n",
            "#150: episode_reward:-1.9192 acc: 89.7200, ratio: 0.9106\n",
            "#151: episode_reward:-1.7505 acc: 90.6200, ratio: 0.9035\n",
            "\u001b[92m New best reward: -1.7323, acc: 90.7200, compress: 0.9079\u001b[00m\n",
            "\u001b[92m New best policy: [0.9989627799763019, 0.9852352880999389, 0.9872653160001007, 0.9242417399131729, 0.9565110895423318, 0.9381826499777602, 0.9783662043580529, 0.98346682866188, 0.994001474280507, 0.9899982558129479, 0.5225804544321007]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 253, 127, 60, 62, 121, 126, 252, 255, 507, 268]\u001b[00m\n",
            "#152: episode_reward:-1.7323 acc: 90.7200, ratio: 0.9079\n",
            "#153: episode_reward:-1.8465 acc: 90.1000, ratio: 0.8944\n",
            "#154: episode_reward:-1.7513 acc: 90.6200, ratio: 0.9114\n",
            "#155: episode_reward:-1.8000 acc: 90.3600, ratio: 0.9126\n",
            "#156: episode_reward:-1.7447 acc: 90.6600, ratio: 0.9197\n",
            "#157: episode_reward:-1.7619 acc: 90.5600, ratio: 0.9056\n",
            "\u001b[92m New best reward: -1.7148, acc: 90.8200, compress: 0.9204\u001b[00m\n",
            "\u001b[92m New best policy: [0.9424067054094349, 0.9933862595053218, 0.9781457319510133, 0.9717362910065055, 0.9754198603536227, 0.9790189475568772, 0.9925054755411683, 0.9693583756820625, 0.9816952978496449, 0.986279424361955, 0.6012495138168642]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [483, 255, 126, 63, 63, 126, 127, 249, 252, 505, 308]\u001b[00m\n",
            "#158: episode_reward:-1.7148 acc: 90.8200, ratio: 0.9204\n",
            "New best clamped policy: [0.9424067054094349, 0.9933862595053218, 0.9781457319510133, 0.9717362910065055, 0.9754198603536227, 0.9790189475568772, 0.9925054755411683, 0.9693583756820625, 0.9816952978496449, 0.986279424361955, 0.6012495138168642]\n",
            "#159: episode_reward:-1.7709 acc: 90.5200, ratio: 0.9201\n",
            "\u001b[92m New best reward: -1.7044, acc: 90.8800, compress: 0.9277\u001b[00m\n",
            "\u001b[92m New best policy: [0.9966341535855667, 0.9829308561658249, 0.986724313740944, 0.9888634948792672, 0.9697900871456414, 0.9986161404470777, 0.9902121540802812, 0.9547001369911884, 0.993592128650748, 0.9757172930560845, 0.6033244120473256]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 252, 127, 63, 63, 127, 127, 245, 255, 500, 309]\u001b[00m\n",
            "#160: episode_reward:-1.7044 acc: 90.8800, ratio: 0.9277\n",
            "New best clamped policy: [0.9966341535855667, 0.9829308561658249, 0.986724313740944, 0.9888634948792672, 0.9697900871456414, 0.9986161404470777, 0.9902121540802812, 0.9547001369911884, 0.993592128650748, 0.9757172930560845, 0.6033244120473256]\n",
            "#161: episode_reward:-1.7742 acc: 90.5000, ratio: 0.9162\n",
            "\u001b[92m New best reward: -1.7034, acc: 90.8800, compress: 0.9179\u001b[00m\n",
            "\u001b[92m New best policy: [0.9558170647425406, 0.9843770489346418, 0.9991363841238513, 0.9762642600288268, 0.9740117109653871, 0.9948653303565205, 0.9990645531033525, 0.995570234236805, 0.993989152528403, 0.981395168338837, 0.5326117468276537]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [490, 253, 127, 63, 63, 127, 127, 255, 255, 503, 273]\u001b[00m\n",
            "#162: episode_reward:-1.7034 acc: 90.8800, ratio: 0.9179\n",
            "#163: episode_reward:-1.7533 acc: 90.6200, ratio: 0.9311\n",
            "#164: episode_reward:-1.7214 acc: 90.7800, ratio: 0.9112\n",
            "#165: episode_reward:-1.7747 acc: 90.5000, ratio: 0.9215\n",
            "#166: episode_reward:-1.7528 acc: 90.6200, ratio: 0.9262\n",
            "#167: episode_reward:-1.7123 acc: 90.8400, ratio: 0.9325\n",
            "#168: episode_reward:-1.7083 acc: 90.8600, ratio: 0.9295\n",
            "#169: episode_reward:-1.7235 acc: 90.7800, ratio: 0.9325\n",
            "#170: episode_reward:-1.7339 acc: 90.7200, ratio: 0.9241\n",
            "#171: episode_reward:-1.7301 acc: 90.7400, ratio: 0.9233\n",
            "\u001b[92m New best reward: -1.6894, acc: 90.9600, compress: 0.9280\u001b[00m\n",
            "\u001b[92m New best policy: [0.9997167452889055, 0.9946738186056527, 0.9946423378825089, 0.9899660026459252, 0.9917296803366825, 0.9904286913194985, 0.9757245434044374, 0.9816304978168106, 0.9823077877636103, 0.9938055263585134, 0.576180905792334]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 255, 127, 63, 63, 127, 125, 252, 252, 509, 296]\u001b[00m\n",
            "#172: episode_reward:-1.6894 acc: 90.9600, ratio: 0.9280\n",
            "New best clamped policy: [0.9997167452889055, 0.9946738186056527, 0.9946423378825089, 0.9899660026459252, 0.9917296803366825, 0.9904286913194985, 0.9757245434044374, 0.9816304978168106, 0.9823077877636103, 0.9938055263585134, 0.576180905792334]\n",
            "#173: episode_reward:-1.7126 acc: 90.8400, ratio: 0.9356\n",
            "#174: episode_reward:-1.7227 acc: 90.7800, ratio: 0.9243\n",
            "#175: episode_reward:-1.7158 acc: 90.8200, ratio: 0.9300\n",
            "#176: episode_reward:-1.7123 acc: 90.8400, ratio: 0.9320\n",
            "#177: episode_reward:-1.7088 acc: 90.8600, ratio: 0.9348\n",
            "#178: episode_reward:-1.7268 acc: 90.7600, ratio: 0.9279\n",
            "#179: episode_reward:-1.7192 acc: 90.8000, ratio: 0.9271\n",
            "#180: episode_reward:-1.7232 acc: 90.7800, ratio: 0.9293\n",
            "#181: episode_reward:-1.7080 acc: 90.8600, ratio: 0.9264\n",
            "#182: episode_reward:-1.7195 acc: 90.8000, ratio: 0.9291\n",
            "#183: episode_reward:-1.7124 acc: 90.8400, ratio: 0.9332\n",
            "#184: episode_reward:-1.7308 acc: 90.7400, ratio: 0.9308\n",
            "#185: episode_reward:-1.7267 acc: 90.7600, ratio: 0.9273\n",
            "#186: episode_reward:-1.7347 acc: 90.7200, ratio: 0.9325\n",
            "#187: episode_reward:-1.7192 acc: 90.8000, ratio: 0.9269\n",
            "#188: episode_reward:-1.7307 acc: 90.7400, ratio: 0.9298\n",
            "#189: episode_reward:-1.7387 acc: 90.7000, ratio: 0.9350\n",
            "#190: episode_reward:-1.7269 acc: 90.7600, ratio: 0.9286\n",
            "#191: episode_reward:-1.6967 acc: 90.9200, ratio: 0.9258\n",
            "#192: episode_reward:-1.7309 acc: 90.7400, ratio: 0.9312\n",
            "#193: episode_reward:-1.7346 acc: 90.7200, ratio: 0.9313\n",
            "#194: episode_reward:-1.7119 acc: 90.8400, ratio: 0.9281\n",
            "#195: episode_reward:-1.7347 acc: 90.7200, ratio: 0.9321\n",
            "#196: episode_reward:-1.7347 acc: 90.7200, ratio: 0.9319\n",
            "#197: episode_reward:-1.7349 acc: 90.7200, ratio: 0.9340\n",
            "#198: episode_reward:-1.7270 acc: 90.7600, ratio: 0.9303\n",
            "#199: episode_reward:-1.7156 acc: 90.8200, ratio: 0.9278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_amc_r0.5_ep200_search-run1', 'resnet_amc_r0.5_ep200_search.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT_GRO9qpm4g",
        "outputId": "a1d1ded7-2ca6-46d4-cf2b-fb17417d3682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/amc3/logs/resnet_cifar_amc_r0.5_ep200_search-run1' successfully zipped to 'resnet_amc_r0.5_ep200_search.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=export \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --policy_path=./checkpoints/resnet_amc_r0.5_ep200_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/resnet_amc_r0.5_ep200_search/resnet_amc_r0.5_ep200_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b84f7d6-e9c3-4715-914c-f2ea78b7c30b",
        "id": "TijHrtLrpm4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Original model channels: [512, 256, 128, 64, 64, 128, 128, 256, 256, 512, 512]\n",
            "=> Pruning with ratios: [0.9997167452889055, 0.9946738186056527, 0.9946423378825089, 0.9899660026459252, 0.9917296803366825, 0.9904286913194985, 0.9757245434044374, 0.9816304978168106, 0.9823077877636103, 0.9938055263585134, 0.576180905792334]\n",
            "=> Channels after pruning: [511, 255, 127, 63, 63, 127, 125, 252, 252, 509, 296]\n",
            "\u001b[92m New best reward: -1.6894, acc: 90.9600, compress: 0.9280\u001b[00m\n",
            "\u001b[92m New best policy: [0.9997167452889055, 0.9946738186056527, 0.9946423378825089, 0.9899660026459252, 0.9917296803366825, 0.9904286913194985, 0.9757245434044374, 0.9816304978168106, 0.9823077877636103, 0.9938055263585134, 0.576180905792334]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 255, 127, 63, 63, 127, 125, 252, 252, 509, 296]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/resnet_amc_r0.5_ep200_search/resnet_amc_r0.5_ep200_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThycuGnnE3J7",
        "outputId": "ffcd3a62-31bd-41b1-eb31-79fa0a50ab95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_amc_r0.5_ep200_search/resnet_amc_r0.5_ep200_search.pt...\n",
            "=> Model Parameter: 9.091 M, FLOPs: 130.237M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_amc_r0.5_ep200_search/resnet_amc_r0.5_ep200_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training resnet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/resnet_cifar_finetune-run4\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 435ms | Tot: 23s676ms | Loss: 0.290 | Acc1: 90.178% | Acc5: 99.767% 352/352 \n",
            " [=======================================>]  Step: 137ms | Tot: 704ms | Loss: 0.288 | Acc1: 90.520% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 90.52\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 13ms | Tot: 23s3ms | Loss: 0.276 | Acc1: 90.453% | Acc5: 99.751% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 564ms | Loss: 0.302 | Acc1: 90.140% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.52\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 56ms | Tot: 22s970ms | Loss: 0.266 | Acc1: 90.869% | Acc5: 99.789% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 559ms | Loss: 0.294 | Acc1: 90.620% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.62\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 56ms | Tot: 22s968ms | Loss: 0.256 | Acc1: 91.056% | Acc5: 99.822% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 566ms | Loss: 0.295 | Acc1: 90.460% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.62\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 48ms | Tot: 23s466ms | Loss: 0.253 | Acc1: 91.131% | Acc5: 99.800% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 569ms | Loss: 0.285 | Acc1: 90.680% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 59ms | Tot: 23s33ms | Loss: 0.243 | Acc1: 91.662% | Acc5: 99.798% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 556ms | Loss: 0.285 | Acc1: 90.680% | Acc5: 99.580% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 55ms | Tot: 23s417ms | Loss: 0.237 | Acc1: 91.824% | Acc5: 99.827% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 582ms | Loss: 0.277 | Acc1: 90.640% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 13ms | Tot: 23s155ms | Loss: 0.221 | Acc1: 92.387% | Acc5: 99.867% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 599ms | Loss: 0.289 | Acc1: 90.660% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 13ms | Tot: 22s919ms | Loss: 0.216 | Acc1: 92.460% | Acc5: 99.871% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 574ms | Loss: 0.270 | Acc1: 91.200% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.2\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 56ms | Tot: 23s595ms | Loss: 0.206 | Acc1: 92.780% | Acc5: 99.889% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 574ms | Loss: 0.266 | Acc1: 91.440% | Acc5: 99.740% 40/40 \n",
            "Current best acc: 91.44\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 55ms | Tot: 23s307ms | Loss: 0.196 | Acc1: 93.058% | Acc5: 99.913% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 578ms | Loss: 0.275 | Acc1: 91.200% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 91.44\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 13ms | Tot: 23s123ms | Loss: 0.185 | Acc1: 93.556% | Acc5: 99.898% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 578ms | Loss: 0.272 | Acc1: 90.900% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.44\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 57ms | Tot: 23s66ms | Loss: 0.179 | Acc1: 93.789% | Acc5: 99.904% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 566ms | Loss: 0.252 | Acc1: 91.640% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 91.64\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 54ms | Tot: 22s835ms | Loss: 0.172 | Acc1: 94.076% | Acc5: 99.891% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 577ms | Loss: 0.261 | Acc1: 91.500% | Acc5: 99.740% 40/40 \n",
            "Current best acc: 91.64\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 13ms | Tot: 22s896ms | Loss: 0.167 | Acc1: 94.342% | Acc5: 99.913% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 581ms | Loss: 0.261 | Acc1: 91.580% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 91.64\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 13ms | Tot: 23s323ms | Loss: 0.158 | Acc1: 94.464% | Acc5: 99.909% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 576ms | Loss: 0.248 | Acc1: 92.120% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 92.12\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 54ms | Tot: 23s243ms | Loss: 0.154 | Acc1: 94.649% | Acc5: 99.940% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 573ms | Loss: 0.251 | Acc1: 92.320% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 92.32\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 34ms | Tot: 23s204ms | Loss: 0.150 | Acc1: 94.782% | Acc5: 99.936% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 563ms | Loss: 0.251 | Acc1: 91.860% | Acc5: 99.740% 40/40 \n",
            "Current best acc: 92.32\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 13ms | Tot: 23s135ms | Loss: 0.151 | Acc1: 94.847% | Acc5: 99.933% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 585ms | Loss: 0.250 | Acc1: 92.000% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.32\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 13ms | Tot: 23s275ms | Loss: 0.151 | Acc1: 94.713% | Acc5: 99.931% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 594ms | Loss: 0.248 | Acc1: 92.020% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 92.32\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run4/ckpt.pth.tar\n",
            "=> Model Parameter: 9.091 M, FLOPs: 130.237M, best top-1 acc: 92.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_finetune-run4', 'resnet_amc_r0.5_ep200_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmnK6yQcUTQs",
        "outputId": "1912ae1a-fd67-4a4b-b81d-0c515e0bae4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/resnet_cifar_finetune-run4 to resnet_amc_r0.5_ep200_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "checkpoint = torch.load('/content/amc3/logs/resnet_cifar_finetune-run1/ckpt.best.pth.tar', map_location=device)\n",
        "print(\"Loaded keys:\", checkpoint.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGK1irJuGw4u",
        "outputId": "0e1086e3-10d7-4343-f6bb-6d5c607fac51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded keys: dict_keys(['epoch', 'model', 'dataset', 'state_dict', 'acc', 'optimizer'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AMC, rbound=0.8"
      ],
      "metadata": {
        "id": "6T0nn5_r36qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=train \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --rbound=0.8 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=300 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --init_delta=1.0 \\\n",
        "    --delta_decay=0.99 \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --seed=10000 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVN6Xm8q38l5",
        "outputId": "6b2d98ab-cd64-4e79-85ad-fef695591305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Saving logs to ./logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run4\n",
            "=> Output path: ./logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run4...\n",
            "** Actual replay buffer size: 1100\n",
            "\u001b[92m New best reward: -9.2875, acc: 49.2200, compress: 0.6228\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.6212741278231493, 0.8, 0.7946774141029013, 0.8, 0.8, 0.41936359483482594, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 160, 103, 51, 52, 103, 54, 205, 205, 410, 410]\u001b[00m\n",
            "#0: episode_reward:-9.2875 acc: 49.2200, ratio: 0.6228\n",
            "New best clamped policy: [0.9000162887906149, 0.6212741278231493, 1.0, 0.7946774141029013, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.8962211148428955, 0.875450813354181]\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-15.3350 acc: 11.6800, ratio: 0.2465\n",
            "#2: episode_reward:-14.7993 acc: 17.3600, ratio: 0.4253\n",
            "#3: episode_reward:-15.7891 acc: 10.5000, ratio: 0.3257\n",
            "#4: episode_reward:-15.7414 acc: 10.6200, ratio: 0.3162\n",
            "#5: episode_reward:-13.5602 acc: 24.0600, ratio: 0.4038\n",
            "#6: episode_reward:-13.6011 acc: 23.7000, ratio: 0.3916\n",
            "#7: episode_reward:-13.9450 acc: 21.1600, ratio: 0.3411\n",
            "#8: episode_reward:-15.3451 acc: 13.8200, ratio: 0.3839\n",
            "#9: episode_reward:-14.8013 acc: 17.0000, ratio: 0.3944\n",
            "#10: episode_reward:-15.0887 acc: 15.7200, ratio: 0.4231\n",
            "#11: episode_reward:-13.7969 acc: 23.0600, ratio: 0.4355\n",
            "#12: episode_reward:-12.6532 acc: 29.6800, ratio: 0.4632\n",
            "#13: episode_reward:-15.1327 acc: 14.7000, ratio: 0.3597\n",
            "#14: episode_reward:-15.1534 acc: 14.0800, ratio: 0.3242\n",
            "#15: episode_reward:-15.8253 acc: 10.9000, ratio: 0.3672\n",
            "#16: episode_reward:-15.6992 acc: 10.6400, ratio: 0.3028\n",
            "#17: episode_reward:-15.1097 acc: 14.2600, ratio: 0.3197\n",
            "#18: episode_reward:-15.7904 acc: 10.6000, ratio: 0.3327\n",
            "#19: episode_reward:-15.5919 acc: 12.4600, ratio: 0.3860\n",
            "#20: episode_reward:-15.0146 acc: 15.5800, ratio: 0.3762\n",
            "#21: episode_reward:-14.5641 acc: 18.2600, ratio: 0.3884\n",
            "#22: episode_reward:-15.5138 acc: 10.7000, ratio: 0.2489\n",
            "#23: episode_reward:-14.9558 acc: 15.9400, ratio: 0.3786\n",
            "#24: episode_reward:-14.2830 acc: 19.2800, ratio: 0.3434\n",
            "#25: episode_reward:-15.4673 acc: 10.8000, ratio: 0.2410\n",
            "#26: episode_reward:-13.1970 acc: 25.6200, ratio: 0.3604\n",
            "#27: episode_reward:-12.6723 acc: 29.2600, ratio: 0.4277\n",
            "#28: episode_reward:-15.1067 acc: 15.4200, ratio: 0.4056\n",
            "#29: episode_reward:-15.3492 acc: 12.2600, ratio: 0.2810\n",
            "#30: episode_reward:-14.7236 acc: 15.6800, ratio: 0.2721\n",
            "#31: episode_reward:-15.8269 acc: 10.4600, ratio: 0.3371\n",
            "#32: episode_reward:-15.3821 acc: 12.0200, ratio: 0.2782\n",
            "#33: episode_reward:-15.7454 acc: 11.0800, ratio: 0.3479\n",
            "#34: episode_reward:-14.0573 acc: 19.4600, ratio: 0.2700\n",
            "#35: episode_reward:-15.3660 acc: 13.2600, ratio: 0.3506\n",
            "#36: episode_reward:-15.9022 acc: 10.7000, ratio: 0.3846\n",
            "#37: episode_reward:-15.8387 acc: 10.8600, ratio: 0.3698\n",
            "#38: episode_reward:-14.3739 acc: 19.3000, ratio: 0.3861\n",
            "#39: episode_reward:-15.7379 acc: 10.4800, ratio: 0.3064\n",
            "#40: episode_reward:-12.8258 acc: 28.3200, ratio: 0.4189\n",
            "#41: episode_reward:-15.1436 acc: 14.0600, ratio: 0.3191\n",
            "#42: episode_reward:-15.6215 acc: 12.0600, ratio: 0.3681\n",
            "#43: episode_reward:-14.4938 acc: 18.1800, ratio: 0.3503\n",
            "#44: episode_reward:-15.4674 acc: 11.6800, ratio: 0.2864\n",
            "#45: episode_reward:-15.5045 acc: 12.4400, ratio: 0.3479\n",
            "#46: episode_reward:-11.9863 acc: 33.5600, ratio: 0.4856\n",
            "#47: episode_reward:-12.1592 acc: 31.7400, ratio: 0.3867\n",
            "#48: episode_reward:-15.1311 acc: 13.2000, ratio: 0.2642\n",
            "#49: episode_reward:-15.3152 acc: 13.6400, ratio: 0.3574\n",
            "#50: episode_reward:-14.8974 acc: 16.0200, ratio: 0.3592\n",
            "#51: episode_reward:-15.8709 acc: 10.5600, ratio: 0.3611\n",
            "\u001b[92m New best reward: -9.0864, acc: 49.6800, compress: 0.4936\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.5577234682029315, 0.7936622628579154, 0.4705519659647183, 0.5726945583635141, 0.2914951363044336, 0.5203177754713777, 0.4112964123612815]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 36, 102, 61, 147, 75, 267, 211]\u001b[00m\n",
            "#52: episode_reward:-9.0864 acc: 49.6800, ratio: 0.4936\n",
            "New best clamped policy: [0.8534233469214512, 0.9706298824559081, 0.8437513298392706, 0.8853384964917524, 0.5577234682029315, 0.7936622628579154, 0.4705519659647183, 0.5726945583635141, 0.2914951363044336, 0.5203177754713777, 0.4112964123612815]\n",
            "#53: episode_reward:-13.4749 acc: 23.8000, ratio: 0.3398\n",
            "#54: episode_reward:-15.5158 acc: 13.1000, ratio: 0.4032\n",
            "#55: episode_reward:-15.6205 acc: 12.2800, ratio: 0.3845\n",
            "#56: episode_reward:-15.3884 acc: 14.0400, ratio: 0.4226\n",
            "#57: episode_reward:-13.3317 acc: 25.9000, ratio: 0.4622\n",
            "#58: episode_reward:-15.1782 acc: 13.7000, ratio: 0.3087\n",
            "#59: episode_reward:-15.5992 acc: 11.3000, ratio: 0.3083\n",
            "#60: episode_reward:-14.3689 acc: 19.3000, ratio: 0.3837\n",
            "#61: episode_reward:-9.9588 acc: 44.9000, ratio: 0.5020\n",
            "#62: episode_reward:-15.5747 acc: 11.8400, ratio: 0.3339\n",
            "#63: episode_reward:-15.4960 acc: 12.2200, ratio: 0.3296\n",
            "#64: episode_reward:-15.3665 acc: 13.0800, ratio: 0.3382\n",
            "#65: episode_reward:-14.2551 acc: 19.7600, ratio: 0.3687\n",
            "#66: episode_reward:-15.6687 acc: 11.6600, ratio: 0.3583\n",
            "#67: episode_reward:-15.2221 acc: 12.2600, ratio: 0.2432\n",
            "#68: episode_reward:-15.4746 acc: 12.2600, ratio: 0.3242\n",
            "#69: episode_reward:-14.9090 acc: 13.0200, ratio: 0.1974\n",
            "#70: episode_reward:-11.6447 acc: 35.2600, ratio: 0.4601\n",
            "#71: episode_reward:-15.0124 acc: 16.5400, ratio: 0.4604\n",
            "#72: episode_reward:-15.4098 acc: 13.6000, ratio: 0.3955\n",
            "#73: episode_reward:-9.7868 acc: 45.8200, ratio: 0.4967\n",
            "#74: episode_reward:-14.9682 acc: 14.9800, ratio: 0.3142\n",
            "#75: episode_reward:-15.2239 acc: 14.7400, ratio: 0.4036\n",
            "#76: episode_reward:-15.1022 acc: 14.8400, ratio: 0.3573\n",
            "#77: episode_reward:-15.3195 acc: 13.4200, ratio: 0.3433\n",
            "#78: episode_reward:-11.8056 acc: 34.3600, ratio: 0.4594\n",
            "#79: episode_reward:-13.3451 acc: 24.2400, ratio: 0.3172\n",
            "#80: episode_reward:-14.8623 acc: 16.4000, ratio: 0.3733\n",
            "#81: episode_reward:-15.7577 acc: 11.0800, ratio: 0.3527\n",
            "#82: episode_reward:-15.2790 acc: 10.6200, ratio: 0.1885\n",
            "#83: episode_reward:-11.0129 acc: 39.2600, ratio: 0.5316\n",
            "#84: episode_reward:-15.5692 acc: 11.8600, ratio: 0.3332\n",
            "#85: episode_reward:-15.2300 acc: 11.5800, ratio: 0.2147\n",
            "#86: episode_reward:-15.5021 acc: 9.9200, ratio: 0.2114\n",
            "#87: episode_reward:-15.3899 acc: 12.3600, ratio: 0.3003\n",
            "#88: episode_reward:-12.9823 acc: 27.4400, ratio: 0.4184\n",
            "#89: episode_reward:-13.8872 acc: 22.3400, ratio: 0.4143\n",
            "#90: episode_reward:-15.5318 acc: 11.6800, ratio: 0.3081\n",
            "#91: episode_reward:-14.3664 acc: 19.3000, ratio: 0.3825\n",
            "#92: episode_reward:-12.3144 acc: 30.8800, ratio: 0.3878\n",
            "#93: episode_reward:-15.4645 acc: 11.9000, ratio: 0.2983\n",
            "#94: episode_reward:-15.0224 acc: 15.1800, ratio: 0.3491\n",
            "#95: episode_reward:-14.5393 acc: 18.1800, ratio: 0.3703\n",
            "#96: episode_reward:-13.0221 acc: 27.4400, ratio: 0.4420\n",
            "#97: episode_reward:-15.0851 acc: 15.1800, ratio: 0.3759\n",
            "#98: episode_reward:-15.4682 acc: 11.6200, ratio: 0.2833\n",
            "#99: episode_reward:-15.4046 acc: 13.1200, ratio: 0.3562\n",
            "#100: episode_reward:-11.7236 acc: 33.6800, ratio: 0.3376\n",
            "/content/amc3/amc_search_no_sensitivity.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-15.1328 acc: 12.9200, ratio: 0.2503\n",
            "#102: episode_reward:-15.4463 acc: 13.6400, ratio: 0.4159\n",
            "#103: episode_reward:-11.4165 acc: 36.3200, ratio: 0.4337\n",
            "#104: episode_reward:-14.7830 acc: 15.3400, ratio: 0.2721\n",
            "#105: episode_reward:-14.7263 acc: 16.7800, ratio: 0.3438\n",
            "#106: episode_reward:-12.9005 acc: 27.0800, ratio: 0.3423\n",
            "#107: episode_reward:-15.3585 acc: 10.7800, ratio: 0.2125\n",
            "#108: episode_reward:-14.9100 acc: 16.9600, ratio: 0.4457\n",
            "#109: episode_reward:-15.3277 acc: 10.8800, ratio: 0.2093\n",
            "#110: episode_reward:-15.3301 acc: 14.6000, ratio: 0.4439\n",
            "#111: episode_reward:-14.0157 acc: 21.6800, ratio: 0.4199\n",
            "#112: episode_reward:-15.5156 acc: 12.1600, ratio: 0.3330\n",
            "#113: episode_reward:-15.6006 acc: 12.2600, ratio: 0.3743\n",
            "#114: episode_reward:-15.6238 acc: 10.8800, ratio: 0.2917\n",
            "#115: episode_reward:-13.1807 acc: 25.9200, ratio: 0.3788\n",
            "#116: episode_reward:-15.8890 acc: 10.6800, ratio: 0.3774\n",
            "#117: episode_reward:-15.0074 acc: 16.3000, ratio: 0.4346\n",
            "#118: episode_reward:-15.1509 acc: 14.4400, ratio: 0.3481\n",
            "#119: episode_reward:-15.6243 acc: 10.5800, ratio: 0.2752\n",
            "#120: episode_reward:-11.8774 acc: 33.2800, ratio: 0.3824\n",
            "#121: episode_reward:-14.1110 acc: 19.8200, ratio: 0.3122\n",
            "#122: episode_reward:-14.9795 acc: 15.5200, ratio: 0.3564\n",
            "#123: episode_reward:-14.6123 acc: 19.0400, ratio: 0.4895\n",
            "#124: episode_reward:-15.6676 acc: 11.1400, ratio: 0.3226\n",
            "#125: episode_reward:-14.3856 acc: 19.1000, ratio: 0.3748\n",
            "#126: episode_reward:-15.2427 acc: 14.1400, ratio: 0.3641\n",
            "#127: episode_reward:-15.1662 acc: 13.1800, ratio: 0.2740\n",
            "#128: episode_reward:-14.6907 acc: 18.2600, ratio: 0.4535\n",
            "#129: episode_reward:-15.3541 acc: 10.4800, ratio: 0.1996\n",
            "#130: episode_reward:-15.6826 acc: 11.9400, ratio: 0.3851\n",
            "#131: episode_reward:-14.1664 acc: 18.6400, ratio: 0.2589\n",
            "#132: episode_reward:-15.5143 acc: 12.1400, ratio: 0.3311\n",
            "#133: episode_reward:-9.9982 acc: 44.9600, ratio: 0.5500\n",
            "#134: episode_reward:-14.9868 acc: 16.3600, ratio: 0.4296\n",
            "#135: episode_reward:-14.4553 acc: 18.5600, ratio: 0.3629\n",
            "#136: episode_reward:-14.8303 acc: 16.7400, ratio: 0.3863\n",
            "#137: episode_reward:-13.1677 acc: 26.0000, ratio: 0.3795\n",
            "#138: episode_reward:-12.0932 acc: 33.2200, ratio: 0.5199\n",
            "#139: episode_reward:-14.6982 acc: 17.6800, ratio: 0.4032\n",
            "#140: episode_reward:-15.7881 acc: 11.7200, ratio: 0.4152\n",
            "#141: episode_reward:-11.6777 acc: 35.3800, ratio: 0.5006\n",
            "#142: episode_reward:-15.8225 acc: 11.2200, ratio: 0.3902\n",
            "#143: episode_reward:-15.5122 acc: 12.3200, ratio: 0.3425\n",
            "#144: episode_reward:-14.1783 acc: 20.0400, ratio: 0.3565\n",
            "#145: episode_reward:-15.1821 acc: 13.7800, ratio: 0.3152\n",
            "#146: episode_reward:-15.1408 acc: 14.3400, ratio: 0.3370\n",
            "#147: episode_reward:-15.6945 acc: 11.0200, ratio: 0.3247\n",
            "#148: episode_reward:-14.0843 acc: 22.3600, ratio: 0.5365\n",
            "#149: episode_reward:-12.6855 acc: 29.3600, ratio: 0.4470\n",
            "#150: episode_reward:-15.1563 acc: 15.3800, ratio: 0.4265\n",
            "#151: episode_reward:-14.8016 acc: 17.0800, ratio: 0.4014\n",
            "#152: episode_reward:-14.3296 acc: 19.7600, ratio: 0.4046\n",
            "#153: episode_reward:-15.7611 acc: 11.6600, ratio: 0.3978\n",
            "#154: episode_reward:-15.2337 acc: 14.6600, ratio: 0.4015\n",
            "#155: episode_reward:-15.1895 acc: 14.5200, ratio: 0.3703\n",
            "#156: episode_reward:-9.6043 acc: 46.9000, ratio: 0.5086\n",
            "#157: episode_reward:-15.2940 acc: 14.3000, ratio: 0.3996\n",
            "#158: episode_reward:-13.9010 acc: 21.4000, ratio: 0.3405\n",
            "#159: episode_reward:-15.2368 acc: 13.9400, ratio: 0.3470\n",
            "#160: episode_reward:-13.3259 acc: 25.5600, ratio: 0.4224\n",
            "#161: episode_reward:-15.5424 acc: 11.4800, ratio: 0.2997\n",
            "#162: episode_reward:-10.8256 acc: 39.5000, ratio: 0.4191\n",
            "#163: episode_reward:-14.2198 acc: 21.5600, ratio: 0.5299\n",
            "#164: episode_reward:-13.6863 acc: 23.1600, ratio: 0.3861\n",
            "#165: episode_reward:-13.8611 acc: 22.5200, ratio: 0.4176\n",
            "#166: episode_reward:-15.7807 acc: 11.1600, ratio: 0.3678\n",
            "#167: episode_reward:-12.1848 acc: 32.1600, ratio: 0.4484\n",
            "#168: episode_reward:-14.5445 acc: 18.3000, ratio: 0.3825\n",
            "#169: episode_reward:-12.3832 acc: 31.1400, ratio: 0.4584\n",
            "#170: episode_reward:-15.3863 acc: 14.0400, ratio: 0.4215\n",
            "#171: episode_reward:-15.5476 acc: 10.5800, ratio: 0.2526\n",
            "#172: episode_reward:-14.7266 acc: 16.8800, ratio: 0.3514\n",
            "#173: episode_reward:-14.3457 acc: 19.8800, ratio: 0.4240\n",
            "#174: episode_reward:-15.7920 acc: 10.7400, ratio: 0.3426\n",
            "#175: episode_reward:-14.8028 acc: 15.7400, ratio: 0.3026\n",
            "#176: episode_reward:-15.2917 acc: 13.0600, ratio: 0.3090\n",
            "#177: episode_reward:-13.0808 acc: 26.3800, ratio: 0.3697\n",
            "#178: episode_reward:-14.8695 acc: 15.8600, ratio: 0.3359\n",
            "#179: episode_reward:-12.2844 acc: 31.0800, ratio: 0.3910\n",
            "#180: episode_reward:-11.3691 acc: 37.1200, ratio: 0.5053\n",
            "#181: episode_reward:-13.0991 acc: 26.4800, ratio: 0.3883\n",
            "#182: episode_reward:-13.1486 acc: 26.9400, ratio: 0.4648\n",
            "#183: episode_reward:-15.3505 acc: 13.9400, ratio: 0.3961\n",
            "#184: episode_reward:-15.3805 acc: 13.0400, ratio: 0.3409\n",
            "#185: episode_reward:-15.0776 acc: 15.4000, ratio: 0.3902\n",
            "#186: episode_reward:-15.2316 acc: 13.0800, ratio: 0.2895\n",
            "#187: episode_reward:-14.5538 acc: 18.5600, ratio: 0.4096\n",
            "#188: episode_reward:-11.1783 acc: 38.2200, ratio: 0.5119\n",
            "#189: episode_reward:-14.8771 acc: 16.3200, ratio: 0.3736\n",
            "#190: episode_reward:-15.0201 acc: 16.1000, ratio: 0.4228\n",
            "#191: episode_reward:-11.2210 acc: 37.9600, ratio: 0.5084\n",
            "#192: episode_reward:-15.7035 acc: 11.6200, ratio: 0.3697\n",
            "#193: episode_reward:-14.0989 acc: 21.3000, ratio: 0.4281\n",
            "#194: episode_reward:-14.0957 acc: 21.2600, ratio: 0.4225\n",
            "#195: episode_reward:-15.0472 acc: 15.4200, ratio: 0.3781\n",
            "#196: episode_reward:-15.4953 acc: 12.6200, ratio: 0.3570\n",
            "#197: episode_reward:-11.5447 acc: 35.6200, ratio: 0.4356\n",
            "#198: episode_reward:-11.7907 acc: 34.4000, ratio: 0.4540\n",
            "#199: episode_reward:-15.7254 acc: 11.5000, ratio: 0.3700\n",
            "#200: episode_reward:-13.8888 acc: 21.8200, ratio: 0.3686\n",
            "#201: episode_reward:-15.4267 acc: 13.1600, ratio: 0.3683\n",
            "#202: episode_reward:-14.6274 acc: 18.5600, ratio: 0.4483\n",
            "#203: episode_reward:-14.0599 acc: 21.7800, ratio: 0.4546\n",
            "#204: episode_reward:-14.9452 acc: 17.0200, ratio: 0.4711\n",
            "#205: episode_reward:-13.9136 acc: 21.6400, ratio: 0.3653\n",
            "#206: episode_reward:-13.8066 acc: 22.9600, ratio: 0.4309\n",
            "#207: episode_reward:-11.8855 acc: 34.0600, ratio: 0.4779\n",
            "#208: episode_reward:-14.2876 acc: 19.7800, ratio: 0.3857\n",
            "#209: episode_reward:-10.4215 acc: 42.2800, ratio: 0.4927\n",
            "#210: episode_reward:-12.0471 acc: 33.0000, ratio: 0.4573\n",
            "#211: episode_reward:-11.9439 acc: 33.0600, ratio: 0.3983\n",
            "#212: episode_reward:-11.5023 acc: 36.5400, ratio: 0.5284\n",
            "#213: episode_reward:-15.6443 acc: 12.5400, ratio: 0.4165\n",
            "#214: episode_reward:-14.5299 acc: 18.9400, ratio: 0.4324\n",
            "#215: episode_reward:-12.7687 acc: 28.8400, ratio: 0.4406\n",
            "#216: episode_reward:-12.7410 acc: 28.7800, ratio: 0.4175\n",
            "#217: episode_reward:-13.6403 acc: 23.3800, ratio: 0.3826\n",
            "#218: episode_reward:-10.3351 acc: 43.0000, ratio: 0.5318\n",
            "#219: episode_reward:-15.4914 acc: 13.2400, ratio: 0.4034\n",
            "#220: episode_reward:-14.8770 acc: 16.6000, ratio: 0.3965\n",
            "#221: episode_reward:-13.4626 acc: 24.6400, ratio: 0.4071\n",
            "#222: episode_reward:-10.7842 acc: 40.4200, ratio: 0.5154\n",
            "#223: episode_reward:-10.1999 acc: 43.4200, ratio: 0.4791\n",
            "#224: episode_reward:-10.8869 acc: 39.7000, ratio: 0.4923\n",
            "#225: episode_reward:-9.3111 acc: 48.6200, ratio: 0.5267\n",
            "#226: episode_reward:-14.7148 acc: 18.0200, ratio: 0.4431\n",
            "#227: episode_reward:-14.4436 acc: 19.1400, ratio: 0.4063\n",
            "#228: episode_reward:-10.3974 acc: 42.5800, ratio: 0.5192\n",
            "#229: episode_reward:-12.6637 acc: 29.9800, ratio: 0.5079\n",
            "#230: episode_reward:-9.9103 acc: 45.2400, ratio: 0.5141\n",
            "#231: episode_reward:-13.6045 acc: 23.8600, ratio: 0.4084\n",
            "\u001b[92m New best reward: -8.5171, acc: 53.1400, compress: 0.5557\u001b[00m\n",
            "\u001b[92m New best policy: [0.6005738236318233, 0.6157364077785774, 0.7354979156970279, 0.8, 0.7470219743317729, 0.8, 0.8, 0.6261976080032327, 0.8, 0.8, 0.24630102636912718]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [308, 158, 95, 52, 48, 103, 103, 161, 205, 410, 127]\u001b[00m\n",
            "#232: episode_reward:-8.5171 acc: 53.1400, ratio: 0.5557\n",
            "New best clamped policy: [0.6005738236318233, 0.6157364077785774, 0.7354979156970279, 0.9999668048485645, 0.7470219743317729, 0.8026299802556792, 0.9491042335123062, 0.6261976080032327, 0.8378716771873882, 0.8147007772937831, 0.24630102636912718]\n",
            "\u001b[92m New best reward: -8.4232, acc: 53.8400, compress: 0.5973\u001b[00m\n",
            "\u001b[92m New best policy: [0.7594077636609249, 0.7372015129708365, 0.8, 0.7746093863061262, 0.8, 0.6395516230682374, 0.8, 0.8, 0.751941723692299, 0.8, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [389, 189, 103, 50, 52, 82, 103, 205, 193, 410, 103]\u001b[00m\n",
            "#233: episode_reward:-8.4232 acc: 53.8400, ratio: 0.5973\n",
            "New best clamped policy: [0.7594077636609249, 0.7372015129708365, 0.825152459602856, 0.7746093863061262, 0.9463742640921281, 0.6395516230682374, 0.8077246868670985, 0.9993158717558621, 0.751941723692299, 0.9342478572553417, 0.10262890661559101]\n",
            "#234: episode_reward:-12.4388 acc: 30.7800, ratio: 0.4524\n",
            "#235: episode_reward:-15.5208 acc: 13.7200, ratio: 0.4610\n",
            "#236: episode_reward:-13.7352 acc: 23.7400, ratio: 0.4713\n",
            "#237: episode_reward:-13.4414 acc: 25.2800, ratio: 0.4611\n",
            "#238: episode_reward:-9.8680 acc: 45.4400, ratio: 0.5083\n",
            "#239: episode_reward:-12.8602 acc: 28.6800, ratio: 0.4812\n",
            "#240: episode_reward:-15.4979 acc: 13.2600, ratio: 0.4081\n",
            "#241: episode_reward:-11.2600 acc: 37.6800, ratio: 0.4990\n",
            "#242: episode_reward:-9.5878 acc: 47.1000, ratio: 0.5279\n",
            "#243: episode_reward:-14.4732 acc: 19.5400, ratio: 0.4607\n",
            "#244: episode_reward:-14.4686 acc: 19.5600, ratio: 0.4601\n",
            "#245: episode_reward:-12.2735 acc: 31.8800, ratio: 0.4744\n",
            "#246: episode_reward:-9.0025 acc: 50.3400, ratio: 0.5300\n",
            "#247: episode_reward:-10.1455 acc: 43.9200, ratio: 0.5106\n",
            "\u001b[92m New best reward: -7.8189, acc: 57.0600, compress: 0.5745\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.7906459941987806, 0.8, 0.723902934479246, 0.8, 0.6588102853012251, 0.8, 0.8, 0.2625822646117239, 0.2826350613543254]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 102, 52, 47, 103, 85, 205, 205, 135, 145]\u001b[00m\n",
            "#248: episode_reward:-7.8189 acc: 57.0600, ratio: 0.5745\n",
            "New best clamped policy: [0.8313566025335857, 0.8910738482377791, 0.7906459941987806, 0.9453014760108677, 0.723902934479246, 0.8423118298155471, 0.6588102853012251, 0.9789840979716403, 0.8498417055235281, 0.2625822646117239, 0.2826350613543254]\n",
            "#249: episode_reward:-10.6411 acc: 41.2400, ratio: 0.5201\n",
            "#250: episode_reward:-13.3044 acc: 26.1200, ratio: 0.4700\n",
            "#251: episode_reward:-12.4315 acc: 31.2000, ratio: 0.4995\n",
            "#252: episode_reward:-9.6146 acc: 46.8400, ratio: 0.5081\n",
            "#253: episode_reward:-8.2203 acc: 54.7800, ratio: 0.5572\n",
            "#254: episode_reward:-10.0695 acc: 44.3200, ratio: 0.5073\n",
            "#255: episode_reward:-13.4087 acc: 25.5800, ratio: 0.4744\n",
            "#256: episode_reward:-10.6587 acc: 41.1800, ratio: 0.5261\n",
            "#257: episode_reward:-12.3654 acc: 31.5400, ratio: 0.4961\n",
            "#258: episode_reward:-13.9794 acc: 22.1800, ratio: 0.4496\n",
            "#259: episode_reward:-13.8946 acc: 22.6800, ratio: 0.4525\n",
            "#260: episode_reward:-10.6264 acc: 41.3800, ratio: 0.5296\n",
            "#261: episode_reward:-8.6306 acc: 52.4600, ratio: 0.5440\n",
            "#262: episode_reward:-7.9697 acc: 56.2400, ratio: 0.5764\n",
            "#263: episode_reward:-11.4034 acc: 36.6400, ratio: 0.4652\n",
            "#264: episode_reward:-9.3260 acc: 48.6400, ratio: 0.5460\n",
            "#265: episode_reward:-9.0961 acc: 49.9800, ratio: 0.5608\n",
            "\u001b[92m New best reward: -7.1242, acc: 61.0600, compress: 0.6264\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.7920389678887997, 0.8, 0.8, 0.7256545051213122, 0.8, 0.7974224386136585, 0.7503166381524765, 0.24499424048776794]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 51, 52, 103, 93, 205, 205, 385, 126]\u001b[00m\n",
            "#266: episode_reward:-7.1242 acc: 61.0600, ratio: 0.6264\n",
            "New best clamped policy: [0.8694516954617205, 0.9008514357321333, 0.9904695628173014, 0.7920389678887997, 0.8958795497885296, 0.8041648581815898, 0.7256545051213122, 0.9555344527223791, 0.7974224386136585, 0.7503166381524765, 0.24499424048776794]\n",
            "#267: episode_reward:-7.8101 acc: 57.2200, ratio: 0.6024\n",
            "#268: episode_reward:-7.7180 acc: 57.7400, ratio: 0.6064\n",
            "#269: episode_reward:-10.8311 acc: 40.3000, ratio: 0.5376\n",
            "#270: episode_reward:-8.5539 acc: 53.0800, ratio: 0.5872\n",
            "\u001b[92m New best reward: -6.7560, acc: 63.0200, compress: 0.6103\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.799620700121868, 0.8, 0.8, 0.6768865440216667, 0.6983817122825094, 0.7375683581085333, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 174, 179, 378, 103]\u001b[00m\n",
            "#271: episode_reward:-6.7560 acc: 63.0200, ratio: 0.6103\n",
            "New best clamped policy: [0.938737140116659, 0.9411524126565329, 0.9878525770461619, 0.8562078597130348, 0.799620700121868, 0.9059569983123031, 0.8351654298542985, 0.6768865440216667, 0.6983817122825094, 0.7375683581085333, 0.12811516055284058]\n",
            "#272: episode_reward:-8.9459 acc: 50.9000, ratio: 0.5808\n",
            "#273: episode_reward:-6.8696 acc: 62.4400, ratio: 0.6229\n",
            "#274: episode_reward:-8.5928 acc: 52.8800, ratio: 0.5903\n",
            "#275: episode_reward:-7.0596 acc: 61.4200, ratio: 0.6284\n",
            "#276: episode_reward:-7.7432 acc: 57.5600, ratio: 0.5957\n",
            "#277: episode_reward:-7.6377 acc: 58.1800, ratio: 0.6066\n",
            "\u001b[92m New best reward: -6.3598, acc: 65.2200, compress: 0.6204\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.7114748812095332, 0.8, 0.8, 0.768755312913402, 0.8, 0.7933396975028365, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 46, 103, 103, 197, 205, 407, 103]\u001b[00m\n",
            "#278: episode_reward:-6.3598 acc: 65.2200, ratio: 0.6204\n",
            "New best clamped policy: [0.8807085230963683, 0.9458487569522815, 0.8767293531394825, 0.9430406876445542, 0.7114748812095332, 0.9455389694193833, 0.976842763834599, 0.768755312913402, 0.9781957223643517, 0.7933396975028365, 0.16407167290737487]\n",
            "#279: episode_reward:-7.0296 acc: 61.5600, ratio: 0.6213\n",
            "#280: episode_reward:-7.2947 acc: 60.1000, ratio: 0.6183\n",
            "#281: episode_reward:-8.0702 acc: 55.8200, ratio: 0.6086\n",
            "#282: episode_reward:-6.7977 acc: 62.9200, ratio: 0.6500\n",
            "#283: episode_reward:-9.2469 acc: 49.2200, ratio: 0.5750\n",
            "#284: episode_reward:-9.5463 acc: 47.5800, ratio: 0.5758\n",
            "#285: episode_reward:-6.4969 acc: 64.4800, ratio: 0.6234\n",
            "#286: episode_reward:-7.0045 acc: 61.7200, ratio: 0.6280\n",
            "#287: episode_reward:-7.0444 acc: 61.4600, ratio: 0.6157\n",
            "#288: episode_reward:-6.6584 acc: 63.5800, ratio: 0.6181\n",
            "#289: episode_reward:-6.4475 acc: 64.7800, ratio: 0.6332\n",
            "#290: episode_reward:-6.4760 acc: 64.6400, ratio: 0.6385\n",
            "#291: episode_reward:-6.5509 acc: 64.1200, ratio: 0.6033\n",
            "#292: episode_reward:-6.6670 acc: 63.5800, ratio: 0.6330\n",
            "\u001b[92m New best reward: -6.3538, acc: 65.3000, compress: 0.6360\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 205, 205, 410, 103]\u001b[00m\n",
            "#293: episode_reward:-6.3538 acc: 65.3000, ratio: 0.6360\n",
            "New best clamped policy: [0.9702728674442148, 0.9325206708821945, 0.9675035011565976, 0.8093058603933911, 0.9848302131160088, 0.8653301864647218, 0.9972632274850904, 0.9225637677833881, 0.9750986892332952, 0.886875233628971, 0.12188680319811804]\n",
            "#294: episode_reward:-7.2866 acc: 60.1400, ratio: 0.6171\n",
            "#295: episode_reward:-6.3966 acc: 65.0600, ratio: 0.6339\n",
            "#296: episode_reward:-7.2972 acc: 60.1000, ratio: 0.6222\n",
            "#297: episode_reward:-6.7913 acc: 62.9000, ratio: 0.6326\n",
            "#298: episode_reward:-6.3726 acc: 65.1400, ratio: 0.6171\n",
            "#299: episode_reward:-6.3538 acc: 65.3000, ratio: 0.6360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_amc_r0.5_rbound0.8_ep300_search-run4', 'resnet_cifar_amc_r0.5_rbound0.8_ep300_search.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3slZn3T5NDK",
        "outputId": "95f33f09-1c4d-482f-f53a-e11a1d6d640f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/amc3/logs/resnet_cifar_amc_r0.5_rbound0.8_ep300_search-run4' successfully zipped to 'resnet_cifar_amc_r0.5_rbound0.8_ep300_search.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search_no_sensitivity.py \\\n",
        "    --job=export \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/resnet_amc_r0.5_rbound0.8_ep300_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/resnet_amc_r0.5_rbound0.8_ep300_search/resnet_amc_r0.5_rbound0.8_ep300_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLi2ng7BWrXq",
        "outputId": "3f1ccd2c-0f68-417b-d2ad-530b01a24faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Original model channels: [512, 256, 128, 64, 64, 128, 128, 256, 256, 512, 512]\n",
            "=> Pruning with ratios: [0.9702728674442148, 0.9325206708821945, 0.9675035011565976, 0.8093058603933911, 0.9848302131160088, 0.8653301864647218, 0.9972632274850904, 0.9225637677833881, 0.9750986892332952, 0.886875233628971, 0.12188680319811804]\n",
            "=> Channels after pruning: [497, 239, 124, 52, 63, 111, 128, 236, 250, 454, 62]\n",
            "\u001b[92m New best reward: -1.9695, acc: 89.3800, compress: 0.8043\u001b[00m\n",
            "\u001b[92m New best policy: [0.9702728674442148, 0.9325206708821945, 0.9675035011565976, 0.8093058603933911, 0.9848302131160088, 0.8653301864647218, 0.9972632274850904, 0.9225637677833881, 0.9750986892332952, 0.886875233628971, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [497, 239, 124, 52, 63, 111, 127, 237, 250, 455, 103]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=/content/amc3/checkpoints/resnet_amc_r0.5_rbound0.8_ep300_search/resnet_amc_r0.5_rbound0.8_ep300_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-XinbzWgiS",
        "outputId": "2619754d-1799-4aa5-9f33-0367a3f9d425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from /content/amc3/checkpoints/resnet_amc_r0.5_rbound0.8_ep300_search/resnet_amc_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Model Parameter: 6.560 M, FLOPs: 112.829M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from /content/amc3/checkpoints/resnet_amc_r0.5_rbound0.8_ep300_search/resnet_amc_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training resnet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/resnet_cifar_finetune-run5\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 396ms | Tot: 23s169ms | Loss: 0.307 | Acc1: 89.420% | Acc5: 99.722% 352/352 \n",
            " [=======================================>]  Step: 152ms | Tot: 762ms | Loss: 0.294 | Acc1: 90.660% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.66\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 13ms | Tot: 23s196ms | Loss: 0.286 | Acc1: 90.104% | Acc5: 99.738% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 561ms | Loss: 0.303 | Acc1: 90.120% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 90.66\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 13ms | Tot: 23s609ms | Loss: 0.278 | Acc1: 90.411% | Acc5: 99.753% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 579ms | Loss: 0.305 | Acc1: 89.860% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 90.66\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 57ms | Tot: 23s421ms | Loss: 0.272 | Acc1: 90.607% | Acc5: 99.776% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 573ms | Loss: 0.290 | Acc1: 90.220% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 90.66\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 15ms | Tot: 22s949ms | Loss: 0.263 | Acc1: 90.887% | Acc5: 99.804% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 550ms | Loss: 0.284 | Acc1: 90.680% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 12ms | Tot: 23s514ms | Loss: 0.252 | Acc1: 91.253% | Acc5: 99.822% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 551ms | Loss: 0.285 | Acc1: 90.520% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 90.68\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 56ms | Tot: 22s984ms | Loss: 0.242 | Acc1: 91.578% | Acc5: 99.818% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 803ms | Loss: 0.278 | Acc1: 90.960% | Acc5: 99.600% 40/40 \n",
            "Current best acc: 90.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 12ms | Tot: 22s995ms | Loss: 0.230 | Acc1: 92.109% | Acc5: 99.820% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 568ms | Loss: 0.294 | Acc1: 90.440% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 90.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 12ms | Tot: 23s541ms | Loss: 0.227 | Acc1: 91.949% | Acc5: 99.851% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 620ms | Loss: 0.270 | Acc1: 91.300% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.3\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 56ms | Tot: 23s58ms | Loss: 0.215 | Acc1: 92.518% | Acc5: 99.827% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 568ms | Loss: 0.270 | Acc1: 91.220% | Acc5: 99.760% 40/40 \n",
            "Current best acc: 91.3\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 56ms | Tot: 22s874ms | Loss: 0.202 | Acc1: 92.911% | Acc5: 99.876% 352/352 \n",
            " [=======================================>]  Step: 5ms | Tot: 557ms | Loss: 0.265 | Acc1: 91.360% | Acc5: 99.760% 40/40 \n",
            "Current best acc: 91.36\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 59ms | Tot: 23s203ms | Loss: 0.193 | Acc1: 93.309% | Acc5: 99.887% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 569ms | Loss: 0.265 | Acc1: 91.700% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 91.7\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 58ms | Tot: 23s207ms | Loss: 0.187 | Acc1: 93.587% | Acc5: 99.891% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 559ms | Loss: 0.263 | Acc1: 91.760% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 91.76\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 57ms | Tot: 23s299ms | Loss: 0.178 | Acc1: 93.860% | Acc5: 99.947% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 563ms | Loss: 0.260 | Acc1: 91.620% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 91.76\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 13ms | Tot: 23s199ms | Loss: 0.175 | Acc1: 93.893% | Acc5: 99.916% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 603ms | Loss: 0.257 | Acc1: 91.860% | Acc5: 99.740% 40/40 \n",
            "Current best acc: 91.86\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 55ms | Tot: 22s808ms | Loss: 0.165 | Acc1: 94.173% | Acc5: 99.927% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 583ms | Loss: 0.255 | Acc1: 92.080% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 92.08\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 56ms | Tot: 23s556ms | Loss: 0.161 | Acc1: 94.373% | Acc5: 99.918% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 562ms | Loss: 0.250 | Acc1: 92.060% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.08\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 38ms | Tot: 23s197ms | Loss: 0.162 | Acc1: 94.324% | Acc5: 99.931% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 574ms | Loss: 0.252 | Acc1: 92.180% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.18\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 58ms | Tot: 23s143ms | Loss: 0.155 | Acc1: 94.680% | Acc5: 99.922% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 569ms | Loss: 0.249 | Acc1: 92.280% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.28\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 59ms | Tot: 24s122ms | Loss: 0.152 | Acc1: 94.787% | Acc5: 99.922% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 579ms | Loss: 0.251 | Acc1: 92.100% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.28\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run5/ckpt.pth.tar\n",
            "=> Model Parameter: 6.560 M, FLOPs: 112.829M, best top-1 acc: 92.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_finetune-run5', 'resnet_amc_r0.5_rbound0.8_ep300_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBuoTMHyZGS1",
        "outputId": "bd320ff2-3192-42c2-f58f-7f512dc1bec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/resnet_cifar_finetune-run5 to resnet_amc_r0.5_rbound0.8_ep300_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity"
      ],
      "metadata": {
        "id": "Ak4COu3iwbx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=200 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukFyM-wat4BK",
        "outputId": "f91c57dc-3c8a-4e7d-b23f-699263e18e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "Identified sensitive layers: ['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample.0', 'layer4.1.conv1', 'layer4.1.conv2']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "Sensitive layer indices: [0, 1, 2, 3, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "=> Saving logs to ./logs/resnet_cifar_sensitivity_r0.5_ep200_search-run5\n",
            "=> Output path: ./logs/resnet_cifar_sensitivity_r0.5_ep200_search-run5...\n",
            "** Actual replay buffer size: 1100\n",
            "\u001b[92m New best reward: -2.8170, acc: 84.8200, compress: 0.8141\u001b[00m\n",
            "\u001b[92m New best policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.9, 0.875450813354181]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 127, 58, 60, 127, 54, 255, 220, 461, 449]\u001b[00m\n",
            "#0: episode_reward:-2.8170 acc: 84.8200, ratio: 0.8141\n",
            "New best clamped policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.9, 0.875450813354181]\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-8.7861 acc: 51.8000, ratio: 0.5858\n",
            "#2: episode_reward:-6.6007 acc: 64.2200, ratio: 0.7296\n",
            "#3: episode_reward:-14.1594 acc: 22.0000, ratio: 0.5433\n",
            "#4: episode_reward:-11.2245 acc: 38.4600, ratio: 0.5923\n",
            "#5: episode_reward:-10.4470 acc: 42.6000, ratio: 0.5696\n",
            "#6: episode_reward:-7.6905 acc: 57.9400, ratio: 0.6197\n",
            "#7: episode_reward:-3.0773 acc: 83.3400, ratio: 0.7470\n",
            "#8: episode_reward:-8.9531 acc: 51.1800, ratio: 0.6543\n",
            "#9: episode_reward:-8.5959 acc: 52.9200, ratio: 0.6034\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#10: episode_reward:-11.8717 acc: 35.5200, ratio: 0.7035\n",
            "#11: episode_reward:-3.2984 acc: 82.1000, ratio: 0.7145\n",
            "#12: episode_reward:-9.6874 acc: 46.9600, ratio: 0.6072\n",
            "#13: episode_reward:-6.4811 acc: 64.8000, ratio: 0.7039\n",
            "#14: episode_reward:-11.9618 acc: 34.6600, ratio: 0.6337\n",
            "#15: episode_reward:-3.7704 acc: 79.5000, ratio: 0.6899\n",
            "#16: episode_reward:-11.0934 acc: 39.5200, ratio: 0.6565\n",
            "#17: episode_reward:-13.8336 acc: 23.4400, ratio: 0.4994\n",
            "#18: episode_reward:-7.9858 acc: 56.3400, ratio: 0.6236\n",
            "#19: episode_reward:-3.9972 acc: 78.2800, ratio: 0.6979\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#20: episode_reward:-10.1365 acc: 44.5200, ratio: 0.6111\n",
            "#21: episode_reward:-9.4101 acc: 48.4600, ratio: 0.6033\n",
            "#22: episode_reward:-14.6101 acc: 19.3800, ratio: 0.5268\n",
            "#23: episode_reward:-6.8991 acc: 62.6000, ratio: 0.7287\n",
            "#24: episode_reward:-3.5853 acc: 80.5200, ratio: 0.6988\n",
            "#25: episode_reward:-5.1588 acc: 71.9200, ratio: 0.6761\n",
            "#26: episode_reward:-4.6367 acc: 74.7800, ratio: 0.6851\n",
            "#27: episode_reward:-10.0580 acc: 45.1000, ratio: 0.6423\n",
            "#28: episode_reward:-10.3481 acc: 43.1800, ratio: 0.5763\n",
            "#29: episode_reward:-8.1978 acc: 55.4800, ratio: 0.7051\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 11, 14, 16, 17, 18, 19]\n",
            "#30: episode_reward:-8.4955 acc: 53.3200, ratio: 0.5691\n",
            "#31: episode_reward:-14.1139 acc: 22.1800, ratio: 0.5344\n",
            "#32: episode_reward:-12.5117 acc: 30.5600, ratio: 0.4746\n",
            "#33: episode_reward:-7.5008 acc: 59.1400, ratio: 0.6664\n",
            "#34: episode_reward:-9.4315 acc: 48.2000, ratio: 0.5737\n",
            "#35: episode_reward:-13.1004 acc: 27.6400, ratio: 0.5175\n",
            "#36: episode_reward:-10.5187 acc: 42.4600, ratio: 0.6172\n",
            "#37: episode_reward:-8.8884 acc: 51.0600, ratio: 0.5480\n",
            "#38: episode_reward:-10.2404 acc: 44.0000, ratio: 0.6208\n",
            "#39: episode_reward:-11.6631 acc: 35.9600, ratio: 0.5764\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#40: episode_reward:-6.3187 acc: 65.6200, ratio: 0.6809\n",
            "#41: episode_reward:-12.6228 acc: 30.4400, ratio: 0.5398\n",
            "#42: episode_reward:-6.3833 acc: 65.3800, ratio: 0.7226\n",
            "#43: episode_reward:-10.2291 acc: 43.8800, ratio: 0.5850\n",
            "#44: episode_reward:-10.7753 acc: 40.7600, ratio: 0.5633\n",
            "#45: episode_reward:-6.3383 acc: 65.5800, ratio: 0.7056\n",
            "#46: episode_reward:-9.8330 acc: 46.4400, ratio: 0.6674\n",
            "#47: episode_reward:-4.4875 acc: 75.7200, ratio: 0.7551\n",
            "#48: episode_reward:-9.3538 acc: 48.6000, ratio: 0.5683\n",
            "#49: episode_reward:-9.8932 acc: 46.1000, ratio: 0.6647\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "#50: episode_reward:-11.5409 acc: 36.9800, ratio: 0.6376\n",
            "#51: episode_reward:-9.7996 acc: 46.5800, ratio: 0.6578\n",
            "#52: episode_reward:-6.2182 acc: 66.0200, ratio: 0.6291\n",
            "#53: episode_reward:-11.0856 acc: 38.8600, ratio: 0.5317\n",
            "#54: episode_reward:-13.7319 acc: 24.9000, ratio: 0.6198\n",
            "#55: episode_reward:-8.5812 acc: 53.1800, ratio: 0.6472\n",
            "#56: episode_reward:-11.5346 acc: 37.1200, ratio: 0.6575\n",
            "#57: episode_reward:-3.7985 acc: 79.3800, ratio: 0.7106\n",
            "#58: episode_reward:-4.4706 acc: 75.7600, ratio: 0.7259\n",
            "#59: episode_reward:-8.5855 acc: 53.2600, ratio: 0.6740\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 15, 16, 17, 18, 19]\n",
            "#60: episode_reward:-4.7235 acc: 74.3400, ratio: 0.7010\n",
            "#61: episode_reward:-4.9780 acc: 72.7800, ratio: 0.6219\n",
            "#62: episode_reward:-5.4048 acc: 70.6600, ratio: 0.7103\n",
            "#63: episode_reward:-11.9141 acc: 34.7400, ratio: 0.6024\n",
            "#64: episode_reward:-11.0413 acc: 39.4000, ratio: 0.5809\n",
            "#65: episode_reward:-4.5387 acc: 75.4000, ratio: 0.7312\n",
            "#66: episode_reward:-8.0839 acc: 55.7600, ratio: 0.6124\n",
            "#67: episode_reward:-11.2543 acc: 37.8600, ratio: 0.5210\n",
            "#68: episode_reward:-12.9915 acc: 28.1200, ratio: 0.5019\n",
            "#69: episode_reward:-11.3622 acc: 37.2800, ratio: 0.5234\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#70: episode_reward:-5.1722 acc: 71.7200, ratio: 0.6226\n",
            "#71: episode_reward:-3.9914 acc: 78.2800, ratio: 0.6793\n",
            "#72: episode_reward:-6.6891 acc: 63.7600, ratio: 0.7368\n",
            "#73: episode_reward:-5.7338 acc: 68.8400, ratio: 0.6963\n",
            "#74: episode_reward:-13.4548 acc: 26.0800, ratio: 0.5704\n",
            "#75: episode_reward:-8.2252 acc: 54.8800, ratio: 0.5865\n",
            "#76: episode_reward:-12.1764 acc: 33.1000, ratio: 0.5699\n",
            "#77: episode_reward:-7.3433 acc: 59.9400, ratio: 0.6489\n",
            "#78: episode_reward:-8.3998 acc: 53.9800, ratio: 0.6001\n",
            "#79: episode_reward:-8.4481 acc: 53.6400, ratio: 0.5825\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 4, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#80: episode_reward:-10.1446 acc: 44.5800, ratio: 0.6324\n",
            "#81: episode_reward:-14.1305 acc: 22.2400, ratio: 0.5536\n",
            "#82: episode_reward:-14.5768 acc: 19.8200, ratio: 0.5581\n",
            "#83: episode_reward:-4.2472 acc: 76.9200, ratio: 0.6970\n",
            "#84: episode_reward:-13.7765 acc: 23.8000, ratio: 0.5047\n",
            "#85: episode_reward:-8.3258 acc: 54.1000, ratio: 0.5357\n",
            "#86: episode_reward:-11.1557 acc: 38.7400, ratio: 0.5754\n",
            "#87: episode_reward:-8.7289 acc: 52.1200, ratio: 0.5872\n",
            "#88: episode_reward:-9.3121 acc: 48.7400, ratio: 0.5506\n",
            "#89: episode_reward:-10.6875 acc: 41.5600, ratio: 0.6218\n",
            "[Train] Sensitive layer indices: [0, 2, 3, 4, 9, 11, 14, 15, 16, 17, 18, 19]\n",
            "#90: episode_reward:-13.5481 acc: 25.0000, ratio: 0.4970\n",
            "#91: episode_reward:-4.9043 acc: 73.3600, ratio: 0.7022\n",
            "#92: episode_reward:-7.5519 acc: 58.8000, ratio: 0.6484\n",
            "#93: episode_reward:-13.4474 acc: 25.7600, ratio: 0.5221\n",
            "#94: episode_reward:-5.2646 acc: 71.4800, ratio: 0.7380\n",
            "#95: episode_reward:-13.2855 acc: 26.7800, ratio: 0.5387\n",
            "#96: episode_reward:-7.8561 acc: 57.1000, ratio: 0.6372\n",
            "#97: episode_reward:-5.4926 acc: 70.2200, ratio: 0.7266\n",
            "#98: episode_reward:-13.8809 acc: 23.4000, ratio: 0.5263\n",
            "#99: episode_reward:-12.5746 acc: 30.7600, ratio: 0.5476\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#100: episode_reward:-6.7466 acc: 63.3000, ratio: 0.6838\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-5.3779 acc: 70.7200, ratio: 0.6730\n",
            "#102: episode_reward:-5.1837 acc: 71.7600, ratio: 0.6654\n",
            "#103: episode_reward:-5.4900 acc: 69.9800, ratio: 0.6216\n",
            "#104: episode_reward:-10.8152 acc: 40.7800, ratio: 0.6062\n",
            "#105: episode_reward:-6.0639 acc: 67.0600, ratio: 0.7017\n",
            "#106: episode_reward:-2.8988 acc: 84.2600, ratio: 0.7072\n",
            "#107: episode_reward:-3.8998 acc: 78.8200, ratio: 0.7044\n",
            "#108: episode_reward:-5.1793 acc: 71.9600, ratio: 0.7467\n",
            "#109: episode_reward:-3.4080 acc: 81.4800, ratio: 0.6966\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#110: episode_reward:-2.8743 acc: 84.4800, ratio: 0.7841\n",
            "#111: episode_reward:-3.7474 acc: 79.7200, ratio: 0.7521\n",
            "#112: episode_reward:-3.5787 acc: 80.5800, ratio: 0.7151\n",
            "#113: episode_reward:-2.9888 acc: 83.8000, ratio: 0.7304\n",
            "#114: episode_reward:-3.5028 acc: 81.1200, ratio: 0.8105\n",
            "\u001b[92m New best reward: -2.6814, acc: 85.5600, compress: 0.8235\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9806318662724697, 0.6175000456709901, 0.9278684628618586, 0.8424712911451914, 0.968666751187559, 0.9200021645173145]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 58, 58, 126, 80, 238, 216, 496, 472]\u001b[00m\n",
            "#115: episode_reward:-2.6814 acc: 85.5600, ratio: 0.8235\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9806318662724697, 0.6175000456709901, 0.9278684628618586, 0.8424712911451914, 0.968666751187559, 0.9200021645173145]\n",
            "#116: episode_reward:-3.4726 acc: 81.2600, ratio: 0.7923\n",
            "#117: episode_reward:-2.7229 acc: 85.3600, ratio: 0.8484\n",
            "#118: episode_reward:-2.7885 acc: 84.9400, ratio: 0.7812\n",
            "\u001b[92m New best reward: -2.3587, acc: 87.3000, compress: 0.8263\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9364170076048687, 0.823175182057604, 0.9236505595927872, 0.9555705386589458, 0.7533020360164776, 0.826315783738496]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 58, 58, 120, 106, 237, 245, 386, 424]\u001b[00m\n",
            "#119: episode_reward:-2.3587 acc: 87.3000, ratio: 0.8263\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9364170076048687, 0.823175182057604, 0.9236505595927872, 0.9555705386589458, 0.7533020360164776, 0.826315783738496]\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#120: episode_reward:-2.6656 acc: 85.6600, ratio: 0.8398\n",
            "#121: episode_reward:-2.4245 acc: 86.9200, ratio: 0.7968\n",
            "#122: episode_reward:-2.4351 acc: 86.9200, ratio: 0.8641\n",
            "\u001b[92m New best reward: -2.1267, acc: 88.6000, compress: 0.8980\u001b[00m\n",
            "\u001b[92m New best policy: [0.9710624933281647, 0.9, 0.9843139963856578, 0.9808579069671254, 0.9552185537882764, 0.8046199968872025, 0.9016862444845511, 0.9541810448488254, 0.8958663262054471, 0.8975448766586154, 0.9628540907679343]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [498, 231, 126, 63, 62, 103, 116, 245, 230, 460, 493]\u001b[00m\n",
            "#123: episode_reward:-2.1267 acc: 88.6000, ratio: 0.8980\n",
            "New best clamped policy: [0.9710624933281647, 0.9, 0.9843139963856578, 0.9808579069671254, 0.9552185537882764, 0.8046199968872025, 0.9016862444845511, 0.9541810448488254, 0.8958663262054471, 0.8975448766586154, 0.9628540907679343]\n",
            "\u001b[92m New best reward: -1.9772, acc: 89.3800, compress: 0.8646\u001b[00m\n",
            "\u001b[92m New best policy: [0.9791972017094227, 0.9, 0.9870143001913357, 0.9197856182759077, 0.9, 0.8814213094619096, 0.7721309001169223, 0.924605912346076, 0.9645147914594387, 0.8229255889757633, 0.9012784621156856]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [502, 231, 127, 59, 58, 113, 99, 237, 247, 422, 462]\u001b[00m\n",
            "#124: episode_reward:-1.9772 acc: 89.3800, ratio: 0.8646\n",
            "New best clamped policy: [0.9791972017094227, 0.9, 0.9870143001913357, 0.9197856182759077, 0.9, 0.8814213094619096, 0.7721309001169223, 0.924605912346076, 0.9645147914594387, 0.8229255889757633, 0.9012784621156856]\n",
            "\u001b[92m New best reward: -1.9718, acc: 89.4000, compress: 0.8514\u001b[00m\n",
            "\u001b[92m New best policy: [0.934361474562084, 0.9, 0.9787854694996563, 0.9558534875530689, 0.9, 0.960649108398311, 0.8897750465581779, 0.8124797608881845, 0.8258614940244426, 0.8554560697760538, 0.8307961353360023]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [479, 231, 126, 62, 58, 123, 114, 208, 212, 438, 426]\u001b[00m\n",
            "#125: episode_reward:-1.9718 acc: 89.4000, ratio: 0.8514\n",
            "New best clamped policy: [0.934361474562084, 0.9, 0.9787854694996563, 0.9558534875530689, 0.9, 0.960649108398311, 0.8897750465581779, 0.8124797608881845, 0.8258614940244426, 0.8554560697760538, 0.8307961353360023]\n",
            "#126: episode_reward:-3.4565 acc: 81.4000, ratio: 0.8354\n",
            "#127: episode_reward:-2.1814 acc: 88.2800, ratio: 0.8606\n",
            "#128: episode_reward:-2.1935 acc: 88.2200, ratio: 0.8673\n",
            "#129: episode_reward:-2.1422 acc: 88.5000, ratio: 0.8736\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 18, 19]\n",
            "#130: episode_reward:-2.6604 acc: 85.7200, ratio: 0.8758\n",
            "#131: episode_reward:-2.1114 acc: 88.6600, ratio: 0.8659\n",
            "#132: episode_reward:-2.1507 acc: 88.4400, ratio: 0.8532\n",
            "\u001b[92m New best reward: -1.8625, acc: 90.0400, compress: 0.9386\u001b[00m\n",
            "\u001b[92m New best policy: [0.9463820176306049, 0.9507010161996982, 0.9586621834684259, 0.9597365553727205, 0.989000201384728, 0.986278185245137, 0.9535419826689586, 0.926524847641915, 0.9794599441839856, 0.9686359364399133, 0.9555970787837557]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [485, 244, 123, 62, 63, 127, 123, 238, 251, 496, 490]\u001b[00m\n",
            "#133: episode_reward:-1.8625 acc: 90.0400, ratio: 0.9386\n",
            "New best clamped policy: [0.9463820176306049, 0.9507010161996982, 0.9586621834684259, 0.9597365553727205, 0.989000201384728, 0.986278185245137, 0.9535419826689586, 0.926524847641915, 0.9794599441839856, 0.9686359364399133, 0.9555970787837557]\n",
            "#134: episode_reward:-1.9486 acc: 89.5600, ratio: 0.9063\n",
            "#135: episode_reward:-2.0810 acc: 88.8400, ratio: 0.8906\n",
            "#136: episode_reward:-2.3232 acc: 87.5400, ratio: 0.8888\n",
            "#137: episode_reward:-2.0497 acc: 89.0200, ratio: 0.9086\n",
            "\u001b[92m New best reward: -1.7176, acc: 90.8200, compress: 0.9488\u001b[00m\n",
            "\u001b[92m New best policy: [0.978218066262704, 0.9832165860568282, 0.9979687520837507, 0.9745721709208238, 0.9907302147791568, 0.9940641415354661, 0.9412497650695164, 0.848278610414639, 0.9590318843058928, 0.9518138338345965, 0.964952347477318]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [501, 252, 127, 63, 63, 127, 121, 218, 246, 488, 495]\u001b[00m\n",
            "#138: episode_reward:-1.7176 acc: 90.8200, ratio: 0.9488\n",
            "New best clamped policy: [0.978218066262704, 0.9832165860568282, 0.9979687520837507, 0.9745721709208238, 0.9907302147791568, 0.9940641415354661, 0.9412497650695164, 0.848278610414639, 0.9590318843058928, 0.9518138338345965, 0.964952347477318]\n",
            "#139: episode_reward:-1.7560 acc: 90.6000, ratio: 0.9208\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#140: episode_reward:-2.1415 acc: 88.5400, ratio: 0.9260\n",
            "#141: episode_reward:-1.7915 acc: 90.4200, ratio: 0.9389\n",
            "#142: episode_reward:-2.0264 acc: 89.1600, ratio: 0.9327\n",
            "#143: episode_reward:-1.9588 acc: 89.5200, ratio: 0.9300\n",
            "#144: episode_reward:-1.8880 acc: 89.9000, ratio: 0.9320\n",
            "#145: episode_reward:-2.1162 acc: 88.6800, ratio: 0.9333\n",
            "#146: episode_reward:-1.9863 acc: 89.3800, ratio: 0.9423\n",
            "#147: episode_reward:-1.9738 acc: 89.4400, ratio: 0.9308\n",
            "#148: episode_reward:-1.8133 acc: 90.3200, ratio: 0.9699\n",
            "#149: episode_reward:-1.7338 acc: 90.7400, ratio: 0.9613\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 19]\n",
            "#150: episode_reward:-1.9024 acc: 89.8400, ratio: 0.9615\n",
            "#151: episode_reward:-1.7592 acc: 90.6000, ratio: 0.9526\n",
            "#152: episode_reward:-1.7533 acc: 90.6400, ratio: 0.9691\n",
            "#153: episode_reward:-1.8036 acc: 90.3600, ratio: 0.9473\n",
            "#154: episode_reward:-1.7526 acc: 90.6400, ratio: 0.9615\n",
            "#155: episode_reward:-1.7681 acc: 90.5600, ratio: 0.9668\n",
            "#156: episode_reward:-1.7203 acc: 90.8200, ratio: 0.9767\n",
            "#157: episode_reward:-1.7645 acc: 90.5800, ratio: 0.9686\n",
            "\u001b[92m New best reward: -1.7122, acc: 90.8600, compress: 0.9702\u001b[00m\n",
            "\u001b[92m New best policy: [0.9424887235295438, 0.9933697108861473, 0.978067088418749, 0.9715022030480029, 0.9752399418095467, 0.9789878530506994, 0.9924742928177066, 0.9693434713869248, 0.9820180784017026, 0.9863074867606458, 0.9941729801345179]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [483, 255, 126, 63, 63, 126, 127, 249, 252, 505, 510]\u001b[00m\n",
            "#158: episode_reward:-1.7122 acc: 90.8600, ratio: 0.9702\n",
            "New best clamped policy: [0.9424887235295438, 0.9933697108861473, 0.978067088418749, 0.9715022030480029, 0.9752399418095467, 0.9789878530506994, 0.9924742928177066, 0.9693434713869248, 0.9820180784017026, 0.9863074867606458, 0.9941729801345179]\n",
            "#159: episode_reward:-1.7607 acc: 90.6000, ratio: 0.9684\n",
            "\u001b[92m New best reward: -1.6830, acc: 91.0200, compress: 0.9782\u001b[00m\n",
            "\u001b[92m New best policy: [0.9966449703516987, 0.9828994114134117, 0.9866727374308427, 0.988747574663856, 0.969610025822753, 0.9986133668191305, 0.9901771737407349, 0.9546851947847407, 0.9937221313559678, 0.9757519159353164, 0.9788620915170669]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 252, 127, 63, 63, 127, 127, 245, 255, 500, 502]\u001b[00m\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 19]\n",
            "#160: episode_reward:-1.6830 acc: 91.0200, ratio: 0.9782\n",
            "New best clamped policy: [0.9966449703516987, 0.9828994114134117, 0.9866727374308427, 0.988747574663856, 0.969610025822753, 0.9986133668191305, 0.9901771737407349, 0.9546851947847407, 0.9937221313559678, 0.9757519159353164, 0.9788620915170669]\n",
            "#161: episode_reward:-1.7867 acc: 90.4600, ratio: 0.9659\n",
            "#162: episode_reward:-1.6976 acc: 90.9400, ratio: 0.9741\n",
            "#163: episode_reward:-1.7508 acc: 90.6600, ratio: 0.9822\n",
            "#164: episode_reward:-1.7381 acc: 90.7200, ratio: 0.9674\n",
            "#165: episode_reward:-1.7466 acc: 90.6800, ratio: 0.9770\n",
            "#166: episode_reward:-1.7468 acc: 90.6800, ratio: 0.9790\n",
            "#167: episode_reward:-1.6984 acc: 90.9400, ratio: 0.9831\n",
            "#168: episode_reward:-1.6985 acc: 90.9400, ratio: 0.9841\n",
            "#169: episode_reward:-1.7171 acc: 90.8400, ratio: 0.9830\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 19]\n",
            "#170: episode_reward:-1.7241 acc: 90.8000, ratio: 0.9770\n",
            "#171: episode_reward:-1.7425 acc: 90.7000, ratio: 0.9735\n",
            "#172: episode_reward:-1.6907 acc: 90.9800, ratio: 0.9813\n",
            "#173: episode_reward:-1.7323 acc: 90.7600, ratio: 0.9852\n",
            "#174: episode_reward:-1.7396 acc: 90.7200, ratio: 0.9831\n",
            "#175: episode_reward:-1.6875 acc: 91.0000, ratio: 0.9866\n",
            "#176: episode_reward:-1.7245 acc: 90.8000, ratio: 0.9819\n",
            "#177: episode_reward:-1.7137 acc: 90.8600, ratio: 0.9860\n",
            "#178: episode_reward:-1.6988 acc: 90.9400, ratio: 0.9878\n",
            "#179: episode_reward:-1.7061 acc: 90.9000, ratio: 0.9857\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 19]\n",
            "#180: episode_reward:-1.7027 acc: 90.9200, ratio: 0.9887\n",
            "#181: episode_reward:-1.7097 acc: 90.8800, ratio: 0.9840\n",
            "#182: episode_reward:-1.7100 acc: 90.8800, ratio: 0.9874\n",
            "#183: episode_reward:-1.6950 acc: 90.9600, ratio: 0.9873\n",
            "#184: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9890\n",
            "#185: episode_reward:-1.7026 acc: 90.9200, ratio: 0.9876\n",
            "#186: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9885\n",
            "#187: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9888\n",
            "#188: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9884\n",
            "#189: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9886\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 19]\n",
            "#190: episode_reward:-1.6989 acc: 90.9400, ratio: 0.9880\n",
            "#191: episode_reward:-1.6875 acc: 91.0000, ratio: 0.9873\n",
            "#192: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9892\n",
            "#193: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9888\n",
            "#194: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9890\n",
            "#195: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9894\n",
            "#196: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9894\n",
            "#197: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9894\n",
            "#198: episode_reward:-1.7102 acc: 90.8800, ratio: 0.9894\n",
            "#199: episode_reward:-1.7139 acc: 90.8600, ratio: 0.9886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('./logs/resnet_cifar_sensitivity_r0.5_ep200_search-run5', 'resnet_cifar_sensitivity_r0.5_ep200_search.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU-Pafc-6k4K",
        "outputId": "7c1928fa-59cf-4d7b-a557-5a45524179e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The zip file 'resnet_cifar_sensitivity_r0.5_ep200_search.zip' already exists. Please choose a different name or delete the existing file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/resnet_cifar_sensitivity_r0.5_ep200_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/resnet_cifar_sensitivity_r0.5_ep200_search/resnet_cifar_sensitivity_r0.5_ep200_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih_Y_nblZYXR",
        "outputId": "61b8243b-b77e-4e1c-8a65-113c234c1e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Identified sensitive layers: ['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample.0', 'layer4.1.conv1', 'layer4.1.conv2']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "Sensitive layer indices: [0, 1, 2, 3, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "=> Original model channels: [512, 256, 128, 64, 64, 128, 128, 256, 256, 512, 512]\n",
            "=> Pruning with ratios: [0.9966449703516987, 0.9828994114134117, 0.9866727374308427, 0.988747574663856, 0.969610025822753, 0.9986133668191305, 0.9901771737407349, 0.9546851947847407, 0.9937221313559678, 0.9757519159353164, 0.9788620915170669]\n",
            "=> Channels after pruning: [510, 252, 126, 63, 62, 128, 127, 244, 254, 500, 501]\n",
            "\u001b[92m New best reward: -1.6830, acc: 91.0200, compress: 0.9782\u001b[00m\n",
            "\u001b[92m New best policy: [0.9966449703516987, 0.9828994114134117, 0.9866727374308427, 0.988747574663856, 0.969610025822753, 0.9986133668191305, 0.9901771737407349, 0.9546851947847407, 0.9937221313559678, 0.9757519159353164, 0.9788620915170669]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [511, 252, 127, 63, 63, 127, 127, 245, 255, 500, 502]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/resnet_cifar_sensitivity_r0.5_ep200_search/resnet_cifar_sensitivity_r0.5_ep200_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcgBG3GKZR8Z",
        "outputId": "cbe0897c-812c-4fb0-80be-0613dadd09dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_cifar_sensitivity_r0.5_ep200_search/resnet_cifar_sensitivity_r0.5_ep200_search.pt...\n",
            "=> Model Parameter: 10.882 M, FLOPs: 137.304M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_cifar_sensitivity_r0.5_ep200_search/resnet_cifar_sensitivity_r0.5_ep200_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training resnet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/resnet_cifar_finetune-run7\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 388ms | Tot: 23s636ms | Loss: 0.286 | Acc1: 90.189% | Acc5: 99.762% 352/352 \n",
            " [=======================================>]  Step: 135ms | Tot: 688ms | Loss: 0.289 | Acc1: 89.980% | Acc5: 99.760% 40/40 \n",
            "Current best acc: 89.98\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 14ms | Tot: 23s432ms | Loss: 0.275 | Acc1: 90.522% | Acc5: 99.764% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 551ms | Loss: 0.288 | Acc1: 90.800% | Acc5: 99.580% 40/40 \n",
            "Current best acc: 90.8\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 14ms | Tot: 23s243ms | Loss: 0.270 | Acc1: 90.736% | Acc5: 99.760% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 628ms | Loss: 0.299 | Acc1: 90.220% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.8\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 56ms | Tot: 23s604ms | Loss: 0.260 | Acc1: 91.084% | Acc5: 99.776% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 664ms | Loss: 0.303 | Acc1: 90.240% | Acc5: 99.600% 40/40 \n",
            "Current best acc: 90.8\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 57ms | Tot: 23s229ms | Loss: 0.244 | Acc1: 91.656% | Acc5: 99.813% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 565ms | Loss: 0.291 | Acc1: 90.420% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 90.8\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 57ms | Tot: 23s745ms | Loss: 0.246 | Acc1: 91.542% | Acc5: 99.827% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 569ms | Loss: 0.281 | Acc1: 90.960% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 90.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 54ms | Tot: 23s692ms | Loss: 0.233 | Acc1: 91.771% | Acc5: 99.847% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 627ms | Loss: 0.281 | Acc1: 90.600% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 14ms | Tot: 23s111ms | Loss: 0.225 | Acc1: 92.158% | Acc5: 99.871% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 565ms | Loss: 0.293 | Acc1: 90.760% | Acc5: 99.600% 40/40 \n",
            "Current best acc: 90.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 13ms | Tot: 23s346ms | Loss: 0.216 | Acc1: 92.567% | Acc5: 99.849% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 585ms | Loss: 0.264 | Acc1: 91.560% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.56\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 24ms | Tot: 23s34ms | Loss: 0.204 | Acc1: 92.942% | Acc5: 99.891% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 596ms | Loss: 0.267 | Acc1: 91.600% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 91.6\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 13ms | Tot: 23s192ms | Loss: 0.195 | Acc1: 93.191% | Acc5: 99.889% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 565ms | Loss: 0.260 | Acc1: 91.640% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 91.64\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 14ms | Tot: 23s438ms | Loss: 0.185 | Acc1: 93.589% | Acc5: 99.902% 352/352 \n",
            " [=======================================>]  Step: 5ms | Tot: 596ms | Loss: 0.262 | Acc1: 91.560% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 91.64\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 13ms | Tot: 23s690ms | Loss: 0.184 | Acc1: 93.682% | Acc5: 99.891% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 556ms | Loss: 0.254 | Acc1: 92.020% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.02\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 14ms | Tot: 23s92ms | Loss: 0.171 | Acc1: 93.949% | Acc5: 99.927% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 568ms | Loss: 0.255 | Acc1: 91.800% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.02\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 57ms | Tot: 23s666ms | Loss: 0.167 | Acc1: 94.133% | Acc5: 99.924% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 576ms | Loss: 0.253 | Acc1: 91.880% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.02\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 14ms | Tot: 23s218ms | Loss: 0.160 | Acc1: 94.464% | Acc5: 99.931% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 560ms | Loss: 0.248 | Acc1: 92.380% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.38\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 56ms | Tot: 23s637ms | Loss: 0.155 | Acc1: 94.744% | Acc5: 99.940% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 572ms | Loss: 0.246 | Acc1: 92.160% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.38\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 55ms | Tot: 23s183ms | Loss: 0.152 | Acc1: 94.756% | Acc5: 99.918% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 555ms | Loss: 0.245 | Acc1: 92.160% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 92.38\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 14ms | Tot: 23s626ms | Loss: 0.148 | Acc1: 94.907% | Acc5: 99.938% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 571ms | Loss: 0.247 | Acc1: 92.260% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 92.38\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 14ms | Tot: 23s273ms | Loss: 0.151 | Acc1: 94.851% | Acc5: 99.907% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 560ms | Loss: 0.246 | Acc1: 92.260% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.38\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run7/ckpt.pth.tar\n",
            "=> Model Parameter: 10.882 M, FLOPs: 137.304M, best top-1 acc: 92.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_finetune-run7', 'resnet_cifar_sensitivity_r0.5_ep200_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCypEUJRZmsu",
        "outputId": "8a292438-0631-4256-c76b-7692b54697b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/resnet_cifar_finetune-run7 to resnet_cifar_sensitivity_r0.5_ep200_ft.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity, rbound=0.8"
      ],
      "metadata": {
        "id": "-UXeKn8IxX4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.5 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --rbound=0.8 \\\n",
        "    --data_bsize 128 \\\n",
        "    --n_worker 2 \\\n",
        "    --train_episode=300 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --init_delta=1.0 \\\n",
        "    --delta_decay=0.99 \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --seed=123456 \\\n",
        "    --split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHW4Jw4lxXMe",
        "outputId": "960240a0-b69d-420e-fbbd-ab5fde3ec1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "Identified sensitive layers: ['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer2.1.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample.0', 'layer4.1.conv1', 'layer4.1.conv2']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "=> Saving logs to ./logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run6\n",
            "=> Output path: ./logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run6...\n",
            "** Actual replay buffer size: 1100\n",
            "\u001b[92m New best reward: -7.9146, acc: 56.8600, compress: 0.6590\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.41936359483482594, 0.8, 0.8, 0.8, 0.8]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 54, 205, 205, 410, 410]\u001b[00m\n",
            "#0: episode_reward:-7.9146 acc: 56.8600, ratio: 0.6590\n",
            "New best clamped policy: [0.9000162887906149, 0.9, 1.0, 0.9, 0.9246297821241971, 1.0, 0.41936359483482594, 1.0, 0.8583141046753631, 0.9, 0.875450813354181]\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#1: episode_reward:-11.9200 acc: 34.1600, ratio: 0.5175\n",
            "#2: episode_reward:-8.9447 acc: 51.0800, ratio: 0.6195\n",
            "#3: episode_reward:-14.6696 acc: 18.6200, ratio: 0.4785\n",
            "#4: episode_reward:-11.9719 acc: 33.7600, ratio: 0.5017\n",
            "#5: episode_reward:-12.5098 acc: 30.6800, ratio: 0.4883\n",
            "#6: episode_reward:-11.9544 acc: 34.0400, ratio: 0.5276\n",
            "\u001b[92m New best reward: -7.4371, acc: 59.4000, compress: 0.6407\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.6943455912929397, 0.7540988546444627, 0.7595717962030262, 0.8, 0.4255292656719772]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 89, 194, 195, 410, 218]\u001b[00m\n",
            "#7: episode_reward:-7.4371 acc: 59.4000, ratio: 0.6407\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 1.0, 0.6943455912929397, 0.7540988546444627, 0.7595717962030262, 0.9643532024222072, 0.4255292656719772]\n",
            "#8: episode_reward:-12.5104 acc: 31.2200, ratio: 0.5632\n",
            "#9: episode_reward:-10.7463 acc: 40.6000, ratio: 0.5108\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "#10: episode_reward:-12.5576 acc: 31.1000, ratio: 0.5843\n",
            "\u001b[92m New best reward: -6.9601, acc: 61.9400, compress: 0.6213\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.4544205742090452, 0.6998637143840201, 0.8, 0.41885229975574967]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 117, 180, 410, 215]\u001b[00m\n",
            "#11: episode_reward:-6.9601 acc: 61.9400, ratio: 0.6213\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9144023415060275, 0.8200297840474129, 0.4544205742090452, 0.6998637143840201, 0.9, 0.41885229975574967]\n",
            "#12: episode_reward:-11.2935 acc: 37.6600, ratio: 0.5235\n",
            "#13: episode_reward:-9.7373 acc: 46.6200, ratio: 0.5935\n",
            "#14: episode_reward:-12.1414 acc: 33.2200, ratio: 0.5588\n",
            "#15: episode_reward:-8.0617 acc: 55.8600, ratio: 0.6070\n",
            "#16: episode_reward:-12.0689 acc: 33.7400, ratio: 0.5777\n",
            "#17: episode_reward:-15.0989 acc: 15.8200, ratio: 0.4375\n",
            "#18: episode_reward:-10.4661 acc: 42.2400, ratio: 0.5256\n",
            "#19: episode_reward:-7.5030 acc: 58.9000, ratio: 0.6018\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 11, 14, 15, 16, 17, 18, 19]\n",
            "#20: episode_reward:-12.1781 acc: 32.7800, ratio: 0.5239\n",
            "#21: episode_reward:-13.3634 acc: 26.2400, ratio: 0.5243\n",
            "#22: episode_reward:-15.2323 acc: 15.3400, ratio: 0.4626\n",
            "#23: episode_reward:-11.0094 acc: 39.8400, ratio: 0.6294\n",
            "#24: episode_reward:-7.5061 acc: 58.8600, ratio: 0.5957\n",
            "#25: episode_reward:-9.0478 acc: 50.4000, ratio: 0.5935\n",
            "#26: episode_reward:-8.0832 acc: 55.7000, ratio: 0.5965\n",
            "#27: episode_reward:-11.1751 acc: 38.5400, ratio: 0.5596\n",
            "#28: episode_reward:-13.6438 acc: 24.5600, ratio: 0.5079\n",
            "#29: episode_reward:-12.1475 acc: 33.4600, ratio: 0.6022\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 15, 16, 17, 18, 19]\n",
            "#30: episode_reward:-10.3607 acc: 42.6600, ratio: 0.4994\n",
            "#31: episode_reward:-15.6097 acc: 13.3200, ratio: 0.4701\n",
            "#32: episode_reward:-13.7956 acc: 22.9800, ratio: 0.4268\n",
            "#33: episode_reward:-11.6907 acc: 35.8800, ratio: 0.5883\n",
            "#34: episode_reward:-11.6091 acc: 35.7000, ratio: 0.4923\n",
            "#35: episode_reward:-14.2051 acc: 20.9600, ratio: 0.4533\n",
            "#36: episode_reward:-12.6170 acc: 30.5400, ratio: 0.5495\n",
            "#37: episode_reward:-10.1798 acc: 43.5600, ratio: 0.4835\n",
            "#38: episode_reward:-13.1408 acc: 27.5800, ratio: 0.5391\n",
            "#39: episode_reward:-13.3008 acc: 26.5000, ratio: 0.5133\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 16, 17, 18, 19]\n",
            "#40: episode_reward:-9.3888 acc: 48.5000, ratio: 0.5871\n",
            "#41: episode_reward:-14.6845 acc: 18.4800, ratio: 0.4724\n",
            "#42: episode_reward:-10.6855 acc: 41.5200, ratio: 0.6119\n",
            "#43: episode_reward:-12.2244 acc: 32.4200, ratio: 0.5094\n",
            "#44: episode_reward:-13.0153 acc: 27.9600, ratio: 0.4984\n",
            "#45: episode_reward:-9.6233 acc: 47.3000, ratio: 0.6050\n",
            "#46: episode_reward:-11.0658 acc: 39.1800, ratio: 0.5661\n",
            "#47: episode_reward:-8.2312 acc: 55.1000, ratio: 0.6499\n",
            "#48: episode_reward:-11.4008 acc: 36.9200, ratio: 0.5018\n",
            "#49: episode_reward:-12.1362 acc: 33.3600, ratio: 0.5761\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 15, 16, 17, 18, 19]\n",
            "#50: episode_reward:-12.2766 acc: 32.4800, ratio: 0.5593\n",
            "#51: episode_reward:-12.8177 acc: 29.5600, ratio: 0.5674\n",
            "#52: episode_reward:-9.3331 acc: 48.6200, ratio: 0.5497\n",
            "#53: episode_reward:-13.5314 acc: 24.8600, ratio: 0.4701\n",
            "#54: episode_reward:-15.6407 acc: 13.7400, ratio: 0.5320\n",
            "#55: episode_reward:-10.2661 acc: 43.6000, ratio: 0.5707\n",
            "#56: episode_reward:-13.5278 acc: 25.5800, ratio: 0.5568\n",
            "#57: episode_reward:-7.6281 acc: 58.2800, ratio: 0.6194\n",
            "#58: episode_reward:-8.0823 acc: 55.8600, ratio: 0.6360\n",
            "#59: episode_reward:-10.2517 acc: 43.7800, ratio: 0.5896\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 16, 17, 18, 19]\n",
            "#60: episode_reward:-8.7633 acc: 51.9600, ratio: 0.5937\n",
            "#61: episode_reward:-8.3427 acc: 54.2200, ratio: 0.5829\n",
            "#62: episode_reward:-8.8790 acc: 51.4800, ratio: 0.6291\n",
            "#63: episode_reward:-13.2280 acc: 27.1200, ratio: 0.5419\n",
            "#64: episode_reward:-13.8744 acc: 23.6000, ratio: 0.5472\n",
            "#65: episode_reward:-7.8953 acc: 56.9000, ratio: 0.6411\n",
            "#66: episode_reward:-10.0922 acc: 44.4800, ratio: 0.5568\n",
            "#67: episode_reward:-12.8588 acc: 28.7000, ratio: 0.4827\n",
            "#68: episode_reward:-14.8179 acc: 17.8000, ratio: 0.4787\n",
            "#69: episode_reward:-11.5548 acc: 36.1400, ratio: 0.5121\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#70: episode_reward:-8.2255 acc: 54.8200, ratio: 0.5729\n",
            "#71: episode_reward:-8.9544 acc: 50.7800, ratio: 0.5652\n",
            "#72: episode_reward:-10.5004 acc: 42.6000, ratio: 0.6251\n",
            "#73: episode_reward:-9.2449 acc: 49.4200, ratio: 0.6154\n",
            "#74: episode_reward:-14.2648 acc: 21.0800, ratio: 0.5025\n",
            "#75: episode_reward:-10.4619 acc: 42.2200, ratio: 0.5186\n",
            "#76: episode_reward:-14.3802 acc: 20.2800, ratio: 0.4844\n",
            "#77: episode_reward:-10.3044 acc: 43.3200, ratio: 0.5581\n",
            "#78: episode_reward:-10.0576 acc: 44.5000, ratio: 0.5265\n",
            "#79: episode_reward:-11.6706 acc: 35.5200, ratio: 0.5150\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 4, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#80: episode_reward:-14.1947 acc: 21.6400, ratio: 0.5228\n",
            "#81: episode_reward:-15.4837 acc: 14.3000, ratio: 0.4986\n",
            "#82: episode_reward:-15.7145 acc: 12.8000, ratio: 0.4761\n",
            "#83: episode_reward:-8.6684 acc: 52.3800, ratio: 0.5712\n",
            "#84: episode_reward:-13.9450 acc: 22.2600, ratio: 0.4382\n",
            "#85: episode_reward:-9.7011 acc: 46.1600, ratio: 0.4749\n",
            "#86: episode_reward:-11.4554 acc: 36.5400, ratio: 0.4908\n",
            "#87: episode_reward:-10.2321 acc: 43.4200, ratio: 0.5072\n",
            "#88: episode_reward:-11.8370 acc: 34.3200, ratio: 0.4767\n",
            "#89: episode_reward:-11.1628 acc: 38.4800, ratio: 0.5389\n",
            "[Train] Sensitive layer indices: [0, 2, 3, 4, 9, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#90: episode_reward:-15.5320 acc: 13.5000, ratio: 0.4462\n",
            "#91: episode_reward:-9.3198 acc: 48.9600, ratio: 0.6045\n",
            "#92: episode_reward:-9.8452 acc: 45.9200, ratio: 0.5722\n",
            "#93: episode_reward:-14.1152 acc: 21.6000, ratio: 0.4681\n",
            "#94: episode_reward:-9.2955 acc: 49.1200, ratio: 0.6103\n",
            "#95: episode_reward:-14.3914 acc: 20.1000, ratio: 0.4717\n",
            "#96: episode_reward:-11.3990 acc: 37.3600, ratio: 0.5681\n",
            "#97: episode_reward:-9.2402 acc: 49.4200, ratio: 0.6097\n",
            "#98: episode_reward:-15.1005 acc: 16.1200, ratio: 0.4673\n",
            "#99: episode_reward:-13.4886 acc: 25.1800, ratio: 0.4794\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#100: episode_reward:-10.9050 acc: 40.1800, ratio: 0.5866\n",
            "/content/amc3/amc_search.py:184: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  action = float(action) + np.random.randn() * noise_std\n",
            "#101: episode_reward:-9.2691 acc: 49.1800, ratio: 0.5921\n",
            "#102: episode_reward:-10.5905 acc: 41.7400, ratio: 0.5570\n",
            "#103: episode_reward:-8.8072 acc: 51.4200, ratio: 0.5305\n",
            "#104: episode_reward:-15.0173 acc: 16.9800, ratio: 0.5095\n",
            "#105: episode_reward:-10.7961 acc: 40.6800, ratio: 0.5693\n",
            "#106: episode_reward:-9.3035 acc: 48.7800, ratio: 0.5492\n",
            "#107: episode_reward:-9.2072 acc: 49.4200, ratio: 0.5712\n",
            "#108: episode_reward:-11.9864 acc: 34.0600, ratio: 0.5568\n",
            "#109: episode_reward:-9.0858 acc: 49.9000, ratio: 0.5337\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#110: episode_reward:-9.3992 acc: 48.4800, ratio: 0.5949\n",
            "#111: episode_reward:-10.9065 acc: 39.8600, ratio: 0.5336\n",
            "#112: episode_reward:-11.2793 acc: 37.5400, ratio: 0.4942\n",
            "#113: episode_reward:-12.9855 acc: 27.9400, ratio: 0.4758\n",
            "#114: episode_reward:-11.2757 acc: 38.1400, ratio: 0.5854\n",
            "#115: episode_reward:-10.6463 acc: 41.7400, ratio: 0.6130\n",
            "#116: episode_reward:-13.0641 acc: 27.6400, ratio: 0.4922\n",
            "#117: episode_reward:-7.9464 acc: 56.3000, ratio: 0.5603\n",
            "#118: episode_reward:-11.9378 acc: 33.8400, ratio: 0.4871\n",
            "#119: episode_reward:-8.8633 acc: 51.3400, ratio: 0.5778\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 16, 17, 18, 19]\n",
            "#120: episode_reward:-9.2590 acc: 49.0200, ratio: 0.5481\n",
            "#121: episode_reward:-12.6666 acc: 29.8800, ratio: 0.4971\n",
            "#122: episode_reward:-9.5937 acc: 47.4600, ratio: 0.6045\n",
            "#123: episode_reward:-10.2166 acc: 44.0800, ratio: 0.6106\n",
            "#124: episode_reward:-12.1530 acc: 33.2600, ratio: 0.5748\n",
            "#125: episode_reward:-10.8161 acc: 40.2400, ratio: 0.5148\n",
            "#126: episode_reward:-15.6935 acc: 13.4600, ratio: 0.5332\n",
            "#127: episode_reward:-8.4696 acc: 53.7400, ratio: 0.6348\n",
            "#128: episode_reward:-13.5505 acc: 25.3600, ratio: 0.5440\n",
            "#129: episode_reward:-7.4889 acc: 59.0400, ratio: 0.6189\n",
            "[Train] Sensitive layer indices: [0, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "#130: episode_reward:-11.9403 acc: 34.2400, ratio: 0.5456\n",
            "#131: episode_reward:-12.9060 acc: 28.7800, ratio: 0.5263\n",
            "#132: episode_reward:-15.5221 acc: 13.8200, ratio: 0.4715\n",
            "#133: episode_reward:-8.4413 acc: 53.8400, ratio: 0.6211\n",
            "#134: episode_reward:-15.2473 acc: 15.3800, ratio: 0.4749\n",
            "#135: episode_reward:-14.2323 acc: 21.0200, ratio: 0.4756\n",
            "#136: episode_reward:-9.9860 acc: 44.8600, ratio: 0.5205\n",
            "#137: episode_reward:-11.2095 acc: 38.6400, ratio: 0.6097\n",
            "#138: episode_reward:-10.5255 acc: 42.1800, ratio: 0.5716\n",
            "#139: episode_reward:-13.2590 acc: 26.5600, ratio: 0.4921\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 11, 13, 14, 15, 16, 17, 18, 19]\n",
            "#140: episode_reward:-13.2667 acc: 27.0200, ratio: 0.5573\n",
            "#141: episode_reward:-7.6031 acc: 58.2600, ratio: 0.5782\n",
            "#142: episode_reward:-11.3135 acc: 37.5400, ratio: 0.5220\n",
            "#143: episode_reward:-9.7270 acc: 46.6000, ratio: 0.5782\n",
            "#144: episode_reward:-10.2043 acc: 43.6800, ratio: 0.5248\n",
            "#145: episode_reward:-10.1225 acc: 44.6000, ratio: 0.6116\n",
            "#146: episode_reward:-10.5440 acc: 41.7000, ratio: 0.5079\n",
            "#147: episode_reward:-14.3268 acc: 20.0800, ratio: 0.4331\n",
            "#148: episode_reward:-7.3495 acc: 59.9200, ratio: 0.6530\n",
            "#149: episode_reward:-10.1896 acc: 43.7000, ratio: 0.5146\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#150: episode_reward:-7.4427 acc: 59.3400, ratio: 0.6322\n",
            "#151: episode_reward:-7.7969 acc: 57.1200, ratio: 0.5598\n",
            "#152: episode_reward:-10.8368 acc: 40.4800, ratio: 0.5734\n",
            "#153: episode_reward:-12.1764 acc: 32.7000, ratio: 0.5115\n",
            "#154: episode_reward:-12.8847 acc: 28.7800, ratio: 0.5108\n",
            "#155: episode_reward:-14.1466 acc: 21.2800, ratio: 0.4528\n",
            "#156: episode_reward:-9.0956 acc: 49.8000, ratio: 0.5250\n",
            "#157: episode_reward:-10.9163 acc: 39.5400, ratio: 0.4928\n",
            "#158: episode_reward:-9.3849 acc: 48.4400, ratio: 0.5705\n",
            "#159: episode_reward:-9.0243 acc: 50.3400, ratio: 0.5537\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 11, 14, 16, 17, 18, 19]\n",
            "#160: episode_reward:-10.4891 acc: 42.2000, ratio: 0.5401\n",
            "#161: episode_reward:-8.2167 acc: 55.0000, ratio: 0.6042\n",
            "#162: episode_reward:-7.0434 acc: 61.4200, ratio: 0.6026\n",
            "#163: episode_reward:-7.6715 acc: 58.2000, ratio: 0.6634\n",
            "#164: episode_reward:-9.4156 acc: 48.3000, ratio: 0.5762\n",
            "#165: episode_reward:-8.4370 acc: 53.6800, ratio: 0.5777\n",
            "#166: episode_reward:-13.7079 acc: 24.2200, ratio: 0.5096\n",
            "#167: episode_reward:-11.4216 acc: 36.8600, ratio: 0.5097\n",
            "#168: episode_reward:-8.5064 acc: 53.4400, ratio: 0.6106\n",
            "#169: episode_reward:-7.7436 acc: 57.5000, ratio: 0.5810\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#170: episode_reward:-7.4223 acc: 59.3600, ratio: 0.6068\n",
            "#171: episode_reward:-9.2907 acc: 48.9800, ratio: 0.5751\n",
            "#172: episode_reward:-14.5793 acc: 18.8200, ratio: 0.4475\n",
            "\u001b[92m New best reward: -6.7982, acc: 62.8600, compress: 0.6320\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.6004091171542145, 0.8, 0.36273310340664866]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 205, 154, 410, 186]\u001b[00m\n",
            "#173: episode_reward:-6.7982 acc: 62.8600, ratio: 0.6320\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9020866306787354, 0.8994857911643379, 0.901935077496942, 0.6004091171542145, 0.9717779437055177, 0.36273310340664866]\n",
            "#174: episode_reward:-10.0850 acc: 44.4200, ratio: 0.5390\n",
            "#175: episode_reward:-8.7015 acc: 52.1800, ratio: 0.5673\n",
            "#176: episode_reward:-8.9513 acc: 50.5800, ratio: 0.5218\n",
            "#177: episode_reward:-10.9794 acc: 39.4200, ratio: 0.5276\n",
            "#178: episode_reward:-10.5825 acc: 41.7400, ratio: 0.5494\n",
            "#179: episode_reward:-7.4893 acc: 58.8200, ratio: 0.5619\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#180: episode_reward:-8.1800 acc: 55.1600, ratio: 0.5942\n",
            "#181: episode_reward:-11.1817 acc: 38.2200, ratio: 0.5148\n",
            "#182: episode_reward:-7.7358 acc: 57.6400, ratio: 0.6058\n",
            "#183: episode_reward:-9.1345 acc: 49.7800, ratio: 0.5632\n",
            "#184: episode_reward:-11.5220 acc: 36.5000, ratio: 0.5389\n",
            "#185: episode_reward:-7.3762 acc: 59.6000, ratio: 0.6034\n",
            "#186: episode_reward:-10.7737 acc: 40.7600, ratio: 0.5618\n",
            "#187: episode_reward:-7.3787 acc: 59.7000, ratio: 0.6353\n",
            "#188: episode_reward:-6.8136 acc: 62.7800, ratio: 0.6333\n",
            "#189: episode_reward:-11.2956 acc: 37.8400, ratio: 0.5536\n",
            "[Train] Sensitive layer indices: [0, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#190: episode_reward:-7.0197 acc: 61.6200, ratio: 0.6230\n",
            "#191: episode_reward:-8.3035 acc: 54.4600, ratio: 0.5887\n",
            "#192: episode_reward:-13.8431 acc: 23.5800, ratio: 0.5228\n",
            "#193: episode_reward:-9.7793 acc: 46.2600, ratio: 0.5679\n",
            "#194: episode_reward:-9.4279 acc: 48.3200, ratio: 0.5943\n",
            "#195: episode_reward:-8.3744 acc: 54.2200, ratio: 0.6246\n",
            "#196: episode_reward:-10.8595 acc: 40.2200, ratio: 0.5502\n",
            "#197: episode_reward:-7.9764 acc: 56.3600, ratio: 0.6154\n",
            "#198: episode_reward:-8.6901 acc: 52.3800, ratio: 0.5979\n",
            "#199: episode_reward:-12.2846 acc: 32.1400, ratio: 0.5167\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "#200: episode_reward:-10.4273 acc: 42.5400, ratio: 0.5401\n",
            "#201: episode_reward:-11.7625 acc: 35.4600, ratio: 0.5839\n",
            "#202: episode_reward:-7.9616 acc: 56.5800, ratio: 0.6526\n",
            "#203: episode_reward:-8.0996 acc: 55.6800, ratio: 0.6139\n",
            "\u001b[92m New best reward: -6.4874, acc: 64.6200, compress: 0.6526\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.35535280376329065]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 205, 205, 410, 182]\u001b[00m\n",
            "#204: episode_reward:-6.4874 acc: 64.6200, ratio: 0.6526\n",
            "New best clamped policy: [0.9, 0.9100899298601538, 0.9, 0.9, 0.9, 0.953550086396653, 0.9030710086382038, 0.8313844555196135, 0.8572987748753745, 0.9, 0.35535280376329065]\n",
            "#205: episode_reward:-14.1258 acc: 22.1600, ratio: 0.5401\n",
            "#206: episode_reward:-7.3761 acc: 59.7000, ratio: 0.6312\n",
            "#207: episode_reward:-6.9599 acc: 61.9400, ratio: 0.6209\n",
            "#208: episode_reward:-7.5242 acc: 58.6800, ratio: 0.5749\n",
            "#209: episode_reward:-6.9050 acc: 62.2400, ratio: 0.6208\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 18, 19]\n",
            "#210: episode_reward:-6.6664 acc: 63.5600, ratio: 0.6256\n",
            "#211: episode_reward:-6.8918 acc: 62.3400, ratio: 0.6293\n",
            "#212: episode_reward:-6.4920 acc: 64.6600, ratio: 0.6750\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9535212230937804, 0.7331922828100411, 0.919806602689588, 0.9923729823972353, 0.9, 0.6347152924206807]\n",
            "#213: episode_reward:-12.9331 acc: 28.7200, ratio: 0.5384\n",
            "#214: episode_reward:-7.8801 acc: 56.8400, ratio: 0.6033\n",
            "#215: episode_reward:-9.0752 acc: 50.2400, ratio: 0.5914\n",
            "#216: episode_reward:-7.6816 acc: 57.8800, ratio: 0.5911\n",
            "#217: episode_reward:-7.5293 acc: 58.7000, ratio: 0.5872\n",
            "#218: episode_reward:-6.7780 acc: 62.9400, ratio: 0.6225\n",
            "#219: episode_reward:-10.0629 acc: 44.5200, ratio: 0.5351\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "#220: episode_reward:-9.4421 acc: 48.1000, ratio: 0.5654\n",
            "#221: episode_reward:-6.9234 acc: 62.2200, ratio: 0.6456\n",
            "#222: episode_reward:-7.0438 acc: 61.5600, ratio: 0.6447\n",
            "#223: episode_reward:-7.0690 acc: 61.4400, ratio: 0.6501\n",
            "#224: episode_reward:-8.2317 acc: 54.9400, ratio: 0.6097\n",
            "#225: episode_reward:-6.5165 acc: 64.4000, ratio: 0.6322\n",
            "#226: episode_reward:-8.1942 acc: 55.0200, ratio: 0.5793\n",
            "#227: episode_reward:-7.2143 acc: 60.5600, ratio: 0.6242\n",
            "#228: episode_reward:-6.9153 acc: 62.2200, ratio: 0.6319\n",
            "\u001b[92m New best reward: -6.4501, acc: 64.8000, compress: 0.6446\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.28121491134291143]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 205, 205, 410, 144]\u001b[00m\n",
            "#229: episode_reward:-6.4501 acc: 64.8000, ratio: 0.6446\n",
            "New best clamped policy: [0.9, 0.9470029272999974, 0.9, 0.9, 0.9058050008301438, 0.9060437628830555, 0.9009875548972337, 0.9238044668017479, 0.9123057113955615, 0.9, 0.28121491134291143]\n",
            "\u001b[92m New best reward: -6.3755, acc: 65.1800, compress: 0.6356\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.7946728153958089, 0.8, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 205, 204, 410, 103]\u001b[00m\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 4, 14, 16, 17, 18, 19]\n",
            "#230: episode_reward:-6.3755 acc: 65.1800, ratio: 0.6356\n",
            "New best clamped policy: [0.9, 0.9813940997394268, 0.9, 0.944332406006992, 0.9343547558249453, 0.8608171727528877, 0.9983705441070573, 0.857077299885582, 0.7946728153958089, 0.9, 0.08340249387915227]\n",
            "#231: episode_reward:-9.1189 acc: 49.8800, ratio: 0.5660\n",
            "#232: episode_reward:-7.0441 acc: 61.4400, ratio: 0.6094\n",
            "#233: episode_reward:-6.5610 acc: 64.1000, ratio: 0.6143\n",
            "#234: episode_reward:-8.6581 acc: 52.3200, ratio: 0.5464\n",
            "#235: episode_reward:-9.5225 acc: 47.5600, ratio: 0.5465\n",
            "#236: episode_reward:-7.2345 acc: 60.3200, ratio: 0.5880\n",
            "#237: episode_reward:-8.2681 acc: 54.5000, ratio: 0.5535\n",
            "#238: episode_reward:-6.7535 acc: 63.0400, ratio: 0.6121\n",
            "#239: episode_reward:-8.9662 acc: 50.8200, ratio: 0.5875\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#240: episode_reward:-8.0462 acc: 55.7800, ratio: 0.5670\n",
            "#241: episode_reward:-7.4605 acc: 59.2000, ratio: 0.6203\n",
            "#242: episode_reward:-6.9411 acc: 62.1200, ratio: 0.6445\n",
            "#243: episode_reward:-7.9568 acc: 56.4800, ratio: 0.6187\n",
            "#244: episode_reward:-6.8952 acc: 62.2800, ratio: 0.6169\n",
            "#245: episode_reward:-7.3496 acc: 59.8200, ratio: 0.6240\n",
            "#246: episode_reward:-6.8061 acc: 62.8200, ratio: 0.6329\n",
            "#247: episode_reward:-6.4201 acc: 64.9400, ratio: 0.6367\n",
            "#248: episode_reward:-7.2911 acc: 60.1600, ratio: 0.6299\n",
            "#249: episode_reward:-7.6072 acc: 58.4200, ratio: 0.6263\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 9, 14, 16, 17, 18, 19]\n",
            "#250: episode_reward:-7.6104 acc: 58.3600, ratio: 0.6147\n",
            "#251: episode_reward:-7.4605 acc: 59.2000, ratio: 0.6203\n",
            "#252: episode_reward:-8.3479 acc: 54.1000, ratio: 0.5622\n",
            "#253: episode_reward:-6.3813 acc: 65.1400, ratio: 0.6327\n",
            "#254: episode_reward:-6.4200 acc: 64.9400, ratio: 0.6364\n",
            "#255: episode_reward:-7.1436 acc: 60.9000, ratio: 0.6107\n",
            "#256: episode_reward:-7.9448 acc: 56.4800, ratio: 0.6019\n",
            "#257: episode_reward:-6.6117 acc: 63.8400, ratio: 0.6196\n",
            "#258: episode_reward:-7.0024 acc: 61.7400, ratio: 0.6305\n",
            "\u001b[92m New best reward: -6.2539, acc: 65.8400, compress: 0.6341\u001b[00m\n",
            "\u001b[92m New best policy: [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.7736983668858755, 0.7992262759196519, 0.8, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [410, 205, 103, 52, 52, 103, 103, 199, 205, 410, 103]\u001b[00m\n",
            "#259: episode_reward:-6.2539 acc: 65.8400, ratio: 0.6341\n",
            "New best clamped policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9043739260762564, 0.9331855155157435, 0.7736983668858755, 0.7992262759196519, 0.9, 0.10772696420955824]\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#260: episode_reward:-6.3538 acc: 65.3000, ratio: 0.6360\n",
            "#261: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#262: episode_reward:-7.3756 acc: 59.5400, ratio: 0.5864\n",
            "#263: episode_reward:-7.4410 acc: 59.1000, ratio: 0.5655\n",
            "#264: episode_reward:-7.4260 acc: 59.3000, ratio: 0.5960\n",
            "#265: episode_reward:-7.8499 acc: 56.8400, ratio: 0.5625\n",
            "#266: episode_reward:-7.8982 acc: 56.6600, ratio: 0.5831\n",
            "#267: episode_reward:-7.7982 acc: 57.2200, ratio: 0.5860\n",
            "#268: episode_reward:-8.0219 acc: 55.9000, ratio: 0.5639\n",
            "#269: episode_reward:-7.7596 acc: 57.4200, ratio: 0.5830\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#270: episode_reward:-7.6031 acc: 58.2600, ratio: 0.5782\n",
            "#271: episode_reward:-7.5084 acc: 58.7400, ratio: 0.5681\n",
            "#272: episode_reward:-7.6775 acc: 57.8600, ratio: 0.5804\n",
            "#273: episode_reward:-7.7314 acc: 57.5600, ratio: 0.5793\n",
            "#274: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#275: episode_reward:-7.2999 acc: 59.9600, ratio: 0.5876\n",
            "#276: episode_reward:-6.8790 acc: 62.2600, ratio: 0.5852\n",
            "#277: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#278: episode_reward:-7.2183 acc: 60.4000, ratio: 0.5855\n",
            "#279: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 13, 14, 16, 17, 18, 19]\n",
            "#280: episode_reward:-8.0740 acc: 55.6400, ratio: 0.5700\n",
            "#281: episode_reward:-7.5256 acc: 58.7600, ratio: 0.5976\n",
            "#282: episode_reward:-7.2586 acc: 60.2800, ratio: 0.6134\n",
            "#283: episode_reward:-8.0557 acc: 55.7000, ratio: 0.5606\n",
            "#284: episode_reward:-8.1458 acc: 55.2800, ratio: 0.5780\n",
            "#285: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#286: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#287: episode_reward:-7.8092 acc: 57.1200, ratio: 0.5761\n",
            "#288: episode_reward:-7.6061 acc: 58.2400, ratio: 0.5773\n",
            "#289: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "[Train] Sensitive layer indices: [0, 1, 2, 3, 4, 14, 16, 17, 18, 19]\n",
            "#290: episode_reward:-7.3709 acc: 59.6200, ratio: 0.6009\n",
            "#291: episode_reward:-7.1810 acc: 60.6000, ratio: 0.5844\n",
            "#292: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#293: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#294: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#295: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#296: episode_reward:-7.3756 acc: 59.5400, ratio: 0.5864\n",
            "#297: episode_reward:-7.7351 acc: 57.5600, ratio: 0.5844\n",
            "#298: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n",
            "#299: episode_reward:-7.2015 acc: 60.5000, ratio: 0.5877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('./logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run6', 'resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsAZrOBZ80qN",
        "outputId": "6f293ac3-2a0a-4d2f-ac45-493c14b12c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder './logs/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search-run6' successfully zipped to 'resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --data_bsize 128 \\\n",
        "    --data_root=./data \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --ckpt_path=./models/state_dict/resnet_cifar.pth.tar \\\n",
        "    --policy_path=/content/amc3/checkpoints/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/best_policy.txt \\\n",
        "    --export_path=./checkpoints/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt \\\n",
        "    --seed=9999 \\\n",
        "    --split_seed=2025 # Use split_seed=2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bf7984-fea2-4a27-d132-57a20aa7c251",
        "id": "zPLfPrfeZ43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Identified sensitive layers: ['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.conv2', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.conv2', 'layer3.1.conv1', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.downsample.0', 'layer4.1.conv1', 'layer4.1.conv2']\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/resnet_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 91.180%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "Sensitive layer indices: [0, 1, 2, 3, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19]\n",
            "=> Original model channels: [512, 256, 128, 64, 64, 128, 128, 256, 256, 512, 512]\n",
            "=> Pruning with ratios: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9043739260762564, 0.9331855155157435, 0.7736983668858755, 0.7992262759196519, 0.9, 0.10772696420955824]\n",
            "=> Channels after pruning: [461, 230, 115, 58, 58, 116, 119, 198, 205, 461, 55]\n",
            "\u001b[92m New best reward: -2.5333, acc: 86.2800, compress: 0.7418\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9043739260762564, 0.9331855155157435, 0.7736983668858755, 0.7992262759196519, 0.9, 0.2]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 58, 58, 116, 120, 199, 205, 461, 103]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=128 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=20 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --split_seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ac37cc-6e18-4c01-fd04-a7f4bc807a6b",
        "id": "ALKVzCdsZ43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data: cifar10...\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Model Parameter: 5.927 M, FLOPs: 104.041M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search/resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_search.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training resnet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/resnet_cifar_finetune-run8\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 374ms | Tot: 23s703ms | Loss: 0.322 | Acc1: 88.960% | Acc5: 99.662% 352/352 \n",
            " [=======================================>]  Step: 136ms | Tot: 844ms | Loss: 0.311 | Acc1: 89.960% | Acc5: 99.600% 40/40 \n",
            "Current best acc: 89.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0049692208514878445\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 13ms | Tot: 23s199ms | Loss: 0.305 | Acc1: 89.413% | Acc5: 99.731% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 607ms | Loss: 0.311 | Acc1: 89.840% | Acc5: 99.600% 40/40 \n",
            "Current best acc: 89.96\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0048776412907378846\n",
            "\n",
            "Epoch: 2\n",
            " [=======================================>]  Step: 14ms | Tot: 24s35ms | Loss: 0.303 | Acc1: 89.469% | Acc5: 99.758% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 578ms | Loss: 0.305 | Acc1: 90.160% | Acc5: 99.540% 40/40 \n",
            "Current best acc: 90.16\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.00472751631047092\n",
            "\n",
            "Epoch: 3\n",
            " [=======================================>]  Step: 12ms | Tot: 23s513ms | Loss: 0.282 | Acc1: 90.331% | Acc5: 99.760% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 586ms | Loss: 0.295 | Acc1: 90.160% | Acc5: 99.520% 40/40 \n",
            "Current best acc: 90.16\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0045225424859373685\n",
            "\n",
            "Epoch: 4\n",
            " [=======================================>]  Step: 58ms | Tot: 23s564ms | Loss: 0.276 | Acc1: 90.371% | Acc5: 99.773% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 573ms | Loss: 0.295 | Acc1: 90.220% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 90.22\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.004267766952966369\n",
            "\n",
            "Epoch: 5\n",
            " [=======================================>]  Step: 12ms | Tot: 23s683ms | Loss: 0.263 | Acc1: 90.822% | Acc5: 99.789% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 685ms | Loss: 0.287 | Acc1: 90.860% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 90.86\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.003969463130731183\n",
            "\n",
            "Epoch: 6\n",
            " [=======================================>]  Step: 17ms | Tot: 23s626ms | Loss: 0.250 | Acc1: 91.373% | Acc5: 99.816% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 583ms | Loss: 0.283 | Acc1: 90.500% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 90.86\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.003634976249348867\n",
            "\n",
            "Epoch: 7\n",
            " [=======================================>]  Step: 12ms | Tot: 23s328ms | Loss: 0.241 | Acc1: 91.584% | Acc5: 99.840% 352/352 \n",
            " [=======================================>]  Step: 5ms | Tot: 585ms | Loss: 0.274 | Acc1: 91.140% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 91.14\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0032725424859373687\n",
            "\n",
            "Epoch: 8\n",
            " [=======================================>]  Step: 13ms | Tot: 23s77ms | Loss: 0.231 | Acc1: 91.933% | Acc5: 99.811% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 573ms | Loss: 0.273 | Acc1: 90.960% | Acc5: 99.580% 40/40 \n",
            "Current best acc: 91.14\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0028910861626005773\n",
            "\n",
            "Epoch: 9\n",
            " [=======================================>]  Step: 60ms | Tot: 23s1ms | Loss: 0.224 | Acc1: 92.280% | Acc5: 99.864% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 587ms | Loss: 0.278 | Acc1: 91.160% | Acc5: 99.620% 40/40 \n",
            "Current best acc: 91.16\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 10\n",
            " [=======================================>]  Step: 13ms | Tot: 23s240ms | Loss: 0.216 | Acc1: 92.420% | Acc5: 99.891% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 564ms | Loss: 0.278 | Acc1: 91.180% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 91.18\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0021089138373994237\n",
            "\n",
            "Epoch: 11\n",
            " [=======================================>]  Step: 12ms | Tot: 23s113ms | Loss: 0.208 | Acc1: 92.836% | Acc5: 99.876% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 738ms | Loss: 0.261 | Acc1: 91.420% | Acc5: 99.720% 40/40 \n",
            "Current best acc: 91.42\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0017274575140626316\n",
            "\n",
            "Epoch: 12\n",
            " [=======================================>]  Step: 58ms | Tot: 23s179ms | Loss: 0.199 | Acc1: 92.993% | Acc5: 99.882% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 568ms | Loss: 0.264 | Acc1: 91.540% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.54\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0013650237506511332\n",
            "\n",
            "Epoch: 13\n",
            " [=======================================>]  Step: 13ms | Tot: 23s243ms | Loss: 0.192 | Acc1: 93.260% | Acc5: 99.884% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 726ms | Loss: 0.256 | Acc1: 91.920% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 91.92\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0010305368692688174\n",
            "\n",
            "Epoch: 14\n",
            " [=======================================>]  Step: 59ms | Tot: 23s281ms | Loss: 0.182 | Acc1: 93.693% | Acc5: 99.918% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 562ms | Loss: 0.255 | Acc1: 91.940% | Acc5: 99.700% 40/40 \n",
            "Current best acc: 91.94\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.0007322330470336313\n",
            "\n",
            "Epoch: 15\n",
            " [=======================================>]  Step: 12ms | Tot: 23s113ms | Loss: 0.173 | Acc1: 93.993% | Acc5: 99.904% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 575ms | Loss: 0.254 | Acc1: 92.160% | Acc5: 99.680% 40/40 \n",
            "Current best acc: 92.16\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.00047745751406263163\n",
            "\n",
            "Epoch: 16\n",
            " [=======================================>]  Step: 12ms | Tot: 23s275ms | Loss: 0.170 | Acc1: 93.969% | Acc5: 99.929% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 597ms | Loss: 0.252 | Acc1: 92.120% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.16\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.00027248368952908055\n",
            "\n",
            "Epoch: 17\n",
            " [=======================================>]  Step: 12ms | Tot: 23s34ms | Loss: 0.166 | Acc1: 94.316% | Acc5: 99.902% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 600ms | Loss: 0.251 | Acc1: 92.260% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 92.26\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 0.00012235870926211617\n",
            "\n",
            "Epoch: 18\n",
            " [=======================================>]  Step: 58ms | Tot: 23s451ms | Loss: 0.160 | Acc1: 94.340% | Acc5: 99.904% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 596ms | Loss: 0.250 | Acc1: 92.260% | Acc5: 99.640% 40/40 \n",
            "Current best acc: 92.26\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> lr: 3.077914851215585e-05\n",
            "\n",
            "Epoch: 19\n",
            " [=======================================>]  Step: 60ms | Tot: 23s450ms | Loss: 0.163 | Acc1: 94.322% | Acc5: 99.913% 352/352 \n",
            " [=======================================>]  Step: 4ms | Tot: 587ms | Loss: 0.251 | Acc1: 92.140% | Acc5: 99.660% 40/40 \n",
            "Current best acc: 92.26\n",
            "=> Saving checkpoint to ./logs/resnet_cifar_finetune-run8/ckpt.pth.tar\n",
            "=> Model Parameter: 5.927 M, FLOPs: 104.041M, best top-1 acc: 92.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_folder('/content/amc3/logs/resnet_cifar_finetune-run8', 'resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_ft.zip', excluded=['ckpt.pth.tar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_cFov6YZ43d",
        "outputId": "8e6e9e64-a543-4ff6-c488-b29cb254ce65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Compressed /content/amc3/logs/resnet_cifar_finetune-run8 to resnet_cifar_sensitivity_r0.5_rbound0.8_ep300_ft.zip\n"
          ]
        }
      ]
    }
  ]
}